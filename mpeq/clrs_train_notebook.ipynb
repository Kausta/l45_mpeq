{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3acdd8b",
   "metadata": {},
   "source": [
    "# Run training of CLRS algorithm\n",
    "\n",
    "Copied main function from clrs_train.py. Helper functions are located in clrs_train_funcs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b11198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "import shutil\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import logging\n",
    "import clrs\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "import haiku as hk\n",
    "\n",
    "import model\n",
    "import flags\n",
    "from clrs_train_funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "771141dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa63cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch = logging.StreamHandler()\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b412628f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 10:01:01,938 - jax._src.lib.xla_bridge - INFO - Remote TPU is not linked into jax; skipping remote TPU.\n",
      "2023-03-17 10:01:01,939 - jax._src.lib.xla_bridge - INFO - Unable to initialize backend 'tpu_driver': Could not initialize backend 'tpu_driver'\n",
      "2023-03-17 10:01:01,939 - jax._src.lib.xla_bridge - INFO - Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "2023-03-17 10:01:01,939 - jax._src.lib.xla_bridge - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "2023-03-17 10:01:01,940 - jax._src.lib.xla_bridge - INFO - Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'\n",
      "2023-03-17 10:01:01,940 - jax._src.lib.xla_bridge - INFO - Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.hint_mode == 'encoded_decoded':\n",
    "    encode_hints = True\n",
    "    decode_hints = True\n",
    "elif FLAGS.hint_mode == 'decoded_only':\n",
    "    encode_hints = False\n",
    "    decode_hints = True\n",
    "elif FLAGS.hint_mode == 'none':\n",
    "    encode_hints = False\n",
    "    decode_hints = False\n",
    "else:\n",
    "    raise ValueError(\n",
    "        'Hint mode not in {encoded_decoded, decoded_only, none}.')\n",
    "\n",
    "train_lengths = [int(x) for x in FLAGS.train_lengths]\n",
    "\n",
    "rng = np.random.RandomState(FLAGS.seed)\n",
    "rng_key = jax.random.PRNGKey(rng.randint(2**32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a79e1217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 10:01:01,981 - root - INFO - Creating samplers for algo binary_search\n",
      "2023-03-17 10:01:01,982 - absl - WARNING - Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.SearchSampler'>\n",
      "2023-03-17 10:01:01,982 - absl - WARNING - Sampling dataset on-the-fly, unlimited samples.\n",
      "2023-03-17 10:01:02,099 - absl - WARNING - Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.SearchSampler'>\n",
      "2023-03-17 10:01:02,099 - absl - WARNING - Sampling dataset on-the-fly, unlimited samples.\n",
      "2023-03-17 10:01:02,220 - absl - WARNING - Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.SearchSampler'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 10:01:02,221 - absl - WARNING - Sampling dataset on-the-fly, unlimited samples.\n",
      "2023-03-17 10:01:02,356 - absl - WARNING - Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.SearchSampler'>\n",
      "2023-03-17 10:01:02,356 - absl - WARNING - Sampling dataset on-the-fly, unlimited samples.\n",
      "2023-03-17 10:01:02,494 - absl - WARNING - Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.SearchSampler'>\n",
      "2023-03-17 10:01:02,495 - absl - WARNING - Sampling dataset on-the-fly, unlimited samples.\n",
      "2023-03-17 10:01:02,638 - absl - WARNING - Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.SearchSampler'>\n",
      "2023-03-17 10:01:02,638 - absl - INFO - Creating a dataset with 4096 samples.\n",
      "2023-03-17 10:01:02,871 - absl - INFO - 1000 samples created\n",
      "2023-03-17 10:01:03,010 - absl - INFO - 2000 samples created\n",
      "2023-03-17 10:01:03,143 - absl - INFO - 3000 samples created\n",
      "2023-03-17 10:01:03,265 - absl - INFO - 4000 samples created\n",
      "2023-03-17 10:01:03,340 - root - INFO - Dataset found at /tmp/CLRS30/CLRS30_v1.0.0. Skipping download.\n",
      "2023-03-17 10:01:03,341 - absl - INFO - Load dataset info from /tmp/CLRS30/CLRS30_v1.0.0/clrs_dataset/binary_search_test/1.0.0\n",
      "2023-03-17 10:01:03,342 - absl - INFO - Load dataset info from /tmp/CLRS30/CLRS30_v1.0.0/clrs_dataset/binary_search_test/1.0.0\n",
      "2023-03-17 10:01:03,343 - absl - INFO - Reusing dataset clrs_dataset (/tmp/CLRS30/CLRS30_v1.0.0/clrs_dataset/binary_search_test/1.0.0)\n",
      "2023-03-17 10:01:03,343 - absl - INFO - Constructing tf.data.Dataset clrs_dataset for split test, from /tmp/CLRS30/CLRS30_v1.0.0/clrs_dataset/binary_search_test/1.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/james/.pyenv/versions/3.9.16/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 10:01:03,399 - tensorflow - WARNING - From /Users/james/.pyenv/versions/3.9.16/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "2023-03-17 10:01:03.540859: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# Create samplers\n",
    "(train_samplers,\n",
    " val_samplers, val_sample_counts,\n",
    " test_samplers, test_sample_counts,\n",
    " spec_list) = create_samplers(rng, train_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cb3c437",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.l1_weight = 0.001\n",
    "FLAGS.train_steps = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3080605",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor_factory = model.get_processor_factory(\n",
    "    FLAGS.processor_type,\n",
    "    use_ln=FLAGS.use_ln,\n",
    "    nb_triplet_fts=FLAGS.nb_triplet_fts,\n",
    "    nb_heads=FLAGS.nb_heads\n",
    ")\n",
    "model_params = dict(\n",
    "    processor_factory=processor_factory,\n",
    "    hidden_dim=FLAGS.hidden_size,\n",
    "    encode_hints=encode_hints,\n",
    "    decode_hints=decode_hints,\n",
    "    encoder_init=FLAGS.encoder_init,\n",
    "    use_lstm=FLAGS.use_lstm,\n",
    "    learning_rate=FLAGS.learning_rate,\n",
    "    grad_clip_max_norm=FLAGS.grad_clip_max_norm,\n",
    "    checkpoint_path=FLAGS.checkpoint_path,\n",
    "    freeze_processor=FLAGS.freeze_processor,\n",
    "    dropout_prob=FLAGS.dropout_prob,\n",
    "    hint_teacher_forcing=FLAGS.hint_teacher_forcing,\n",
    "    hint_repred_mode=FLAGS.hint_repred_mode,\n",
    "    nb_msg_passing_steps=FLAGS.nb_msg_passing_steps,\n",
    "    l1_weight=FLAGS.l1_weight\n",
    ")\n",
    "\n",
    "eval_model = model.BaselineMsgModel(\n",
    "    spec=spec_list,\n",
    "    dummy_trajectory=[next(t) for t in val_samplers],\n",
    "    **model_params\n",
    ")\n",
    "# # we will never used chunked training\n",
    "# if FLAGS.chunked_training:\n",
    "#     train_model = clrs.models.BaselineModelChunked(\n",
    "#         spec=spec_list,\n",
    "#         dummy_trajectory=[next(t) for t in train_samplers],\n",
    "#         **model_params\n",
    "#     )\n",
    "# else:\n",
    "#     train_model = eval_model\n",
    "train_model = eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6738fd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 2, 4, 4, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 10:03:38,267 - root - INFO - Algo binary_search step 0 current loss 6.506681, current_train_items 32.\n",
      "2023-03-17 10:03:40,861 - root - INFO - (val) algo binary_search step 0: {'return': 0.09521484375, 'score': 0.09521484375, 'examples_seen': 32, 'step': 0, 'algorithm': 'binary_search'}\n",
      "2023-03-17 10:03:40,861 - root - INFO - Checkpointing best model, best avg val score was -1.000, current avg val score is 0.095, val scores are: binary_search: 0.095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 7, 7, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 10:03:44,304 - root - INFO - Algo binary_search step 1 current loss 9.225758, current_train_items 64.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 4, 11, 11, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 10:03:47,739 - root - INFO - Algo binary_search step 2 current loss 13.320404, current_train_items 96.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 4, 13, 13, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 10:03:51,240 - root - INFO - Algo binary_search step 3 current loss 13.820802, current_train_items 128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 4, 16, 16, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 10:03:54,674 - root - INFO - Algo binary_search step 4 current loss 15.492587, current_train_items 160.\n",
      "2023-03-17 10:03:54,690 - root - INFO - Algo binary_search step 5 current loss 5.844983, current_train_items 192.\n",
      "2023-03-17 10:03:54,725 - root - INFO - Algo binary_search step 6 current loss 7.556711, current_train_items 224.\n",
      "2023-03-17 10:03:54,795 - root - INFO - Algo binary_search step 7 current loss 9.790084, current_train_items 256.\n",
      "2023-03-17 10:03:54,898 - root - INFO - Algo binary_search step 8 current loss 10.749120, current_train_items 288.\n",
      "2023-03-17 10:03:55,007 - root - INFO - Algo binary_search step 9 current loss 12.213992, current_train_items 320.\n",
      "2023-03-17 10:03:55,022 - root - INFO - Algo binary_search step 10 current loss 5.405589, current_train_items 352.\n",
      "2023-03-17 10:03:55,059 - root - INFO - Algo binary_search step 11 current loss 6.864581, current_train_items 384.\n",
      "2023-03-17 10:03:55,128 - root - INFO - Algo binary_search step 12 current loss 8.880873, current_train_items 416.\n",
      "2023-03-17 10:03:55,211 - root - INFO - Algo binary_search step 13 current loss 9.523474, current_train_items 448.\n",
      "2023-03-17 10:03:55,320 - root - INFO - Algo binary_search step 14 current loss 10.763199, current_train_items 480.\n",
      "2023-03-17 10:03:55,333 - root - INFO - Algo binary_search step 15 current loss 4.900162, current_train_items 512.\n",
      "2023-03-17 10:03:55,366 - root - INFO - Algo binary_search step 16 current loss 6.665845, current_train_items 544.\n",
      "2023-03-17 10:03:55,436 - root - INFO - Algo binary_search step 17 current loss 7.958735, current_train_items 576.\n",
      "2023-03-17 10:03:55,518 - root - INFO - Algo binary_search step 18 current loss 8.562065, current_train_items 608.\n",
      "2023-03-17 10:03:55,627 - root - INFO - Algo binary_search step 19 current loss 10.050405, current_train_items 640.\n",
      "2023-03-17 10:03:55,685 - root - INFO - Algo binary_search step 20 current loss 4.134727, current_train_items 672.\n",
      "2023-03-17 10:03:55,749 - root - INFO - Algo binary_search step 21 current loss 5.792807, current_train_items 704.\n",
      "2023-03-17 10:03:55,820 - root - INFO - Algo binary_search step 22 current loss 7.295956, current_train_items 736.\n",
      "2023-03-17 10:03:55,907 - root - INFO - Algo binary_search step 23 current loss 7.809872, current_train_items 768.\n",
      "2023-03-17 10:03:56,016 - root - INFO - Algo binary_search step 24 current loss 8.575358, current_train_items 800.\n",
      "2023-03-17 10:03:56,031 - root - INFO - Algo binary_search step 25 current loss 3.815020, current_train_items 832.\n",
      "2023-03-17 10:03:56,065 - root - INFO - Algo binary_search step 26 current loss 5.127681, current_train_items 864.\n",
      "2023-03-17 10:03:56,134 - root - INFO - Algo binary_search step 27 current loss 6.576973, current_train_items 896.\n",
      "2023-03-17 10:03:56,218 - root - INFO - Algo binary_search step 28 current loss 6.854885, current_train_items 928.\n",
      "2023-03-17 10:03:56,324 - root - INFO - Algo binary_search step 29 current loss 8.341929, current_train_items 960.\n",
      "2023-03-17 10:03:56,337 - root - INFO - Algo binary_search step 30 current loss 3.130383, current_train_items 992.\n",
      "2023-03-17 10:03:56,371 - root - INFO - Algo binary_search step 31 current loss 4.504529, current_train_items 1024.\n",
      "2023-03-17 10:03:56,440 - root - INFO - Algo binary_search step 32 current loss 5.878189, current_train_items 1056.\n",
      "2023-03-17 10:03:56,532 - root - INFO - Algo binary_search step 33 current loss 6.053843, current_train_items 1088.\n",
      "2023-03-17 10:03:56,641 - root - INFO - Algo binary_search step 34 current loss 7.138930, current_train_items 1120.\n",
      "2023-03-17 10:03:56,657 - root - INFO - Algo binary_search step 35 current loss 3.514568, current_train_items 1152.\n",
      "2023-03-17 10:03:56,690 - root - INFO - Algo binary_search step 36 current loss 3.930024, current_train_items 1184.\n",
      "2023-03-17 10:03:56,757 - root - INFO - Algo binary_search step 37 current loss 5.589167, current_train_items 1216.\n",
      "2023-03-17 10:03:56,852 - root - INFO - Algo binary_search step 38 current loss 6.534020, current_train_items 1248.\n",
      "2023-03-17 10:03:56,986 - root - INFO - Algo binary_search step 39 current loss 6.481444, current_train_items 1280.\n",
      "2023-03-17 10:03:57,000 - root - INFO - Algo binary_search step 40 current loss 2.337001, current_train_items 1312.\n",
      "2023-03-17 10:03:57,036 - root - INFO - Algo binary_search step 41 current loss 3.618903, current_train_items 1344.\n",
      "2023-03-17 10:03:57,110 - root - INFO - Algo binary_search step 42 current loss 6.370484, current_train_items 1376.\n",
      "2023-03-17 10:03:57,198 - root - INFO - Algo binary_search step 43 current loss 7.343815, current_train_items 1408.\n",
      "2023-03-17 10:03:57,313 - root - INFO - Algo binary_search step 44 current loss 7.635183, current_train_items 1440.\n",
      "2023-03-17 10:03:57,328 - root - INFO - Algo binary_search step 45 current loss 2.072472, current_train_items 1472.\n",
      "2023-03-17 10:03:57,362 - root - INFO - Algo binary_search step 46 current loss 4.647462, current_train_items 1504.\n",
      "2023-03-17 10:03:57,436 - root - INFO - Algo binary_search step 47 current loss 5.648286, current_train_items 1536.\n",
      "2023-03-17 10:03:57,521 - root - INFO - Algo binary_search step 48 current loss 6.436715, current_train_items 1568.\n",
      "2023-03-17 10:03:57,633 - root - INFO - Algo binary_search step 49 current loss 7.021670, current_train_items 1600.\n",
      "2023-03-17 10:03:57,647 - root - INFO - Algo binary_search step 50 current loss 2.464888, current_train_items 1632.\n",
      "2023-03-17 10:04:00,013 - root - INFO - (val) algo binary_search step 50: {'return': 0.604248046875, 'score': 0.604248046875, 'examples_seen': 1632, 'step': 50, 'algorithm': 'binary_search'}\n",
      "2023-03-17 10:04:00,013 - root - INFO - Checkpointing best model, best avg val score was 0.095, current avg val score is 0.604, val scores are: binary_search: 0.604\n",
      "2023-03-17 10:04:00,052 - root - INFO - Algo binary_search step 51 current loss 3.253619, current_train_items 1664.\n",
      "2023-03-17 10:04:00,123 - root - INFO - Algo binary_search step 52 current loss 4.618026, current_train_items 1696.\n",
      "2023-03-17 10:04:00,206 - root - INFO - Algo binary_search step 53 current loss 5.701491, current_train_items 1728.\n",
      "2023-03-17 10:04:00,313 - root - INFO - Algo binary_search step 54 current loss 6.237730, current_train_items 1760.\n",
      "2023-03-17 10:04:00,327 - root - INFO - Algo binary_search step 55 current loss 2.472780, current_train_items 1792.\n",
      "2023-03-17 10:04:00,360 - root - INFO - Algo binary_search step 56 current loss 5.056266, current_train_items 1824.\n",
      "2023-03-17 10:04:00,430 - root - INFO - Algo binary_search step 57 current loss 4.612938, current_train_items 1856.\n",
      "2023-03-17 10:04:00,514 - root - INFO - Algo binary_search step 58 current loss 5.399536, current_train_items 1888.\n",
      "2023-03-17 10:04:00,623 - root - INFO - Algo binary_search step 59 current loss 5.802155, current_train_items 1920.\n",
      "2023-03-17 10:04:00,636 - root - INFO - Algo binary_search step 60 current loss 1.781849, current_train_items 1952.\n",
      "2023-03-17 10:04:00,670 - root - INFO - Algo binary_search step 61 current loss 3.016543, current_train_items 1984.\n",
      "2023-03-17 10:04:00,740 - root - INFO - Algo binary_search step 62 current loss 4.708795, current_train_items 2016.\n",
      "2023-03-17 10:04:00,824 - root - INFO - Algo binary_search step 63 current loss 5.200746, current_train_items 2048.\n",
      "2023-03-17 10:04:00,952 - root - INFO - Algo binary_search step 64 current loss 5.401301, current_train_items 2080.\n",
      "2023-03-17 10:04:00,966 - root - INFO - Algo binary_search step 65 current loss 2.034638, current_train_items 2112.\n",
      "2023-03-17 10:04:01,002 - root - INFO - Algo binary_search step 66 current loss 3.034897, current_train_items 2144.\n",
      "2023-03-17 10:04:01,076 - root - INFO - Algo binary_search step 67 current loss 4.524118, current_train_items 2176.\n",
      "2023-03-17 10:04:01,166 - root - INFO - Algo binary_search step 68 current loss 5.110939, current_train_items 2208.\n",
      "2023-03-17 10:04:01,280 - root - INFO - Algo binary_search step 69 current loss 6.309531, current_train_items 2240.\n",
      "2023-03-17 10:04:01,295 - root - INFO - Algo binary_search step 70 current loss 1.448927, current_train_items 2272.\n",
      "2023-03-17 10:04:01,329 - root - INFO - Algo binary_search step 71 current loss 3.013697, current_train_items 2304.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 10:04:01,399 - root - INFO - Algo binary_search step 72 current loss 4.815959, current_train_items 2336.\n",
      "2023-03-17 10:04:01,482 - root - INFO - Algo binary_search step 73 current loss 4.907534, current_train_items 2368.\n",
      "2023-03-17 10:04:01,594 - root - INFO - Algo binary_search step 74 current loss 5.452176, current_train_items 2400.\n",
      "2023-03-17 10:04:01,607 - root - INFO - Algo binary_search step 75 current loss 1.807760, current_train_items 2432.\n",
      "2023-03-17 10:04:01,643 - root - INFO - Algo binary_search step 76 current loss 2.645643, current_train_items 2464.\n",
      "2023-03-17 10:04:01,717 - root - INFO - Algo binary_search step 77 current loss 4.997289, current_train_items 2496.\n",
      "2023-03-17 10:04:01,819 - root - INFO - Algo binary_search step 78 current loss 5.114048, current_train_items 2528.\n",
      "2023-03-17 10:04:01,933 - root - INFO - Algo binary_search step 79 current loss 5.380050, current_train_items 2560.\n",
      "2023-03-17 10:04:01,948 - root - INFO - Algo binary_search step 80 current loss 1.712265, current_train_items 2592.\n",
      "2023-03-17 10:04:01,985 - root - INFO - Algo binary_search step 81 current loss 2.635115, current_train_items 2624.\n",
      "2023-03-17 10:04:02,057 - root - INFO - Algo binary_search step 82 current loss 4.718927, current_train_items 2656.\n",
      "2023-03-17 10:04:02,146 - root - INFO - Algo binary_search step 83 current loss 4.845047, current_train_items 2688.\n",
      "2023-03-17 10:04:02,262 - root - INFO - Algo binary_search step 84 current loss 6.222374, current_train_items 2720.\n",
      "2023-03-17 10:04:02,277 - root - INFO - Algo binary_search step 85 current loss 1.749483, current_train_items 2752.\n",
      "2023-03-17 10:04:02,312 - root - INFO - Algo binary_search step 86 current loss 2.702214, current_train_items 2784.\n",
      "2023-03-17 10:04:02,385 - root - INFO - Algo binary_search step 87 current loss 4.429560, current_train_items 2816.\n",
      "2023-03-17 10:04:02,472 - root - INFO - Algo binary_search step 88 current loss 4.872351, current_train_items 2848.\n",
      "2023-03-17 10:04:02,581 - root - INFO - Algo binary_search step 89 current loss 5.181929, current_train_items 2880.\n",
      "2023-03-17 10:04:02,595 - root - INFO - Algo binary_search step 90 current loss 1.599570, current_train_items 2912.\n",
      "2023-03-17 10:04:02,627 - root - INFO - Algo binary_search step 91 current loss 2.730272, current_train_items 2944.\n",
      "2023-03-17 10:04:02,696 - root - INFO - Algo binary_search step 92 current loss 4.977565, current_train_items 2976.\n",
      "2023-03-17 10:04:02,779 - root - INFO - Algo binary_search step 93 current loss 6.250953, current_train_items 3008.\n",
      "2023-03-17 10:04:02,898 - root - INFO - Algo binary_search step 94 current loss 4.760167, current_train_items 3040.\n",
      "2023-03-17 10:04:02,911 - root - INFO - Algo binary_search step 95 current loss 1.300093, current_train_items 3072.\n",
      "2023-03-17 10:04:02,945 - root - INFO - Algo binary_search step 96 current loss 2.690425, current_train_items 3104.\n",
      "2023-03-17 10:04:03,015 - root - INFO - Algo binary_search step 97 current loss 4.317364, current_train_items 3136.\n",
      "2023-03-17 10:04:03,102 - root - INFO - Algo binary_search step 98 current loss 4.446870, current_train_items 3168.\n",
      "2023-03-17 10:04:03,216 - root - INFO - Algo binary_search step 99 current loss 5.113451, current_train_items 3200.\n",
      "2023-03-17 10:04:03,232 - root - INFO - Algo binary_search step 100 current loss 1.732473, current_train_items 3232.\n",
      "2023-03-17 10:04:05,597 - root - INFO - (val) algo binary_search step 100: {'return': 0.6953125, 'score': 0.6953125, 'examples_seen': 3232, 'step': 100, 'algorithm': 'binary_search'}\n",
      "2023-03-17 10:04:05,598 - root - INFO - Checkpointing best model, best avg val score was 0.604, current avg val score is 0.695, val scores are: binary_search: 0.695\n",
      "2023-03-17 10:04:05,634 - root - INFO - Algo binary_search step 101 current loss 2.530738, current_train_items 3264.\n",
      "2023-03-17 10:04:05,703 - root - INFO - Algo binary_search step 102 current loss 3.606219, current_train_items 3296.\n",
      "2023-03-17 10:04:05,790 - root - INFO - Algo binary_search step 103 current loss 3.935757, current_train_items 3328.\n",
      "2023-03-17 10:04:05,912 - root - INFO - Algo binary_search step 104 current loss 5.301030, current_train_items 3360.\n",
      "2023-03-17 10:04:05,928 - root - INFO - Algo binary_search step 105 current loss 1.568800, current_train_items 3392.\n",
      "2023-03-17 10:04:05,963 - root - INFO - Algo binary_search step 106 current loss 2.045302, current_train_items 3424.\n",
      "2023-03-17 10:04:06,035 - root - INFO - Algo binary_search step 107 current loss 3.496326, current_train_items 3456.\n",
      "2023-03-17 10:04:06,125 - root - INFO - Algo binary_search step 108 current loss 4.338989, current_train_items 3488.\n",
      "2023-03-17 10:04:06,240 - root - INFO - Algo binary_search step 109 current loss 4.744848, current_train_items 3520.\n",
      "2023-03-17 10:04:06,255 - root - INFO - Algo binary_search step 110 current loss 0.930343, current_train_items 3552.\n",
      "2023-03-17 10:04:06,291 - root - INFO - Algo binary_search step 111 current loss 2.661706, current_train_items 3584.\n",
      "2023-03-17 10:04:06,365 - root - INFO - Algo binary_search step 112 current loss 4.123052, current_train_items 3616.\n",
      "2023-03-17 10:04:06,451 - root - INFO - Algo binary_search step 113 current loss 4.601467, current_train_items 3648.\n",
      "2023-03-17 10:04:06,559 - root - INFO - Algo binary_search step 114 current loss 4.857347, current_train_items 3680.\n",
      "2023-03-17 10:04:06,573 - root - INFO - Algo binary_search step 115 current loss 1.612319, current_train_items 3712.\n",
      "2023-03-17 10:04:06,607 - root - INFO - Algo binary_search step 116 current loss 2.291181, current_train_items 3744.\n",
      "2023-03-17 10:04:06,676 - root - INFO - Algo binary_search step 117 current loss 3.519039, current_train_items 3776.\n",
      "2023-03-17 10:04:06,761 - root - INFO - Algo binary_search step 118 current loss 3.914758, current_train_items 3808.\n",
      "2023-03-17 10:04:06,888 - root - INFO - Algo binary_search step 119 current loss 4.440483, current_train_items 3840.\n",
      "2023-03-17 10:04:06,903 - root - INFO - Algo binary_search step 120 current loss 0.899313, current_train_items 3872.\n",
      "2023-03-17 10:04:06,938 - root - INFO - Algo binary_search step 121 current loss 2.893862, current_train_items 3904.\n",
      "2023-03-17 10:04:07,010 - root - INFO - Algo binary_search step 122 current loss 3.242171, current_train_items 3936.\n",
      "2023-03-17 10:04:07,099 - root - INFO - Algo binary_search step 123 current loss 3.613935, current_train_items 3968.\n",
      "2023-03-17 10:04:07,213 - root - INFO - Algo binary_search step 124 current loss 5.319833, current_train_items 4000.\n",
      "2023-03-17 10:04:07,227 - root - INFO - Algo binary_search step 125 current loss 1.133821, current_train_items 4032.\n",
      "2023-03-17 10:04:07,262 - root - INFO - Algo binary_search step 126 current loss 2.495933, current_train_items 4064.\n",
      "2023-03-17 10:04:07,333 - root - INFO - Algo binary_search step 127 current loss 3.324509, current_train_items 4096.\n",
      "2023-03-17 10:04:07,417 - root - INFO - Algo binary_search step 128 current loss 3.444888, current_train_items 4128.\n",
      "2023-03-17 10:04:07,526 - root - INFO - Algo binary_search step 129 current loss 4.730954, current_train_items 4160.\n",
      "2023-03-17 10:04:07,540 - root - INFO - Algo binary_search step 130 current loss 0.780764, current_train_items 4192.\n",
      "2023-03-17 10:04:07,574 - root - INFO - Algo binary_search step 131 current loss 1.904033, current_train_items 4224.\n",
      "2023-03-17 10:04:07,649 - root - INFO - Algo binary_search step 132 current loss 3.621761, current_train_items 4256.\n",
      "2023-03-17 10:04:07,734 - root - INFO - Algo binary_search step 133 current loss 3.814717, current_train_items 4288.\n",
      "2023-03-17 10:04:07,851 - root - INFO - Algo binary_search step 134 current loss 4.256966, current_train_items 4320.\n",
      "2023-03-17 10:04:07,865 - root - INFO - Algo binary_search step 135 current loss 1.218407, current_train_items 4352.\n",
      "2023-03-17 10:04:07,898 - root - INFO - Algo binary_search step 136 current loss 2.382670, current_train_items 4384.\n",
      "2023-03-17 10:04:07,968 - root - INFO - Algo binary_search step 137 current loss 3.904389, current_train_items 4416.\n",
      "2023-03-17 10:04:08,056 - root - INFO - Algo binary_search step 138 current loss 3.753058, current_train_items 4448.\n",
      "2023-03-17 10:04:08,167 - root - INFO - Algo binary_search step 139 current loss 4.964245, current_train_items 4480.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 10:04:08,181 - root - INFO - Algo binary_search step 140 current loss 0.685631, current_train_items 4512.\n",
      "2023-03-17 10:04:08,215 - root - INFO - Algo binary_search step 141 current loss 1.513210, current_train_items 4544.\n",
      "2023-03-17 10:04:08,285 - root - INFO - Algo binary_search step 142 current loss 2.753431, current_train_items 4576.\n",
      "2023-03-17 10:04:08,370 - root - INFO - Algo binary_search step 143 current loss 3.698956, current_train_items 4608.\n",
      "2023-03-17 10:04:08,483 - root - INFO - Algo binary_search step 144 current loss 4.164170, current_train_items 4640.\n",
      "2023-03-17 10:04:08,497 - root - INFO - Algo binary_search step 145 current loss 0.903493, current_train_items 4672.\n",
      "2023-03-17 10:04:08,532 - root - INFO - Algo binary_search step 146 current loss 2.017942, current_train_items 4704.\n",
      "2023-03-17 10:04:08,601 - root - INFO - Algo binary_search step 147 current loss 3.391451, current_train_items 4736.\n",
      "2023-03-17 10:04:08,684 - root - INFO - Algo binary_search step 148 current loss 3.095323, current_train_items 4768.\n",
      "2023-03-17 10:04:08,800 - root - INFO - Algo binary_search step 149 current loss 3.451483, current_train_items 4800.\n",
      "2023-03-17 10:04:08,818 - root - INFO - Algo binary_search step 150 current loss 0.980985, current_train_items 4832.\n",
      "2023-03-17 10:04:11,170 - root - INFO - (val) algo binary_search step 150: {'return': 0.776123046875, 'score': 0.776123046875, 'examples_seen': 4832, 'step': 150, 'algorithm': 'binary_search'}\n",
      "2023-03-17 10:04:11,171 - root - INFO - Checkpointing best model, best avg val score was 0.695, current avg val score is 0.776, val scores are: binary_search: 0.776\n",
      "2023-03-17 10:04:11,207 - root - INFO - Algo binary_search step 151 current loss 1.882061, current_train_items 4864.\n",
      "2023-03-17 10:04:11,277 - root - INFO - Algo binary_search step 152 current loss 2.787929, current_train_items 4896.\n",
      "2023-03-17 10:04:11,359 - root - INFO - Algo binary_search step 153 current loss 3.740352, current_train_items 4928.\n",
      "2023-03-17 10:04:11,467 - root - INFO - Algo binary_search step 154 current loss 4.250794, current_train_items 4960.\n",
      "2023-03-17 10:04:11,480 - root - INFO - Algo binary_search step 155 current loss 0.811190, current_train_items 4992.\n",
      "2023-03-17 10:04:11,514 - root - INFO - Algo binary_search step 156 current loss 2.128685, current_train_items 5024.\n",
      "2023-03-17 10:04:11,584 - root - INFO - Algo binary_search step 157 current loss 3.379028, current_train_items 5056.\n",
      "2023-03-17 10:04:11,669 - root - INFO - Algo binary_search step 158 current loss 3.704351, current_train_items 5088.\n",
      "2023-03-17 10:04:11,776 - root - INFO - Algo binary_search step 159 current loss 3.884856, current_train_items 5120.\n",
      "2023-03-17 10:04:11,790 - root - INFO - Algo binary_search step 160 current loss 1.106748, current_train_items 5152.\n",
      "2023-03-17 10:04:11,838 - root - INFO - Algo binary_search step 161 current loss 2.119090, current_train_items 5184.\n",
      "2023-03-17 10:04:11,910 - root - INFO - Algo binary_search step 162 current loss 2.762265, current_train_items 5216.\n",
      "2023-03-17 10:04:11,995 - root - INFO - Algo binary_search step 163 current loss 3.580486, current_train_items 5248.\n",
      "2023-03-17 10:04:12,107 - root - INFO - Algo binary_search step 164 current loss 4.435327, current_train_items 5280.\n",
      "2023-03-17 10:04:12,123 - root - INFO - Algo binary_search step 165 current loss 2.175022, current_train_items 5312.\n",
      "2023-03-17 10:04:12,158 - root - INFO - Algo binary_search step 166 current loss 1.773128, current_train_items 5344.\n",
      "2023-03-17 10:04:12,231 - root - INFO - Algo binary_search step 167 current loss 3.246308, current_train_items 5376.\n",
      "2023-03-17 10:04:12,315 - root - INFO - Algo binary_search step 168 current loss 4.200159, current_train_items 5408.\n",
      "2023-03-17 10:04:12,422 - root - INFO - Algo binary_search step 169 current loss 4.591747, current_train_items 5440.\n",
      "2023-03-17 10:04:12,434 - root - INFO - Algo binary_search step 170 current loss 1.167424, current_train_items 5472.\n",
      "2023-03-17 10:04:12,467 - root - INFO - Algo binary_search step 171 current loss 2.553184, current_train_items 5504.\n",
      "2023-03-17 10:04:12,535 - root - INFO - Algo binary_search step 172 current loss 4.354285, current_train_items 5536.\n",
      "2023-03-17 10:04:12,619 - root - INFO - Algo binary_search step 173 current loss 3.247192, current_train_items 5568.\n",
      "2023-03-17 10:04:12,731 - root - INFO - Algo binary_search step 174 current loss 4.604048, current_train_items 5600.\n",
      "2023-03-17 10:04:12,745 - root - INFO - Algo binary_search step 175 current loss 0.900145, current_train_items 5632.\n",
      "2023-03-17 10:04:12,780 - root - INFO - Algo binary_search step 176 current loss 1.586785, current_train_items 5664.\n",
      "2023-03-17 10:04:12,864 - root - INFO - Algo binary_search step 177 current loss 3.154390, current_train_items 5696.\n",
      "2023-03-17 10:04:12,950 - root - INFO - Algo binary_search step 178 current loss 3.801716, current_train_items 5728.\n",
      "2023-03-17 10:04:13,062 - root - INFO - Algo binary_search step 179 current loss 3.836099, current_train_items 5760.\n",
      "2023-03-17 10:04:13,075 - root - INFO - Algo binary_search step 180 current loss 0.725305, current_train_items 5792.\n",
      "2023-03-17 10:04:13,110 - root - INFO - Algo binary_search step 181 current loss 1.820703, current_train_items 5824.\n",
      "2023-03-17 10:04:13,181 - root - INFO - Algo binary_search step 182 current loss 2.334854, current_train_items 5856.\n",
      "2023-03-17 10:04:13,266 - root - INFO - Algo binary_search step 183 current loss 2.958549, current_train_items 5888.\n",
      "2023-03-17 10:04:13,375 - root - INFO - Algo binary_search step 184 current loss 3.982739, current_train_items 5920.\n",
      "2023-03-17 10:04:13,388 - root - INFO - Algo binary_search step 185 current loss 1.091475, current_train_items 5952.\n",
      "2023-03-17 10:04:13,423 - root - INFO - Algo binary_search step 186 current loss 1.437797, current_train_items 5984.\n",
      "2023-03-17 10:04:13,495 - root - INFO - Algo binary_search step 187 current loss 2.737100, current_train_items 6016.\n",
      "2023-03-17 10:04:13,580 - root - INFO - Algo binary_search step 188 current loss 3.109632, current_train_items 6048.\n",
      "2023-03-17 10:04:13,688 - root - INFO - Algo binary_search step 189 current loss 3.938480, current_train_items 6080.\n",
      "2023-03-17 10:04:13,703 - root - INFO - Algo binary_search step 190 current loss 0.992864, current_train_items 6112.\n",
      "2023-03-17 10:04:13,737 - root - INFO - Algo binary_search step 191 current loss 1.900551, current_train_items 6144.\n",
      "2023-03-17 10:04:13,819 - root - INFO - Algo binary_search step 192 current loss 2.788839, current_train_items 6176.\n",
      "2023-03-17 10:04:13,902 - root - INFO - Algo binary_search step 193 current loss 2.819403, current_train_items 6208.\n",
      "2023-03-17 10:04:14,016 - root - INFO - Algo binary_search step 194 current loss 4.493928, current_train_items 6240.\n",
      "2023-03-17 10:04:14,031 - root - INFO - Algo binary_search step 195 current loss 0.781704, current_train_items 6272.\n",
      "2023-03-17 10:04:14,066 - root - INFO - Algo binary_search step 196 current loss 1.645558, current_train_items 6304.\n",
      "2023-03-17 10:04:14,138 - root - INFO - Algo binary_search step 197 current loss 2.720039, current_train_items 6336.\n",
      "2023-03-17 10:04:14,226 - root - INFO - Algo binary_search step 198 current loss 3.629237, current_train_items 6368.\n",
      "2023-03-17 10:04:14,362 - root - INFO - Algo binary_search step 199 current loss 3.750721, current_train_items 6400.\n",
      "2023-03-17 10:04:14,376 - root - INFO - Algo binary_search step 200 current loss 0.950012, current_train_items 6432.\n",
      "2023-03-17 10:04:16,740 - root - INFO - (val) algo binary_search step 200: {'return': 0.8681640625, 'score': 0.8681640625, 'examples_seen': 6432, 'step': 200, 'algorithm': 'binary_search'}\n",
      "2023-03-17 10:04:16,740 - root - INFO - Checkpointing best model, best avg val score was 0.776, current avg val score is 0.868, val scores are: binary_search: 0.868\n",
      "2023-03-17 10:04:16,778 - root - INFO - Algo binary_search step 201 current loss 1.686539, current_train_items 6464.\n",
      "2023-03-17 10:04:16,869 - root - INFO - Algo binary_search step 202 current loss 3.170923, current_train_items 6496.\n",
      "2023-03-17 10:04:16,958 - root - INFO - Algo binary_search step 203 current loss 3.413369, current_train_items 6528.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 10:04:17,072 - root - INFO - Algo binary_search step 204 current loss 3.773260, current_train_items 6560.\n",
      "2023-03-17 10:04:17,087 - root - INFO - Algo binary_search step 205 current loss 1.066801, current_train_items 6592.\n",
      "2023-03-17 10:04:17,123 - root - INFO - Algo binary_search step 206 current loss 1.166779, current_train_items 6624.\n",
      "2023-03-17 10:04:17,196 - root - INFO - Algo binary_search step 207 current loss 2.960557, current_train_items 6656.\n",
      "2023-03-17 10:04:17,279 - root - INFO - Algo binary_search step 208 current loss 2.679141, current_train_items 6688.\n",
      "2023-03-17 10:04:17,388 - root - INFO - Algo binary_search step 209 current loss 3.843515, current_train_items 6720.\n",
      "2023-03-17 10:04:17,402 - root - INFO - Algo binary_search step 210 current loss 0.945793, current_train_items 6752.\n",
      "2023-03-17 10:04:17,435 - root - INFO - Algo binary_search step 211 current loss 1.361296, current_train_items 6784.\n",
      "2023-03-17 10:04:17,506 - root - INFO - Algo binary_search step 212 current loss 2.563666, current_train_items 6816.\n",
      "2023-03-17 10:04:17,591 - root - INFO - Algo binary_search step 213 current loss 2.721228, current_train_items 6848.\n",
      "2023-03-17 10:04:17,703 - root - INFO - Algo binary_search step 214 current loss 4.959475, current_train_items 6880.\n",
      "2023-03-17 10:04:17,716 - root - INFO - Algo binary_search step 215 current loss 1.193841, current_train_items 6912.\n",
      "2023-03-17 10:04:17,752 - root - INFO - Algo binary_search step 216 current loss 1.599691, current_train_items 6944.\n",
      "2023-03-17 10:04:17,833 - root - INFO - Algo binary_search step 217 current loss 2.751536, current_train_items 6976.\n",
      "2023-03-17 10:04:17,920 - root - INFO - Algo binary_search step 218 current loss 2.784489, current_train_items 7008.\n",
      "2023-03-17 10:04:18,035 - root - INFO - Algo binary_search step 219 current loss 3.852278, current_train_items 7040.\n",
      "2023-03-17 10:04:18,050 - root - INFO - Algo binary_search step 220 current loss 0.622082, current_train_items 7072.\n",
      "2023-03-17 10:04:18,082 - root - INFO - Algo binary_search step 221 current loss 1.515685, current_train_items 7104.\n",
      "2023-03-17 10:04:18,152 - root - INFO - Algo binary_search step 222 current loss 2.598780, current_train_items 7136.\n",
      "2023-03-17 10:04:18,236 - root - INFO - Algo binary_search step 223 current loss 2.775832, current_train_items 7168.\n",
      "2023-03-17 10:04:18,343 - root - INFO - Algo binary_search step 224 current loss 3.845278, current_train_items 7200.\n",
      "2023-03-17 10:04:18,357 - root - INFO - Algo binary_search step 225 current loss 0.609299, current_train_items 7232.\n",
      "2023-03-17 10:04:18,391 - root - INFO - Algo binary_search step 226 current loss 1.732834, current_train_items 7264.\n",
      "2023-03-17 10:04:18,463 - root - INFO - Algo binary_search step 227 current loss 2.374598, current_train_items 7296.\n",
      "2023-03-17 10:04:18,544 - root - INFO - Algo binary_search step 228 current loss 3.012071, current_train_items 7328.\n",
      "2023-03-17 10:04:18,655 - root - INFO - Algo binary_search step 229 current loss 3.607021, current_train_items 7360.\n",
      "2023-03-17 10:04:18,668 - root - INFO - Algo binary_search step 230 current loss 1.737644, current_train_items 7392.\n",
      "2023-03-17 10:04:18,701 - root - INFO - Algo binary_search step 231 current loss 1.444047, current_train_items 7424.\n",
      "2023-03-17 10:04:18,772 - root - INFO - Algo binary_search step 232 current loss 2.227713, current_train_items 7456.\n",
      "2023-03-17 10:04:18,864 - root - INFO - Algo binary_search step 233 current loss 3.367867, current_train_items 7488.\n",
      "2023-03-17 10:04:18,972 - root - INFO - Algo binary_search step 234 current loss 3.009453, current_train_items 7520.\n",
      "2023-03-17 10:04:18,984 - root - INFO - Algo binary_search step 235 current loss 1.161139, current_train_items 7552.\n",
      "2023-03-17 10:04:19,017 - root - INFO - Algo binary_search step 236 current loss 1.456050, current_train_items 7584.\n",
      "2023-03-17 10:04:19,087 - root - INFO - Algo binary_search step 237 current loss 2.280536, current_train_items 7616.\n",
      "2023-03-17 10:04:19,170 - root - INFO - Algo binary_search step 238 current loss 3.397458, current_train_items 7648.\n",
      "2023-03-17 10:04:19,281 - root - INFO - Algo binary_search step 239 current loss 3.837559, current_train_items 7680.\n",
      "2023-03-17 10:04:19,295 - root - INFO - Algo binary_search step 240 current loss 1.016204, current_train_items 7712.\n",
      "2023-03-17 10:04:19,327 - root - INFO - Algo binary_search step 241 current loss 1.250127, current_train_items 7744.\n",
      "2023-03-17 10:04:19,396 - root - INFO - Algo binary_search step 242 current loss 2.254687, current_train_items 7776.\n",
      "2023-03-17 10:04:19,479 - root - INFO - Algo binary_search step 243 current loss 3.232562, current_train_items 7808.\n",
      "2023-03-17 10:04:19,588 - root - INFO - Algo binary_search step 244 current loss 3.367005, current_train_items 7840.\n",
      "2023-03-17 10:04:19,600 - root - INFO - Algo binary_search step 245 current loss 0.819401, current_train_items 7872.\n",
      "2023-03-17 10:04:19,634 - root - INFO - Algo binary_search step 246 current loss 1.435513, current_train_items 7904.\n",
      "2023-03-17 10:04:19,703 - root - INFO - Algo binary_search step 247 current loss 4.367126, current_train_items 7936.\n",
      "2023-03-17 10:04:19,786 - root - INFO - Algo binary_search step 248 current loss 4.789012, current_train_items 7968.\n",
      "2023-03-17 10:04:19,906 - root - INFO - Algo binary_search step 249 current loss 3.928109, current_train_items 8000.\n",
      "2023-03-17 10:04:19,919 - root - INFO - Algo binary_search step 250 current loss 1.420992, current_train_items 8032.\n",
      "2023-03-17 10:04:22,199 - root - INFO - (val) algo binary_search step 250: {'return': 0.8720703125, 'score': 0.8720703125, 'examples_seen': 8032, 'step': 250, 'algorithm': 'binary_search'}\n",
      "2023-03-17 10:04:22,199 - root - INFO - Checkpointing best model, best avg val score was 0.868, current avg val score is 0.872, val scores are: binary_search: 0.872\n",
      "2023-03-17 10:04:22,237 - root - INFO - Algo binary_search step 251 current loss 1.425484, current_train_items 8064.\n",
      "2023-03-17 10:04:22,306 - root - INFO - Algo binary_search step 252 current loss 2.842857, current_train_items 8096.\n",
      "2023-03-17 10:04:22,391 - root - INFO - Algo binary_search step 253 current loss 3.075301, current_train_items 8128.\n",
      "2023-03-17 10:04:22,498 - root - INFO - Algo binary_search step 254 current loss 3.591016, current_train_items 8160.\n",
      "2023-03-17 10:04:22,512 - root - INFO - Algo binary_search step 255 current loss 0.802679, current_train_items 8192.\n",
      "2023-03-17 10:04:22,545 - root - INFO - Algo binary_search step 256 current loss 1.309154, current_train_items 8224.\n",
      "2023-03-17 10:04:22,614 - root - INFO - Algo binary_search step 257 current loss 3.586528, current_train_items 8256.\n",
      "2023-03-17 10:04:22,698 - root - INFO - Algo binary_search step 258 current loss 4.004695, current_train_items 8288.\n",
      "2023-03-17 10:04:22,815 - root - INFO - Algo binary_search step 259 current loss 4.189387, current_train_items 8320.\n",
      "2023-03-17 10:04:22,829 - root - INFO - Algo binary_search step 260 current loss 0.818023, current_train_items 8352.\n",
      "2023-03-17 10:04:22,863 - root - INFO - Algo binary_search step 261 current loss 1.409073, current_train_items 8384.\n",
      "2023-03-17 10:04:22,933 - root - INFO - Algo binary_search step 262 current loss 2.614942, current_train_items 8416.\n",
      "2023-03-17 10:04:23,015 - root - INFO - Algo binary_search step 263 current loss 2.389190, current_train_items 8448.\n",
      "2023-03-17 10:04:23,125 - root - INFO - Algo binary_search step 264 current loss 3.744948, current_train_items 8480.\n",
      "2023-03-17 10:04:23,139 - root - INFO - Algo binary_search step 265 current loss 0.446194, current_train_items 8512.\n",
      "2023-03-17 10:04:23,172 - root - INFO - Algo binary_search step 266 current loss 1.604389, current_train_items 8544.\n",
      "2023-03-17 10:04:23,243 - root - INFO - Algo binary_search step 267 current loss 2.636773, current_train_items 8576.\n",
      "2023-03-17 10:04:23,326 - root - INFO - Algo binary_search step 268 current loss 2.752425, current_train_items 8608.\n",
      "2023-03-17 10:04:23,436 - root - INFO - Algo binary_search step 269 current loss 3.161356, current_train_items 8640.\n",
      "2023-03-17 10:04:23,451 - root - INFO - Algo binary_search step 270 current loss 0.575846, current_train_items 8672.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 10:04:23,484 - root - INFO - Algo binary_search step 271 current loss 2.417202, current_train_items 8704.\n",
      "2023-03-17 10:04:23,554 - root - INFO - Algo binary_search step 272 current loss 3.040916, current_train_items 8736.\n",
      "2023-03-17 10:04:23,640 - root - INFO - Algo binary_search step 273 current loss 3.035372, current_train_items 8768.\n",
      "2023-03-17 10:04:23,808 - root - INFO - Algo binary_search step 274 current loss 4.233149, current_train_items 8800.\n",
      "2023-03-17 10:04:23,822 - root - INFO - Algo binary_search step 275 current loss 1.457255, current_train_items 8832.\n",
      "2023-03-17 10:04:23,856 - root - INFO - Algo binary_search step 276 current loss 2.291582, current_train_items 8864.\n",
      "2023-03-17 10:04:23,924 - root - INFO - Algo binary_search step 277 current loss 2.449690, current_train_items 8896.\n",
      "2023-03-17 10:04:24,006 - root - INFO - Algo binary_search step 278 current loss 2.946670, current_train_items 8928.\n",
      "2023-03-17 10:04:24,115 - root - INFO - Algo binary_search step 279 current loss 4.320774, current_train_items 8960.\n",
      "2023-03-17 10:04:24,129 - root - INFO - Algo binary_search step 280 current loss 0.599479, current_train_items 8992.\n",
      "2023-03-17 10:04:24,161 - root - INFO - Algo binary_search step 281 current loss 1.152885, current_train_items 9024.\n",
      "2023-03-17 10:04:24,229 - root - INFO - Algo binary_search step 282 current loss 2.981278, current_train_items 9056.\n",
      "2023-03-17 10:04:24,312 - root - INFO - Algo binary_search step 283 current loss 3.140202, current_train_items 9088.\n",
      "2023-03-17 10:04:24,418 - root - INFO - Algo binary_search step 284 current loss 3.772942, current_train_items 9120.\n",
      "2023-03-17 10:04:24,432 - root - INFO - Algo binary_search step 285 current loss 0.704343, current_train_items 9152.\n",
      "2023-03-17 10:04:24,464 - root - INFO - Algo binary_search step 286 current loss 1.086676, current_train_items 9184.\n",
      "2023-03-17 10:04:24,534 - root - INFO - Algo binary_search step 287 current loss 2.880320, current_train_items 9216.\n",
      "2023-03-17 10:04:24,617 - root - INFO - Algo binary_search step 288 current loss 4.010142, current_train_items 9248.\n",
      "2023-03-17 10:04:24,725 - root - INFO - Algo binary_search step 289 current loss 4.299900, current_train_items 9280.\n",
      "2023-03-17 10:04:24,738 - root - INFO - Algo binary_search step 290 current loss 1.158765, current_train_items 9312.\n",
      "2023-03-17 10:04:24,771 - root - INFO - Algo binary_search step 291 current loss 1.248761, current_train_items 9344.\n",
      "2023-03-17 10:04:24,850 - root - INFO - Algo binary_search step 292 current loss 2.323601, current_train_items 9376.\n",
      "2023-03-17 10:04:24,933 - root - INFO - Algo binary_search step 293 current loss 2.591898, current_train_items 9408.\n",
      "2023-03-17 10:04:25,042 - root - INFO - Algo binary_search step 294 current loss 3.710257, current_train_items 9440.\n",
      "2023-03-17 10:04:25,056 - root - INFO - Algo binary_search step 295 current loss 0.534586, current_train_items 9472.\n",
      "2023-03-17 10:04:25,089 - root - INFO - Algo binary_search step 296 current loss 1.289882, current_train_items 9504.\n",
      "2023-03-17 10:04:25,158 - root - INFO - Algo binary_search step 297 current loss 2.050930, current_train_items 9536.\n",
      "2023-03-17 10:04:25,242 - root - INFO - Algo binary_search step 298 current loss 2.849473, current_train_items 9568.\n",
      "2023-03-17 10:04:25,349 - root - INFO - Algo binary_search step 299 current loss 3.792587, current_train_items 9600.\n",
      "2023-03-17 10:04:25,363 - root - INFO - Algo binary_search step 300 current loss 0.924390, current_train_items 9632.\n",
      "2023-03-17 10:04:27,657 - root - INFO - (val) algo binary_search step 300: {'return': 0.894287109375, 'score': 0.894287109375, 'examples_seen': 9632, 'step': 300, 'algorithm': 'binary_search'}\n",
      "2023-03-17 10:04:27,657 - root - INFO - Checkpointing best model, best avg val score was 0.872, current avg val score is 0.894, val scores are: binary_search: 0.894\n",
      "2023-03-17 10:04:27,694 - root - INFO - Algo binary_search step 301 current loss 1.272340, current_train_items 9664.\n",
      "2023-03-17 10:04:27,764 - root - INFO - Algo binary_search step 302 current loss 2.581081, current_train_items 9696.\n",
      "2023-03-17 10:04:27,857 - root - INFO - Algo binary_search step 303 current loss 3.671760, current_train_items 9728.\n",
      "2023-03-17 10:04:27,966 - root - INFO - Algo binary_search step 304 current loss 3.118508, current_train_items 9760.\n",
      "2023-03-17 10:04:27,980 - root - INFO - Algo binary_search step 305 current loss 0.612928, current_train_items 9792.\n",
      "2023-03-17 10:04:28,012 - root - INFO - Algo binary_search step 306 current loss 0.954808, current_train_items 9824.\n",
      "2023-03-17 10:04:28,084 - root - INFO - Algo binary_search step 307 current loss 3.117495, current_train_items 9856.\n",
      "2023-03-17 10:04:28,168 - root - INFO - Algo binary_search step 308 current loss 2.744261, current_train_items 9888.\n",
      "2023-03-17 10:04:28,276 - root - INFO - Algo binary_search step 309 current loss 3.402613, current_train_items 9920.\n",
      "2023-03-17 10:04:28,289 - root - INFO - Algo binary_search step 310 current loss 0.489355, current_train_items 9952.\n",
      "2023-03-17 10:04:28,323 - root - INFO - Algo binary_search step 311 current loss 1.224203, current_train_items 9984.\n",
      "2023-03-17 10:04:28,392 - root - INFO - Algo binary_search step 312 current loss 2.484504, current_train_items 10016.\n",
      "2023-03-17 10:04:28,471 - root - INFO - Algo binary_search step 313 current loss 2.560545, current_train_items 10048.\n",
      "2023-03-17 10:04:28,578 - root - INFO - Algo binary_search step 314 current loss 3.479454, current_train_items 10080.\n",
      "2023-03-17 10:04:28,592 - root - INFO - Algo binary_search step 315 current loss 0.846348, current_train_items 10112.\n",
      "2023-03-17 10:04:28,625 - root - INFO - Algo binary_search step 316 current loss 1.454323, current_train_items 10144.\n",
      "2023-03-17 10:04:28,693 - root - INFO - Algo binary_search step 317 current loss 2.143055, current_train_items 10176.\n",
      "2023-03-17 10:04:28,777 - root - INFO - Algo binary_search step 318 current loss 2.217170, current_train_items 10208.\n",
      "2023-03-17 10:04:28,910 - root - INFO - Algo binary_search step 319 current loss 3.116970, current_train_items 10240.\n",
      "2023-03-17 10:04:28,924 - root - INFO - Algo binary_search step 320 current loss 0.788744, current_train_items 10272.\n",
      "2023-03-17 10:04:28,959 - root - INFO - Algo binary_search step 321 current loss 1.439684, current_train_items 10304.\n",
      "2023-03-17 10:04:29,032 - root - INFO - Algo binary_search step 322 current loss 2.618073, current_train_items 10336.\n",
      "2023-03-17 10:04:29,120 - root - INFO - Algo binary_search step 323 current loss 2.647400, current_train_items 10368.\n",
      "2023-03-17 10:04:29,231 - root - INFO - Algo binary_search step 324 current loss 4.657008, current_train_items 10400.\n",
      "2023-03-17 10:04:29,245 - root - INFO - Algo binary_search step 325 current loss 0.800457, current_train_items 10432.\n",
      "2023-03-17 10:04:29,278 - root - INFO - Algo binary_search step 326 current loss 1.329328, current_train_items 10464.\n",
      "2023-03-17 10:04:29,348 - root - INFO - Algo binary_search step 327 current loss 2.070574, current_train_items 10496.\n",
      "2023-03-17 10:04:29,432 - root - INFO - Algo binary_search step 328 current loss 2.422065, current_train_items 10528.\n",
      "2023-03-17 10:04:29,541 - root - INFO - Algo binary_search step 329 current loss 3.336339, current_train_items 10560.\n",
      "2023-03-17 10:04:29,555 - root - INFO - Algo binary_search step 330 current loss 0.573378, current_train_items 10592.\n",
      "2023-03-17 10:04:29,590 - root - INFO - Algo binary_search step 331 current loss 1.187529, current_train_items 10624.\n",
      "2023-03-17 10:04:29,659 - root - INFO - Algo binary_search step 332 current loss 2.132559, current_train_items 10656.\n",
      "2023-03-17 10:04:29,742 - root - INFO - Algo binary_search step 333 current loss 3.594661, current_train_items 10688.\n",
      "2023-03-17 10:04:29,865 - root - INFO - Algo binary_search step 334 current loss 3.302113, current_train_items 10720.\n",
      "2023-03-17 10:04:29,880 - root - INFO - Algo binary_search step 335 current loss 0.443334, current_train_items 10752.\n",
      "2023-03-17 10:04:29,914 - root - INFO - Algo binary_search step 336 current loss 1.270070, current_train_items 10784.\n",
      "2023-03-17 10:04:29,984 - root - INFO - Algo binary_search step 337 current loss 2.541173, current_train_items 10816.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 10:04:30,068 - root - INFO - Algo binary_search step 338 current loss 3.390095, current_train_items 10848.\n",
      "2023-03-17 10:04:30,175 - root - INFO - Algo binary_search step 339 current loss 3.460988, current_train_items 10880.\n",
      "2023-03-17 10:04:30,190 - root - INFO - Algo binary_search step 340 current loss 0.672797, current_train_items 10912.\n",
      "2023-03-17 10:04:30,224 - root - INFO - Algo binary_search step 341 current loss 1.010101, current_train_items 10944.\n",
      "2023-03-17 10:04:30,296 - root - INFO - Algo binary_search step 342 current loss 2.547439, current_train_items 10976.\n",
      "2023-03-17 10:04:30,381 - root - INFO - Algo binary_search step 343 current loss 2.866984, current_train_items 11008.\n",
      "2023-03-17 10:04:30,492 - root - INFO - Algo binary_search step 344 current loss 4.187172, current_train_items 11040.\n",
      "2023-03-17 10:04:30,505 - root - INFO - Algo binary_search step 345 current loss 0.880275, current_train_items 11072.\n",
      "2023-03-17 10:04:30,539 - root - INFO - Algo binary_search step 346 current loss 0.949287, current_train_items 11104.\n",
      "2023-03-17 10:04:30,608 - root - INFO - Algo binary_search step 347 current loss 2.394782, current_train_items 11136.\n",
      "2023-03-17 10:04:30,691 - root - INFO - Algo binary_search step 348 current loss 2.708486, current_train_items 11168.\n",
      "2023-03-17 10:04:30,807 - root - INFO - Algo binary_search step 349 current loss 3.734303, current_train_items 11200.\n",
      "2023-03-17 10:04:30,821 - root - INFO - Algo binary_search step 350 current loss 0.455311, current_train_items 11232.\n",
      "2023-03-17 10:04:33,243 - root - INFO - (val) algo binary_search step 350: {'return': 0.827880859375, 'score': 0.827880859375, 'examples_seen': 11232, 'step': 350, 'algorithm': 'binary_search'}\n",
      "2023-03-17 10:04:33,247 - root - INFO - Not saving new best model, best avg val score was 0.894, current avg val score is 0.828, val scores are: binary_search: 0.828\n",
      "2023-03-17 10:04:33,310 - root - INFO - Algo binary_search step 351 current loss 1.709751, current_train_items 11264.\n",
      "2023-03-17 10:04:33,401 - root - INFO - Algo binary_search step 352 current loss 2.384865, current_train_items 11296.\n",
      "2023-03-17 10:04:33,478 - root - INFO - Algo binary_search step 353 current loss 2.957500, current_train_items 11328.\n",
      "2023-03-17 10:04:33,581 - root - INFO - Algo binary_search step 354 current loss 4.013824, current_train_items 11360.\n",
      "2023-03-17 10:04:33,593 - root - INFO - Algo binary_search step 355 current loss 0.668015, current_train_items 11392.\n",
      "2023-03-17 10:04:33,625 - root - INFO - Algo binary_search step 356 current loss 1.147211, current_train_items 11424.\n",
      "2023-03-17 10:04:33,689 - root - INFO - Algo binary_search step 357 current loss 2.467341, current_train_items 11456.\n",
      "2023-03-17 10:04:33,796 - root - INFO - Algo binary_search step 358 current loss 2.614265, current_train_items 11488.\n",
      "2023-03-17 10:04:33,907 - root - INFO - Algo binary_search step 359 current loss 3.485384, current_train_items 11520.\n",
      "2023-03-17 10:04:33,919 - root - INFO - Algo binary_search step 360 current loss 0.466782, current_train_items 11552.\n",
      "2023-03-17 10:04:33,951 - root - INFO - Algo binary_search step 361 current loss 0.788162, current_train_items 11584.\n",
      "2023-03-17 10:04:34,016 - root - INFO - Algo binary_search step 362 current loss 2.086673, current_train_items 11616.\n",
      "2023-03-17 10:04:34,094 - root - INFO - Algo binary_search step 363 current loss 2.569208, current_train_items 11648.\n",
      "2023-03-17 10:04:34,197 - root - INFO - Algo binary_search step 364 current loss 3.389122, current_train_items 11680.\n",
      "2023-03-17 10:04:34,210 - root - INFO - Algo binary_search step 365 current loss 0.896866, current_train_items 11712.\n",
      "2023-03-17 10:04:34,242 - root - INFO - Algo binary_search step 366 current loss 1.373491, current_train_items 11744.\n",
      "2023-03-17 10:04:34,306 - root - INFO - Algo binary_search step 367 current loss 1.980014, current_train_items 11776.\n",
      "2023-03-17 10:04:34,393 - root - INFO - Algo binary_search step 368 current loss 2.577447, current_train_items 11808.\n",
      "2023-03-17 10:04:34,497 - root - INFO - Algo binary_search step 369 current loss 4.166950, current_train_items 11840.\n",
      "2023-03-17 10:04:34,510 - root - INFO - Algo binary_search step 370 current loss 0.949189, current_train_items 11872.\n",
      "2023-03-17 10:04:34,542 - root - INFO - Algo binary_search step 371 current loss 1.563179, current_train_items 11904.\n",
      "2023-03-17 10:04:34,611 - root - INFO - Algo binary_search step 372 current loss 2.122108, current_train_items 11936.\n",
      "2023-03-17 10:04:34,694 - root - INFO - Algo binary_search step 373 current loss 2.502245, current_train_items 11968.\n",
      "2023-03-17 10:04:34,810 - root - INFO - Algo binary_search step 374 current loss 3.181267, current_train_items 12000.\n",
      "2023-03-17 10:04:34,826 - root - INFO - Algo binary_search step 375 current loss 1.702943, current_train_items 12032.\n",
      "2023-03-17 10:04:34,858 - root - INFO - Algo binary_search step 376 current loss 1.730635, current_train_items 12064.\n",
      "2023-03-17 10:04:34,927 - root - INFO - Algo binary_search step 377 current loss 2.255633, current_train_items 12096.\n",
      "2023-03-17 10:04:35,010 - root - INFO - Algo binary_search step 378 current loss 2.029723, current_train_items 12128.\n",
      "2023-03-17 10:04:35,119 - root - INFO - Algo binary_search step 379 current loss 3.745956, current_train_items 12160.\n",
      "2023-03-17 10:04:35,133 - root - INFO - Algo binary_search step 380 current loss 0.554983, current_train_items 12192.\n",
      "2023-03-17 10:04:35,168 - root - INFO - Algo binary_search step 381 current loss 0.744391, current_train_items 12224.\n",
      "2023-03-17 10:04:35,235 - root - INFO - Algo binary_search step 382 current loss 1.653020, current_train_items 12256.\n",
      "2023-03-17 10:04:35,318 - root - INFO - Algo binary_search step 383 current loss 3.548548, current_train_items 12288.\n",
      "2023-03-17 10:04:35,426 - root - INFO - Algo binary_search step 384 current loss 4.303178, current_train_items 12320.\n",
      "2023-03-17 10:04:35,445 - root - INFO - Algo binary_search step 385 current loss 0.664286, current_train_items 12352.\n",
      "2023-03-17 10:04:35,482 - root - INFO - Algo binary_search step 386 current loss 1.017617, current_train_items 12384.\n",
      "2023-03-17 10:04:35,551 - root - INFO - Algo binary_search step 387 current loss 1.991581, current_train_items 12416.\n",
      "2023-03-17 10:04:35,634 - root - INFO - Algo binary_search step 388 current loss 2.710509, current_train_items 12448.\n",
      "2023-03-17 10:04:35,742 - root - INFO - Algo binary_search step 389 current loss 3.992339, current_train_items 12480.\n",
      "2023-03-17 10:04:35,755 - root - INFO - Algo binary_search step 390 current loss 0.494485, current_train_items 12512.\n",
      "2023-03-17 10:04:35,788 - root - INFO - Algo binary_search step 391 current loss 0.816846, current_train_items 12544.\n",
      "2023-03-17 10:04:35,870 - root - INFO - Algo binary_search step 392 current loss 2.143023, current_train_items 12576.\n",
      "2023-03-17 10:04:35,952 - root - INFO - Algo binary_search step 393 current loss 2.223865, current_train_items 12608.\n",
      "2023-03-17 10:04:36,067 - root - INFO - Algo binary_search step 394 current loss 3.173728, current_train_items 12640.\n",
      "2023-03-17 10:04:36,081 - root - INFO - Algo binary_search step 395 current loss 0.397523, current_train_items 12672.\n",
      "2023-03-17 10:04:36,119 - root - INFO - Algo binary_search step 396 current loss 1.480301, current_train_items 12704.\n",
      "2023-03-17 10:04:36,190 - root - INFO - Algo binary_search step 397 current loss 3.379024, current_train_items 12736.\n",
      "2023-03-17 10:04:36,277 - root - INFO - Algo binary_search step 398 current loss 4.502143, current_train_items 12768.\n",
      "2023-03-17 10:04:36,392 - root - INFO - Algo binary_search step 399 current loss 3.710671, current_train_items 12800.\n",
      "2023-03-17 10:04:36,407 - root - INFO - Algo binary_search step 400 current loss 1.285754, current_train_items 12832.\n",
      "2023-03-17 10:04:38,805 - root - INFO - (val) algo binary_search step 400: {'return': 0.77392578125, 'score': 0.77392578125, 'examples_seen': 12832, 'step': 400, 'algorithm': 'binary_search'}\n",
      "2023-03-17 10:04:38,807 - root - INFO - Not saving new best model, best avg val score was 0.894, current avg val score is 0.774, val scores are: binary_search: 0.774\n",
      "2023-03-17 10:04:38,843 - root - INFO - Algo binary_search step 401 current loss 1.216059, current_train_items 12864.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 10:04:38,911 - root - INFO - Algo binary_search step 402 current loss 2.297888, current_train_items 12896.\n",
      "2023-03-17 10:04:38,998 - root - INFO - Algo binary_search step 403 current loss 2.882795, current_train_items 12928.\n",
      "2023-03-17 10:04:39,107 - root - INFO - Algo binary_search step 404 current loss 3.857188, current_train_items 12960.\n",
      "2023-03-17 10:04:39,122 - root - INFO - Algo binary_search step 405 current loss 0.466323, current_train_items 12992.\n",
      "2023-03-17 10:04:39,155 - root - INFO - Algo binary_search step 406 current loss 0.688842, current_train_items 13024.\n",
      "2023-03-17 10:04:39,225 - root - INFO - Algo binary_search step 407 current loss 2.567268, current_train_items 13056.\n",
      "2023-03-17 10:04:39,307 - root - INFO - Algo binary_search step 408 current loss 2.775641, current_train_items 13088.\n",
      "2023-03-17 10:04:39,422 - root - INFO - Algo binary_search step 409 current loss 3.407589, current_train_items 13120.\n",
      "2023-03-17 10:04:39,436 - root - INFO - Algo binary_search step 410 current loss 0.482968, current_train_items 13152.\n",
      "2023-03-17 10:04:39,473 - root - INFO - Algo binary_search step 411 current loss 0.952377, current_train_items 13184.\n",
      "2023-03-17 10:04:39,546 - root - INFO - Algo binary_search step 412 current loss 1.407174, current_train_items 13216.\n",
      "2023-03-17 10:04:39,630 - root - INFO - Algo binary_search step 413 current loss 2.365471, current_train_items 13248.\n",
      "2023-03-17 10:04:39,738 - root - INFO - Algo binary_search step 414 current loss 4.550737, current_train_items 13280.\n",
      "2023-03-17 10:04:39,752 - root - INFO - Algo binary_search step 415 current loss 0.579741, current_train_items 13312.\n",
      "2023-03-17 10:04:39,786 - root - INFO - Algo binary_search step 416 current loss 1.041197, current_train_items 13344.\n",
      "2023-03-17 10:04:39,866 - root - INFO - Algo binary_search step 417 current loss 1.818046, current_train_items 13376.\n",
      "2023-03-17 10:04:39,949 - root - INFO - Algo binary_search step 418 current loss 2.972645, current_train_items 13408.\n",
      "2023-03-17 10:04:40,060 - root - INFO - Algo binary_search step 419 current loss 4.206143, current_train_items 13440.\n",
      "2023-03-17 10:04:40,076 - root - INFO - Algo binary_search step 420 current loss 0.203011, current_train_items 13472.\n",
      "2023-03-17 10:04:40,111 - root - INFO - Algo binary_search step 421 current loss 1.083147, current_train_items 13504.\n",
      "2023-03-17 10:04:40,180 - root - INFO - Algo binary_search step 422 current loss 2.022170, current_train_items 13536.\n",
      "2023-03-17 10:04:40,264 - root - INFO - Algo binary_search step 423 current loss 2.170191, current_train_items 13568.\n",
      "2023-03-17 10:04:40,373 - root - INFO - Algo binary_search step 424 current loss 3.137680, current_train_items 13600.\n",
      "2023-03-17 10:04:40,386 - root - INFO - Algo binary_search step 425 current loss 0.372574, current_train_items 13632.\n",
      "2023-03-17 10:04:40,419 - root - INFO - Algo binary_search step 426 current loss 2.674928, current_train_items 13664.\n",
      "2023-03-17 10:04:40,488 - root - INFO - Algo binary_search step 427 current loss 1.962673, current_train_items 13696.\n",
      "2023-03-17 10:04:40,571 - root - INFO - Algo binary_search step 428 current loss 2.519436, current_train_items 13728.\n",
      "2023-03-17 10:04:40,679 - root - INFO - Algo binary_search step 429 current loss 3.295538, current_train_items 13760.\n",
      "2023-03-17 10:04:40,692 - root - INFO - Algo binary_search step 430 current loss 0.441345, current_train_items 13792.\n",
      "2023-03-17 10:04:40,725 - root - INFO - Algo binary_search step 431 current loss 1.544289, current_train_items 13824.\n",
      "2023-03-17 10:04:40,794 - root - INFO - Algo binary_search step 432 current loss 2.974911, current_train_items 13856.\n",
      "2023-03-17 10:04:40,886 - root - INFO - Algo binary_search step 433 current loss 3.051045, current_train_items 13888.\n",
      "2023-03-17 10:04:41,013 - root - INFO - Algo binary_search step 434 current loss 3.333056, current_train_items 13920.\n",
      "2023-03-17 10:04:41,027 - root - INFO - Algo binary_search step 435 current loss 0.567877, current_train_items 13952.\n",
      "2023-03-17 10:04:41,060 - root - INFO - Algo binary_search step 436 current loss 1.203534, current_train_items 13984.\n",
      "2023-03-17 10:04:41,128 - root - INFO - Algo binary_search step 437 current loss 2.856360, current_train_items 14016.\n",
      "2023-03-17 10:04:41,212 - root - INFO - Algo binary_search step 438 current loss 2.771753, current_train_items 14048.\n",
      "2023-03-17 10:04:41,320 - root - INFO - Algo binary_search step 439 current loss 3.446290, current_train_items 14080.\n",
      "2023-03-17 10:04:41,333 - root - INFO - Algo binary_search step 440 current loss 0.609417, current_train_items 14112.\n",
      "2023-03-17 10:04:41,367 - root - INFO - Algo binary_search step 441 current loss 1.645942, current_train_items 14144.\n",
      "2023-03-17 10:04:41,439 - root - INFO - Algo binary_search step 442 current loss 2.591632, current_train_items 14176.\n",
      "2023-03-17 10:04:41,523 - root - INFO - Algo binary_search step 443 current loss 2.581862, current_train_items 14208.\n",
      "2023-03-17 10:04:41,631 - root - INFO - Algo binary_search step 444 current loss 3.346695, current_train_items 14240.\n",
      "2023-03-17 10:04:41,644 - root - INFO - Algo binary_search step 445 current loss 0.255964, current_train_items 14272.\n",
      "2023-03-17 10:04:41,676 - root - INFO - Algo binary_search step 446 current loss 0.830085, current_train_items 14304.\n",
      "2023-03-17 10:04:41,745 - root - INFO - Algo binary_search step 447 current loss 1.723426, current_train_items 14336.\n",
      "2023-03-17 10:04:41,837 - root - INFO - Algo binary_search step 448 current loss 2.121263, current_train_items 14368.\n",
      "2023-03-17 10:04:41,945 - root - INFO - Algo binary_search step 449 current loss 2.898267, current_train_items 14400.\n",
      "2023-03-17 10:04:41,958 - root - INFO - Algo binary_search step 450 current loss 0.284544, current_train_items 14432.\n",
      "2023-03-17 10:04:44,290 - root - INFO - (val) algo binary_search step 450: {'return': 0.919677734375, 'score': 0.919677734375, 'examples_seen': 14432, 'step': 450, 'algorithm': 'binary_search'}\n",
      "2023-03-17 10:04:44,290 - root - INFO - Checkpointing best model, best avg val score was 0.894, current avg val score is 0.920, val scores are: binary_search: 0.920\n",
      "2023-03-17 10:04:44,327 - root - INFO - Algo binary_search step 451 current loss 1.392586, current_train_items 14464.\n",
      "2023-03-17 10:04:44,397 - root - INFO - Algo binary_search step 452 current loss 2.787158, current_train_items 14496.\n",
      "2023-03-17 10:04:44,480 - root - INFO - Algo binary_search step 453 current loss 2.808208, current_train_items 14528.\n",
      "2023-03-17 10:04:44,587 - root - INFO - Algo binary_search step 454 current loss 3.208769, current_train_items 14560.\n",
      "2023-03-17 10:04:44,599 - root - INFO - Algo binary_search step 455 current loss 0.278646, current_train_items 14592.\n",
      "2023-03-17 10:04:44,631 - root - INFO - Algo binary_search step 456 current loss 1.031742, current_train_items 14624.\n",
      "2023-03-17 10:04:44,702 - root - INFO - Algo binary_search step 457 current loss 1.648817, current_train_items 14656.\n",
      "2023-03-17 10:04:44,784 - root - INFO - Algo binary_search step 458 current loss 2.493489, current_train_items 14688.\n",
      "2023-03-17 10:04:44,904 - root - INFO - Algo binary_search step 459 current loss 3.430468, current_train_items 14720.\n",
      "2023-03-17 10:04:44,917 - root - INFO - Algo binary_search step 460 current loss 1.622131, current_train_items 14752.\n",
      "2023-03-17 10:04:44,950 - root - INFO - Algo binary_search step 461 current loss 1.156011, current_train_items 14784.\n",
      "2023-03-17 10:04:45,019 - root - INFO - Algo binary_search step 462 current loss 2.057583, current_train_items 14816.\n",
      "2023-03-17 10:04:45,101 - root - INFO - Algo binary_search step 463 current loss 2.931156, current_train_items 14848.\n",
      "2023-03-17 10:04:45,210 - root - INFO - Algo binary_search step 464 current loss 3.650149, current_train_items 14880.\n",
      "2023-03-17 10:04:45,223 - root - INFO - Algo binary_search step 465 current loss 0.558393, current_train_items 14912.\n",
      "2023-03-17 10:04:45,256 - root - INFO - Algo binary_search step 466 current loss 0.867125, current_train_items 14944.\n",
      "2023-03-17 10:04:45,327 - root - INFO - Algo binary_search step 467 current loss 1.810455, current_train_items 14976.\n",
      "2023-03-17 10:04:45,412 - root - INFO - Algo binary_search step 468 current loss 2.117940, current_train_items 15008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 10:04:45,523 - root - INFO - Algo binary_search step 469 current loss 3.134935, current_train_items 15040.\n",
      "2023-03-17 10:04:45,537 - root - INFO - Algo binary_search step 470 current loss 1.265869, current_train_items 15072.\n",
      "2023-03-17 10:04:45,572 - root - INFO - Algo binary_search step 471 current loss 0.863863, current_train_items 15104.\n",
      "2023-03-17 10:04:45,641 - root - INFO - Algo binary_search step 472 current loss 1.681667, current_train_items 15136.\n",
      "2023-03-17 10:04:45,722 - root - INFO - Algo binary_search step 473 current loss 1.818089, current_train_items 15168.\n",
      "2023-03-17 10:04:45,840 - root - INFO - Algo binary_search step 474 current loss 3.439990, current_train_items 15200.\n",
      "2023-03-17 10:04:45,853 - root - INFO - Algo binary_search step 475 current loss 0.725968, current_train_items 15232.\n",
      "2023-03-17 10:04:45,885 - root - INFO - Algo binary_search step 476 current loss 0.716647, current_train_items 15264.\n",
      "2023-03-17 10:04:45,953 - root - INFO - Algo binary_search step 477 current loss 2.583241, current_train_items 15296.\n",
      "2023-03-17 10:04:46,036 - root - INFO - Algo binary_search step 478 current loss 2.547099, current_train_items 15328.\n",
      "2023-03-17 10:04:46,144 - root - INFO - Algo binary_search step 479 current loss 3.552814, current_train_items 15360.\n",
      "2023-03-17 10:04:46,157 - root - INFO - Algo binary_search step 480 current loss 1.203123, current_train_items 15392.\n",
      "2023-03-17 10:04:46,189 - root - INFO - Algo binary_search step 481 current loss 0.939451, current_train_items 15424.\n",
      "2023-03-17 10:04:46,257 - root - INFO - Algo binary_search step 482 current loss 2.026075, current_train_items 15456.\n",
      "2023-03-17 10:04:46,339 - root - INFO - Algo binary_search step 483 current loss 2.419329, current_train_items 15488.\n",
      "2023-03-17 10:04:46,446 - root - INFO - Algo binary_search step 484 current loss 3.448836, current_train_items 15520.\n",
      "2023-03-17 10:04:46,460 - root - INFO - Algo binary_search step 485 current loss 0.963034, current_train_items 15552.\n",
      "2023-03-17 10:04:46,492 - root - INFO - Algo binary_search step 486 current loss 0.728987, current_train_items 15584.\n",
      "2023-03-17 10:04:46,561 - root - INFO - Algo binary_search step 487 current loss 1.853698, current_train_items 15616.\n",
      "2023-03-17 10:04:46,643 - root - INFO - Algo binary_search step 488 current loss 2.666376, current_train_items 15648.\n",
      "2023-03-17 10:04:46,749 - root - INFO - Algo binary_search step 489 current loss 3.054800, current_train_items 15680.\n",
      "2023-03-17 10:04:46,771 - root - INFO - Algo binary_search step 490 current loss 0.690278, current_train_items 15712.\n",
      "2023-03-17 10:04:46,804 - root - INFO - Algo binary_search step 491 current loss 0.886544, current_train_items 15744.\n",
      "2023-03-17 10:04:46,873 - root - INFO - Algo binary_search step 492 current loss 1.965678, current_train_items 15776.\n",
      "2023-03-17 10:04:46,957 - root - INFO - Algo binary_search step 493 current loss 2.200463, current_train_items 15808.\n",
      "2023-03-17 10:04:47,065 - root - INFO - Algo binary_search step 494 current loss 3.213594, current_train_items 15840.\n",
      "2023-03-17 10:04:47,079 - root - INFO - Algo binary_search step 495 current loss 0.720341, current_train_items 15872.\n",
      "2023-03-17 10:04:47,112 - root - INFO - Algo binary_search step 496 current loss 1.787330, current_train_items 15904.\n",
      "2023-03-17 10:04:47,180 - root - INFO - Algo binary_search step 497 current loss 2.124230, current_train_items 15936.\n",
      "2023-03-17 10:04:47,264 - root - INFO - Algo binary_search step 498 current loss 2.629642, current_train_items 15968.\n",
      "2023-03-17 10:04:47,372 - root - INFO - Algo binary_search step 499 current loss 3.274502, current_train_items 16000.\n",
      "2023-03-17 10:04:47,373 - root - INFO - Restoring best model from checkpoint...\n"
     ]
    }
   ],
   "source": [
    "# Training loop.\n",
    "best_score = -1.0\n",
    "current_train_items = [0] * len(FLAGS.algorithms)\n",
    "step = 0\n",
    "next_eval = 0\n",
    "# Make sure scores improve on first step, but not overcome best score\n",
    "# until all algos have had at least one evaluation.\n",
    "val_scores = [-99999.9] * len(FLAGS.algorithms)\n",
    "length_idx = 0\n",
    "\n",
    "while step < FLAGS.train_steps:\n",
    "    feedback_list = [next(t) for t in train_samplers]\n",
    "\n",
    "    # Initialize model.\n",
    "    if step == 0:\n",
    "        all_features = [f.features for f in feedback_list]\n",
    "        if FLAGS.chunked_training:\n",
    "            # We need to initialize the model with samples of all lengths for\n",
    "            # all algorithms. Also, we need to make sure that the order of these\n",
    "            # sample sizes is the same as the order of the actual training sizes.\n",
    "            all_length_features = [all_features] + [\n",
    "                [next(t).features for t in train_samplers]\n",
    "                for _ in range(len(train_lengths))]\n",
    "            train_model.init(all_length_features[:-1], FLAGS.seed + 1)\n",
    "        else:\n",
    "            train_model.init(all_features, FLAGS.seed + 1)\n",
    "\n",
    "    # Training step.\n",
    "    for algo_idx in range(len(train_samplers)):\n",
    "        feedback = feedback_list[algo_idx]\n",
    "        rng_key, new_rng_key = jax.random.split(rng_key)\n",
    "        if FLAGS.chunked_training:\n",
    "            # In chunked training, we must indicate which training length we are\n",
    "            # using, so the model uses the correct state.\n",
    "            length_and_algo_idx = (length_idx, algo_idx)\n",
    "        else:\n",
    "            # In non-chunked training, all training lengths can be treated equally,\n",
    "            # since there is no state to maintain between batches.\n",
    "            length_and_algo_idx = algo_idx\n",
    "        cur_loss = train_model.feedback(\n",
    "            rng_key, feedback, length_and_algo_idx)\n",
    "        rng_key = new_rng_key\n",
    "\n",
    "        if FLAGS.chunked_training:\n",
    "            examples_in_chunk = np.sum(feedback.features.is_last).item()\n",
    "        else:\n",
    "            examples_in_chunk = len(feedback.features.lengths)\n",
    "        current_train_items[algo_idx] += examples_in_chunk\n",
    "        logging.info('Algo %s step %i current loss %f, current_train_items %i.',\n",
    "                     FLAGS.algorithms[algo_idx], step,\n",
    "                     cur_loss, current_train_items[algo_idx])\n",
    "\n",
    "    # Periodically evaluate model\n",
    "    if step >= next_eval:\n",
    "        eval_model.params = train_model.params\n",
    "        for algo_idx in range(len(train_samplers)):\n",
    "            common_extras = {'examples_seen': current_train_items[algo_idx],\n",
    "                             'step': step,\n",
    "                             'algorithm': FLAGS.algorithms[algo_idx]}\n",
    "\n",
    "            # Validation info.\n",
    "            new_rng_key, rng_key = jax.random.split(rng_key)\n",
    "            val_stats = collect_and_eval(\n",
    "                val_samplers[algo_idx],\n",
    "                functools.partial(eval_model.predict,\n",
    "                                  algorithm_index=algo_idx),\n",
    "                val_sample_counts[algo_idx],\n",
    "                new_rng_key,\n",
    "                extras=common_extras)\n",
    "            logging.info('(val) algo %s step %d: %s',\n",
    "                         FLAGS.algorithms[algo_idx], step, val_stats)\n",
    "            val_scores[algo_idx] = val_stats['score']\n",
    "\n",
    "        next_eval += FLAGS.eval_every\n",
    "\n",
    "        # If best total score, update best checkpoint.\n",
    "        # Also save a best checkpoint on the first step.\n",
    "        msg = (f'best avg val score was '\n",
    "               f'{best_score/len(FLAGS.algorithms):.3f}, '\n",
    "               f'current avg val score is {np.mean(val_scores):.3f}, '\n",
    "               f'val scores are: ')\n",
    "        msg += ', '.join(\n",
    "            ['%s: %.3f' % (x, y) for (x, y) in zip(FLAGS.algorithms, val_scores)])\n",
    "        if (sum(val_scores) > best_score) or step == 0:\n",
    "            best_score = sum(val_scores)\n",
    "            logging.info('Checkpointing best model, %s', msg)\n",
    "            train_model.save_model('best.pkl')\n",
    "        else:\n",
    "            logging.info('Not saving new best model, %s', msg)\n",
    "\n",
    "    step += 1\n",
    "    length_idx = (length_idx + 1) % len(train_lengths)\n",
    "\n",
    "logging.info('Restoring best model from checkpoint...')\n",
    "eval_model.restore_model('best.pkl', only_load_processor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7414d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def restore_model(model, file_name):\n",
    "    \"\"\"Restore model from `file_name`.\"\"\"\n",
    "    with open(file_name, 'rb') as f:\n",
    "        restored_state = pickle.load(f)\n",
    "        restored_params = restored_state['params']\n",
    "        model.params = hk.data_structures.merge(restored_params)\n",
    "        model.opt_state = restored_state['opt_state']\n",
    "\n",
    "def save_model(model, file_name):\n",
    "    \"\"\"Save model (processor weights only) to `file_name`.\"\"\"\n",
    "    to_save = {'params': model.params, 'opt_state': model.opt_state}\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(to_save, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4c11566",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(eval_model, 'eval_model_1e-3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb459f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_model(eval_model, 'eval_model_asdf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1aed2485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'return': 0.912353515625, 'score': 0.912353515625}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_idx = 0\n",
    "common_extras = {}\n",
    "\n",
    "new_rng_key, rng_key = jax.random.split(rng_key)\n",
    "val_stats = collect_and_eval(\n",
    "    val_samplers[algo_idx],\n",
    "    functools.partial(eval_model.predict, algorithm_index=algo_idx),\n",
    "    val_sample_counts[algo_idx],\n",
    "    new_rng_key,\n",
    "    extras=common_extras)\n",
    "\n",
    "val_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2b7510d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'return': 0.70068359375, 'score': 0.70068359375}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rng_key, rng_key = jax.random.split(rng_key)\n",
    "test_stats = collect_and_eval(\n",
    "    test_samplers[algo_idx],\n",
    "    functools.partial(eval_model.predict, algorithm_index=algo_idx),\n",
    "    test_sample_counts[algo_idx],\n",
    "    new_rng_key,\n",
    "    extras=common_extras)\n",
    "\n",
    "test_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00b5f2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback = next(val_samplers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6eede5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_asdict',\n",
       " '_field_defaults',\n",
       " '_fields',\n",
       " '_make',\n",
       " '_replace',\n",
       " 'count',\n",
       " 'features',\n",
       " 'index',\n",
       " 'outputs']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: x[:2] != '__', dir(feedback)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa70e0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_asdict',\n",
       " '_field_defaults',\n",
       " '_fields',\n",
       " '_make',\n",
       " '_replace',\n",
       " 'count',\n",
       " 'hints',\n",
       " 'index',\n",
       " 'inputs',\n",
       " 'lengths']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: x[:2] != '__', dir(feedback.features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87285504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Features(inputs=(DataPoint(name=\"pos\",\tlocation=node,\ttype=scalar,\tdata=Array(32, 16)), DataPoint(name=\"key\",\tlocation=node,\ttype=scalar,\tdata=Array(32, 16)), DataPoint(name=\"target\",\tlocation=graph,\ttype=scalar,\tdata=Array(32,)), DataPoint(name=\"pred\",\tlocation=node,\ttype=pointer,\tdata=Array(32, 16))), hints=(DataPoint(name=\"low\",\tlocation=node,\ttype=mask_one,\tdata=Array(5, 32, 16)), DataPoint(name=\"high\",\tlocation=node,\ttype=mask_one,\tdata=Array(5, 32, 16)), DataPoint(name=\"mid\",\tlocation=node,\ttype=mask_one,\tdata=Array(5, 32, 16))), lengths=array([5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9cd67ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DataPoint(name=\"pos\",\tlocation=node,\ttype=scalar,\tdata=Array(32, 16)),\n",
       " DataPoint(name=\"key\",\tlocation=node,\ttype=scalar,\tdata=Array(32, 16)),\n",
       " DataPoint(name=\"target\",\tlocation=graph,\ttype=scalar,\tdata=Array(32,)),\n",
       " DataPoint(name=\"pred\",\tlocation=node,\ttype=pointer,\tdata=Array(32, 16)))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback.features.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03d5c9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14317903, 0.07972956, 0.67909305, 0.98567252, 0.93329147,\n",
       "       0.28345592, 0.43966783, 0.07153851, 0.12399225, 0.76594674,\n",
       "       0.36091068, 0.97857869, 0.28576997, 0.40300221, 0.26544856,\n",
       "       0.52667835, 0.12452213, 0.07972956, 0.93578709, 0.51574709,\n",
       "       0.3870473 , 0.58158791, 0.68471948, 0.92190682, 0.18154095,\n",
       "       0.38265265, 0.65144341, 0.42893379, 0.05218584, 0.86252671,\n",
       "       0.059794  , 0.44887807])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback.features.inputs[2].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19b9ee9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DataPoint(name=\"low\",\tlocation=node,\ttype=mask_one,\tdata=Array(5, 32, 16)),\n",
       " DataPoint(name=\"high\",\tlocation=node,\ttype=mask_one,\tdata=Array(5, 32, 16)),\n",
       " DataPoint(name=\"mid\",\tlocation=node,\ttype=mask_one,\tdata=Array(5, 32, 16)))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback.features.hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b088c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(feedback.features.inputs[0].data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7396caeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]),\n",
       " array([ 2,  1, 11, 15, 14,  3,  9,  0,  3, 11,  5, 15,  6,  5,  6,  6,  3,\n",
       "         1, 14,  9,  7, 12, 10, 13,  2,  5,  9, 10,  1, 14,  1,  8]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(feedback.outputs[0].data == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb04a573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample_counts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "189e76f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "32\n",
      "64\n",
      "96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(128, 6, 64, 64, 128)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rng_key, rng_key = jax.random.split(rng_key)\n",
    "batched_msgs = get_msgs(\n",
    "    test_samplers[0],\n",
    "    functools.partial(eval_model.predict, algorithm_index=0),\n",
    "#     test_sample_counts[0],  # EXPLODING MEMORY LOL\n",
    "    32*4,\n",
    "    new_rng_key,\n",
    "    0.01)\n",
    "\n",
    "batched_msgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1bec654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'binary_search_val_msgs.pkl'\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(msgs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e9a3dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1610612912"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(batched_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f58ca72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample_counts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6bd81bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.906304"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(batched_msgs) / 1000000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
