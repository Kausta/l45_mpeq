{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3acdd8b",
   "metadata": {},
   "source": [
    "# Run training of CLRS algorithm\n",
    "\n",
    "Copied main function from clrs_train.py. Helper functions are located in clrs_train_funcs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b11198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "import shutil\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import logging\n",
    "import clrs\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "import haiku as hk\n",
    "\n",
    "import model\n",
    "import flags\n",
    "from clrs_train_funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "771141dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa63cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch = logging.StreamHandler()\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b412628f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 10:55:41,982 - jax._src.lib.xla_bridge - INFO - Remote TPU is not linked into jax; skipping remote TPU.\n",
      "2023-03-23 10:55:41,982 - jax._src.lib.xla_bridge - INFO - Unable to initialize backend 'tpu_driver': Could not initialize backend 'tpu_driver'\n",
      "2023-03-23 10:55:41,983 - jax._src.lib.xla_bridge - INFO - Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "2023-03-23 10:55:41,985 - jax._src.lib.xla_bridge - INFO - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "2023-03-23 10:55:41,986 - jax._src.lib.xla_bridge - INFO - Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'\n",
      "2023-03-23 10:55:41,990 - jax._src.lib.xla_bridge - INFO - Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.hint_mode == 'encoded_decoded':\n",
    "    encode_hints = True\n",
    "    decode_hints = True\n",
    "elif FLAGS.hint_mode == 'decoded_only':\n",
    "    encode_hints = False\n",
    "    decode_hints = True\n",
    "elif FLAGS.hint_mode == 'none':\n",
    "    encode_hints = False\n",
    "    decode_hints = False\n",
    "else:\n",
    "    raise ValueError(\n",
    "        'Hint mode not in {encoded_decoded, decoded_only, none}.')\n",
    "\n",
    "train_lengths = [int(x) for x in FLAGS.train_lengths]\n",
    "\n",
    "rng = np.random.RandomState(FLAGS.seed)\n",
    "rng_key = jax.random.PRNGKey(rng.randint(2**32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a79e1217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 10:55:42,032 - root - INFO - Creating samplers for algo binary_search\n",
      "2023-03-23 10:55:42,033 - absl - WARNING - Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.SearchSampler'>\n",
      "2023-03-23 10:55:42,034 - absl - WARNING - Sampling dataset on-the-fly, unlimited samples.\n",
      "2023-03-23 10:55:42,146 - absl - WARNING - Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.SearchSampler'>\n",
      "2023-03-23 10:55:42,147 - absl - WARNING - Sampling dataset on-the-fly, unlimited samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 10:55:42,266 - absl - WARNING - Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.SearchSampler'>\n",
      "2023-03-23 10:55:42,266 - absl - WARNING - Sampling dataset on-the-fly, unlimited samples.\n",
      "2023-03-23 10:55:42,387 - absl - WARNING - Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.SearchSampler'>\n",
      "2023-03-23 10:55:42,388 - absl - WARNING - Sampling dataset on-the-fly, unlimited samples.\n",
      "2023-03-23 10:55:42,510 - absl - WARNING - Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.SearchSampler'>\n",
      "2023-03-23 10:55:42,511 - absl - WARNING - Sampling dataset on-the-fly, unlimited samples.\n",
      "2023-03-23 10:55:42,655 - absl - WARNING - Ignoring kwargs {'p', 'length_needle'} when building sampler class <class 'clrs._src.samplers.SearchSampler'>\n",
      "2023-03-23 10:55:42,655 - absl - INFO - Creating a dataset with 4096 samples.\n",
      "2023-03-23 10:55:42,871 - absl - INFO - 1000 samples created\n",
      "2023-03-23 10:55:42,997 - absl - INFO - 2000 samples created\n",
      "2023-03-23 10:55:43,123 - absl - INFO - 3000 samples created\n",
      "2023-03-23 10:55:43,246 - absl - INFO - 4000 samples created\n",
      "2023-03-23 10:55:43,325 - root - INFO - Dataset found at /tmp/CLRS30/CLRS30_v1.0.0. Skipping download.\n",
      "2023-03-23 10:55:43,326 - absl - INFO - Load dataset info from /tmp/CLRS30/CLRS30_v1.0.0/clrs_dataset/binary_search_test/1.0.0\n",
      "2023-03-23 10:55:43,330 - absl - INFO - Load dataset info from /tmp/CLRS30/CLRS30_v1.0.0/clrs_dataset/binary_search_test/1.0.0\n",
      "2023-03-23 10:55:43,331 - absl - INFO - Reusing dataset clrs_dataset (/tmp/CLRS30/CLRS30_v1.0.0/clrs_dataset/binary_search_test/1.0.0)\n",
      "2023-03-23 10:55:43,332 - absl - INFO - Constructing tf.data.Dataset clrs_dataset for split test, from /tmp/CLRS30/CLRS30_v1.0.0/clrs_dataset/binary_search_test/1.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/james/.pyenv/versions/3.9.16/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 10:55:43,387 - tensorflow - WARNING - From /Users/james/.pyenv/versions/3.9.16/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "2023-03-23 10:55:43.520796: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# Create samplers\n",
    "(train_samplers,\n",
    " val_samplers, val_sample_counts,\n",
    " test_samplers, test_sample_counts,\n",
    " spec_list) = create_samplers(rng, train_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e70415b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.l1_weight = 0.001\n",
    "FLAGS.train_steps = 1000\n",
    "FLAGS.hidden_size = 32\n",
    "FLAGS.msg_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d6249f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLAGS.hidden_size = 8\n",
    "# FLAGS.algorithms = ['dijkstra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3080605",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor_factory = model.get_processor_factory(\n",
    "    FLAGS.processor_type,\n",
    "    use_ln=FLAGS.use_ln,\n",
    "    nb_triplet_fts=FLAGS.nb_triplet_fts,\n",
    "    nb_heads=FLAGS.nb_heads\n",
    ")\n",
    "model_params = dict(\n",
    "    processor_factory=processor_factory,\n",
    "    hidden_dim=FLAGS.hidden_size,\n",
    "    msg_dim=FLAGS.msg_size,\n",
    "    encode_hints=encode_hints,\n",
    "    decode_hints=decode_hints,\n",
    "    encoder_init=FLAGS.encoder_init,\n",
    "    use_lstm=FLAGS.use_lstm,\n",
    "    learning_rate=FLAGS.learning_rate,\n",
    "    grad_clip_max_norm=FLAGS.grad_clip_max_norm,\n",
    "    checkpoint_path=FLAGS.checkpoint_path,\n",
    "    freeze_processor=FLAGS.freeze_processor,\n",
    "    dropout_prob=FLAGS.dropout_prob,\n",
    "    hint_teacher_forcing=FLAGS.hint_teacher_forcing,\n",
    "    hint_repred_mode=FLAGS.hint_repred_mode,\n",
    "    nb_msg_passing_steps=FLAGS.nb_msg_passing_steps,\n",
    "    l1_weight=FLAGS.l1_weight\n",
    ")\n",
    "\n",
    "eval_model = model.BaselineMsgModel(\n",
    "    spec=spec_list,\n",
    "    dummy_trajectory=[next(t) for t in val_samplers],\n",
    "    **model_params\n",
    ")\n",
    "# # we will never used chunked training\n",
    "# if FLAGS.chunked_training:\n",
    "#     train_model = clrs.models.BaselineModelChunked(\n",
    "#         spec=spec_list,\n",
    "#         dummy_trajectory=[next(t) for t in train_samplers],\n",
    "#         **model_params\n",
    "#     )\n",
    "# else:\n",
    "#     train_model = eval_model\n",
    "train_model = eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6738fd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 10:55:47,758 - root - INFO - Algo binary_search step 0 current loss 6.239127, current_train_items 32.\n",
      "2023-03-23 10:55:50,400 - root - INFO - (val) algo binary_search step 0: {'return': 0.090087890625, 'score': 0.090087890625, 'examples_seen': 32, 'step': 0, 'algorithm': 'binary_search'}\n",
      "2023-03-23 10:55:50,400 - root - INFO - Checkpointing best model, best avg val score was -1.000, current avg val score is 0.090, val scores are: binary_search: 0.090\n",
      "2023-03-23 10:55:53,668 - root - INFO - Algo binary_search step 1 current loss 8.979127, current_train_items 64.\n",
      "2023-03-23 10:55:56,864 - root - INFO - Algo binary_search step 2 current loss 11.884584, current_train_items 96.\n",
      "2023-03-23 10:56:00,204 - root - INFO - Algo binary_search step 3 current loss 13.249916, current_train_items 128.\n",
      "2023-03-23 10:56:03,675 - root - INFO - Algo binary_search step 4 current loss 14.738131, current_train_items 160.\n",
      "2023-03-23 10:56:03,687 - root - INFO - Algo binary_search step 5 current loss 5.610897, current_train_items 192.\n",
      "2023-03-23 10:56:03,719 - root - INFO - Algo binary_search step 6 current loss 7.772156, current_train_items 224.\n",
      "2023-03-23 10:56:03,748 - root - INFO - Algo binary_search step 7 current loss 10.536375, current_train_items 256.\n",
      "2023-03-23 10:56:03,779 - root - INFO - Algo binary_search step 8 current loss 11.548616, current_train_items 288.\n",
      "2023-03-23 10:56:03,817 - root - INFO - Algo binary_search step 9 current loss 12.809106, current_train_items 320.\n",
      "2023-03-23 10:56:03,826 - root - INFO - Algo binary_search step 10 current loss 5.310874, current_train_items 352.\n",
      "2023-03-23 10:56:03,846 - root - INFO - Algo binary_search step 11 current loss 7.409027, current_train_items 384.\n",
      "2023-03-23 10:56:03,875 - root - INFO - Algo binary_search step 12 current loss 9.911168, current_train_items 416.\n",
      "2023-03-23 10:56:03,909 - root - INFO - Algo binary_search step 13 current loss 10.700902, current_train_items 448.\n",
      "2023-03-23 10:56:03,994 - root - INFO - Algo binary_search step 14 current loss 11.994863, current_train_items 480.\n",
      "2023-03-23 10:56:04,005 - root - INFO - Algo binary_search step 15 current loss 5.085104, current_train_items 512.\n",
      "2023-03-23 10:56:04,027 - root - INFO - Algo binary_search step 16 current loss 7.033742, current_train_items 544.\n",
      "2023-03-23 10:56:04,056 - root - INFO - Algo binary_search step 17 current loss 9.495680, current_train_items 576.\n",
      "2023-03-23 10:56:04,091 - root - INFO - Algo binary_search step 18 current loss 10.037456, current_train_items 608.\n",
      "2023-03-23 10:56:04,133 - root - INFO - Algo binary_search step 19 current loss 11.309295, current_train_items 640.\n",
      "2023-03-23 10:56:04,142 - root - INFO - Algo binary_search step 20 current loss 5.103077, current_train_items 672.\n",
      "2023-03-23 10:56:04,162 - root - INFO - Algo binary_search step 21 current loss 6.785374, current_train_items 704.\n",
      "2023-03-23 10:56:04,190 - root - INFO - Algo binary_search step 22 current loss 9.001040, current_train_items 736.\n",
      "2023-03-23 10:56:04,223 - root - INFO - Algo binary_search step 23 current loss 9.593708, current_train_items 768.\n",
      "2023-03-23 10:56:04,264 - root - INFO - Algo binary_search step 24 current loss 10.759487, current_train_items 800.\n",
      "2023-03-23 10:56:04,272 - root - INFO - Algo binary_search step 25 current loss 4.604852, current_train_items 832.\n",
      "2023-03-23 10:56:04,291 - root - INFO - Algo binary_search step 26 current loss 6.614614, current_train_items 864.\n",
      "2023-03-23 10:56:04,320 - root - INFO - Algo binary_search step 27 current loss 8.350425, current_train_items 896.\n",
      "2023-03-23 10:56:04,353 - root - INFO - Algo binary_search step 28 current loss 9.082911, current_train_items 928.\n",
      "2023-03-23 10:56:04,394 - root - INFO - Algo binary_search step 29 current loss 10.463020, current_train_items 960.\n",
      "2023-03-23 10:56:04,403 - root - INFO - Algo binary_search step 30 current loss 4.517388, current_train_items 992.\n",
      "2023-03-23 10:56:04,422 - root - INFO - Algo binary_search step 31 current loss 6.418639, current_train_items 1024.\n",
      "2023-03-23 10:56:04,449 - root - INFO - Algo binary_search step 32 current loss 7.937282, current_train_items 1056.\n",
      "2023-03-23 10:56:04,482 - root - INFO - Algo binary_search step 33 current loss 8.934036, current_train_items 1088.\n",
      "2023-03-23 10:56:04,521 - root - INFO - Algo binary_search step 34 current loss 10.010326, current_train_items 1120.\n",
      "2023-03-23 10:56:04,530 - root - INFO - Algo binary_search step 35 current loss 4.176278, current_train_items 1152.\n",
      "2023-03-23 10:56:04,547 - root - INFO - Algo binary_search step 36 current loss 6.285445, current_train_items 1184.\n",
      "2023-03-23 10:56:04,575 - root - INFO - Algo binary_search step 37 current loss 7.498308, current_train_items 1216.\n",
      "2023-03-23 10:56:04,608 - root - INFO - Algo binary_search step 38 current loss 8.043008, current_train_items 1248.\n",
      "2023-03-23 10:56:04,647 - root - INFO - Algo binary_search step 39 current loss 9.680228, current_train_items 1280.\n",
      "2023-03-23 10:56:04,656 - root - INFO - Algo binary_search step 40 current loss 3.939330, current_train_items 1312.\n",
      "2023-03-23 10:56:04,673 - root - INFO - Algo binary_search step 41 current loss 5.914227, current_train_items 1344.\n",
      "2023-03-23 10:56:04,703 - root - INFO - Algo binary_search step 42 current loss 7.362168, current_train_items 1376.\n",
      "2023-03-23 10:56:04,736 - root - INFO - Algo binary_search step 43 current loss 8.017579, current_train_items 1408.\n",
      "2023-03-23 10:56:04,786 - root - INFO - Algo binary_search step 44 current loss 9.026596, current_train_items 1440.\n",
      "2023-03-23 10:56:04,795 - root - INFO - Algo binary_search step 45 current loss 3.538189, current_train_items 1472.\n",
      "2023-03-23 10:56:04,813 - root - INFO - Algo binary_search step 46 current loss 5.765092, current_train_items 1504.\n",
      "2023-03-23 10:56:04,840 - root - INFO - Algo binary_search step 47 current loss 7.116833, current_train_items 1536.\n",
      "2023-03-23 10:56:04,871 - root - INFO - Algo binary_search step 48 current loss 7.354349, current_train_items 1568.\n",
      "2023-03-23 10:56:04,912 - root - INFO - Algo binary_search step 49 current loss 8.776778, current_train_items 1600.\n",
      "2023-03-23 10:56:04,920 - root - INFO - Algo binary_search step 50 current loss 3.440265, current_train_items 1632.\n",
      "2023-03-23 10:56:07,605 - root - INFO - (val) algo binary_search step 50: {'return': 0.217529296875, 'score': 0.217529296875, 'examples_seen': 1632, 'step': 50, 'algorithm': 'binary_search'}\n",
      "2023-03-23 10:56:07,605 - root - INFO - Checkpointing best model, best avg val score was 0.090, current avg val score is 0.218, val scores are: binary_search: 0.218\n",
      "2023-03-23 10:56:07,629 - root - INFO - Algo binary_search step 51 current loss 5.306061, current_train_items 1664.\n",
      "2023-03-23 10:56:07,666 - root - INFO - Algo binary_search step 52 current loss 6.969770, current_train_items 1696.\n",
      "2023-03-23 10:56:07,708 - root - INFO - Algo binary_search step 53 current loss 7.542310, current_train_items 1728.\n",
      "2023-03-23 10:56:07,767 - root - INFO - Algo binary_search step 54 current loss 8.451653, current_train_items 1760.\n",
      "2023-03-23 10:56:07,794 - root - INFO - Algo binary_search step 55 current loss 3.814070, current_train_items 1792.\n",
      "2023-03-23 10:56:07,816 - root - INFO - Algo binary_search step 56 current loss 5.239847, current_train_items 1824.\n",
      "2023-03-23 10:56:07,845 - root - INFO - Algo binary_search step 57 current loss 7.436653, current_train_items 1856.\n",
      "2023-03-23 10:56:07,879 - root - INFO - Algo binary_search step 58 current loss 8.170677, current_train_items 1888.\n",
      "2023-03-23 10:56:07,919 - root - INFO - Algo binary_search step 59 current loss 8.647817, current_train_items 1920.\n",
      "2023-03-23 10:56:07,926 - root - INFO - Algo binary_search step 60 current loss 3.141234, current_train_items 1952.\n",
      "2023-03-23 10:56:07,943 - root - INFO - Algo binary_search step 61 current loss 4.677692, current_train_items 1984.\n",
      "2023-03-23 10:56:07,970 - root - INFO - Algo binary_search step 62 current loss 6.683660, current_train_items 2016.\n",
      "2023-03-23 10:56:08,001 - root - INFO - Algo binary_search step 63 current loss 7.470469, current_train_items 2048.\n",
      "2023-03-23 10:56:08,039 - root - INFO - Algo binary_search step 64 current loss 8.315493, current_train_items 2080.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 10:56:08,047 - root - INFO - Algo binary_search step 65 current loss 3.129440, current_train_items 2112.\n",
      "2023-03-23 10:56:08,064 - root - INFO - Algo binary_search step 66 current loss 5.345869, current_train_items 2144.\n",
      "2023-03-23 10:56:08,091 - root - INFO - Algo binary_search step 67 current loss 6.262424, current_train_items 2176.\n",
      "2023-03-23 10:56:08,122 - root - INFO - Algo binary_search step 68 current loss 6.721148, current_train_items 2208.\n",
      "2023-03-23 10:56:08,165 - root - INFO - Algo binary_search step 69 current loss 7.544115, current_train_items 2240.\n",
      "2023-03-23 10:56:08,174 - root - INFO - Algo binary_search step 70 current loss 3.016263, current_train_items 2272.\n",
      "2023-03-23 10:56:08,191 - root - INFO - Algo binary_search step 71 current loss 4.796534, current_train_items 2304.\n",
      "2023-03-23 10:56:08,220 - root - INFO - Algo binary_search step 72 current loss 5.786991, current_train_items 2336.\n",
      "2023-03-23 10:56:08,253 - root - INFO - Algo binary_search step 73 current loss 6.723462, current_train_items 2368.\n",
      "2023-03-23 10:56:08,291 - root - INFO - Algo binary_search step 74 current loss 8.132728, current_train_items 2400.\n",
      "2023-03-23 10:56:08,299 - root - INFO - Algo binary_search step 75 current loss 2.636525, current_train_items 2432.\n",
      "2023-03-23 10:56:08,316 - root - INFO - Algo binary_search step 76 current loss 4.974247, current_train_items 2464.\n",
      "2023-03-23 10:56:08,342 - root - INFO - Algo binary_search step 77 current loss 5.599395, current_train_items 2496.\n",
      "2023-03-23 10:56:08,373 - root - INFO - Algo binary_search step 78 current loss 6.596547, current_train_items 2528.\n",
      "2023-03-23 10:56:08,417 - root - INFO - Algo binary_search step 79 current loss 7.878862, current_train_items 2560.\n",
      "2023-03-23 10:56:08,427 - root - INFO - Algo binary_search step 80 current loss 2.579590, current_train_items 2592.\n",
      "2023-03-23 10:56:08,446 - root - INFO - Algo binary_search step 81 current loss 4.077841, current_train_items 2624.\n",
      "2023-03-23 10:56:08,475 - root - INFO - Algo binary_search step 82 current loss 5.839911, current_train_items 2656.\n",
      "2023-03-23 10:56:08,513 - root - INFO - Algo binary_search step 83 current loss 5.922976, current_train_items 2688.\n",
      "2023-03-23 10:56:08,551 - root - INFO - Algo binary_search step 84 current loss 7.592942, current_train_items 2720.\n",
      "2023-03-23 10:56:08,559 - root - INFO - Algo binary_search step 85 current loss 2.586132, current_train_items 2752.\n",
      "2023-03-23 10:56:08,578 - root - INFO - Algo binary_search step 86 current loss 4.411393, current_train_items 2784.\n",
      "2023-03-23 10:56:08,605 - root - INFO - Algo binary_search step 87 current loss 5.679720, current_train_items 2816.\n",
      "2023-03-23 10:56:08,636 - root - INFO - Algo binary_search step 88 current loss 5.940223, current_train_items 2848.\n",
      "2023-03-23 10:56:08,684 - root - INFO - Algo binary_search step 89 current loss 7.059881, current_train_items 2880.\n",
      "2023-03-23 10:56:08,692 - root - INFO - Algo binary_search step 90 current loss 2.734015, current_train_items 2912.\n",
      "2023-03-23 10:56:08,710 - root - INFO - Algo binary_search step 91 current loss 3.277772, current_train_items 2944.\n",
      "2023-03-23 10:56:08,737 - root - INFO - Algo binary_search step 92 current loss 5.379230, current_train_items 2976.\n",
      "2023-03-23 10:56:08,771 - root - INFO - Algo binary_search step 93 current loss 5.565956, current_train_items 3008.\n",
      "2023-03-23 10:56:08,809 - root - INFO - Algo binary_search step 94 current loss 6.576685, current_train_items 3040.\n",
      "2023-03-23 10:56:08,820 - root - INFO - Algo binary_search step 95 current loss 2.487170, current_train_items 3072.\n",
      "2023-03-23 10:56:08,844 - root - INFO - Algo binary_search step 96 current loss 4.204180, current_train_items 3104.\n",
      "2023-03-23 10:56:08,891 - root - INFO - Algo binary_search step 97 current loss 5.404660, current_train_items 3136.\n",
      "2023-03-23 10:56:08,934 - root - INFO - Algo binary_search step 98 current loss 5.446279, current_train_items 3168.\n",
      "2023-03-23 10:56:08,993 - root - INFO - Algo binary_search step 99 current loss 6.992729, current_train_items 3200.\n",
      "2023-03-23 10:56:09,002 - root - INFO - Algo binary_search step 100 current loss 2.894402, current_train_items 3232.\n",
      "2023-03-23 10:56:11,257 - root - INFO - (val) algo binary_search step 100: {'return': 0.65234375, 'score': 0.65234375, 'examples_seen': 3232, 'step': 100, 'algorithm': 'binary_search'}\n",
      "2023-03-23 10:56:11,257 - root - INFO - Checkpointing best model, best avg val score was 0.218, current avg val score is 0.652, val scores are: binary_search: 0.652\n",
      "2023-03-23 10:56:11,295 - root - INFO - Algo binary_search step 101 current loss 3.718665, current_train_items 3264.\n",
      "2023-03-23 10:56:11,321 - root - INFO - Algo binary_search step 102 current loss 4.376458, current_train_items 3296.\n",
      "2023-03-23 10:56:11,355 - root - INFO - Algo binary_search step 103 current loss 5.068175, current_train_items 3328.\n",
      "2023-03-23 10:56:11,394 - root - INFO - Algo binary_search step 104 current loss 6.404884, current_train_items 3360.\n",
      "2023-03-23 10:56:11,407 - root - INFO - Algo binary_search step 105 current loss 2.348698, current_train_items 3392.\n",
      "2023-03-23 10:56:11,426 - root - INFO - Algo binary_search step 106 current loss 3.756491, current_train_items 3424.\n",
      "2023-03-23 10:56:11,454 - root - INFO - Algo binary_search step 107 current loss 5.058851, current_train_items 3456.\n",
      "2023-03-23 10:56:11,487 - root - INFO - Algo binary_search step 108 current loss 5.341194, current_train_items 3488.\n",
      "2023-03-23 10:56:11,540 - root - INFO - Algo binary_search step 109 current loss 6.516995, current_train_items 3520.\n",
      "2023-03-23 10:56:11,555 - root - INFO - Algo binary_search step 110 current loss 1.717469, current_train_items 3552.\n",
      "2023-03-23 10:56:11,583 - root - INFO - Algo binary_search step 111 current loss 3.625227, current_train_items 3584.\n",
      "2023-03-23 10:56:11,621 - root - INFO - Algo binary_search step 112 current loss 4.525556, current_train_items 3616.\n",
      "2023-03-23 10:56:11,669 - root - INFO - Algo binary_search step 113 current loss 6.056508, current_train_items 3648.\n",
      "2023-03-23 10:56:11,799 - root - INFO - Algo binary_search step 114 current loss 6.287786, current_train_items 3680.\n",
      "2023-03-23 10:56:11,810 - root - INFO - Algo binary_search step 115 current loss 1.644406, current_train_items 3712.\n",
      "2023-03-23 10:56:11,838 - root - INFO - Algo binary_search step 116 current loss 3.680914, current_train_items 3744.\n",
      "2023-03-23 10:56:11,869 - root - INFO - Algo binary_search step 117 current loss 4.372440, current_train_items 3776.\n",
      "2023-03-23 10:56:11,904 - root - INFO - Algo binary_search step 118 current loss 5.163923, current_train_items 3808.\n",
      "2023-03-23 10:56:11,954 - root - INFO - Algo binary_search step 119 current loss 6.162536, current_train_items 3840.\n",
      "2023-03-23 10:56:11,964 - root - INFO - Algo binary_search step 120 current loss 2.420282, current_train_items 3872.\n",
      "2023-03-23 10:56:11,983 - root - INFO - Algo binary_search step 121 current loss 3.538168, current_train_items 3904.\n",
      "2023-03-23 10:56:12,011 - root - INFO - Algo binary_search step 122 current loss 4.441153, current_train_items 3936.\n",
      "2023-03-23 10:56:12,047 - root - INFO - Algo binary_search step 123 current loss 5.163094, current_train_items 3968.\n",
      "2023-03-23 10:56:12,103 - root - INFO - Algo binary_search step 124 current loss 6.496882, current_train_items 4000.\n",
      "2023-03-23 10:56:12,113 - root - INFO - Algo binary_search step 125 current loss 2.088066, current_train_items 4032.\n",
      "2023-03-23 10:56:12,133 - root - INFO - Algo binary_search step 126 current loss 3.100811, current_train_items 4064.\n",
      "2023-03-23 10:56:12,161 - root - INFO - Algo binary_search step 127 current loss 4.469956, current_train_items 4096.\n",
      "2023-03-23 10:56:12,194 - root - INFO - Algo binary_search step 128 current loss 5.359334, current_train_items 4128.\n",
      "2023-03-23 10:56:12,235 - root - INFO - Algo binary_search step 129 current loss 7.052579, current_train_items 4160.\n",
      "2023-03-23 10:56:12,244 - root - INFO - Algo binary_search step 130 current loss 2.076622, current_train_items 4192.\n",
      "2023-03-23 10:56:12,263 - root - INFO - Algo binary_search step 131 current loss 3.727529, current_train_items 4224.\n",
      "2023-03-23 10:56:12,292 - root - INFO - Algo binary_search step 132 current loss 4.228044, current_train_items 4256.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 10:56:12,325 - root - INFO - Algo binary_search step 133 current loss 5.085920, current_train_items 4288.\n",
      "2023-03-23 10:56:12,365 - root - INFO - Algo binary_search step 134 current loss 6.456422, current_train_items 4320.\n",
      "2023-03-23 10:56:12,378 - root - INFO - Algo binary_search step 135 current loss 2.050768, current_train_items 4352.\n",
      "2023-03-23 10:56:12,397 - root - INFO - Algo binary_search step 136 current loss 2.633639, current_train_items 4384.\n",
      "2023-03-23 10:56:12,423 - root - INFO - Algo binary_search step 137 current loss 4.423470, current_train_items 4416.\n",
      "2023-03-23 10:56:12,455 - root - INFO - Algo binary_search step 138 current loss 5.306309, current_train_items 4448.\n",
      "2023-03-23 10:56:12,495 - root - INFO - Algo binary_search step 139 current loss 6.110987, current_train_items 4480.\n",
      "2023-03-23 10:56:12,504 - root - INFO - Algo binary_search step 140 current loss 1.612501, current_train_items 4512.\n",
      "2023-03-23 10:56:12,522 - root - INFO - Algo binary_search step 141 current loss 3.009107, current_train_items 4544.\n",
      "2023-03-23 10:56:12,548 - root - INFO - Algo binary_search step 142 current loss 4.291094, current_train_items 4576.\n",
      "2023-03-23 10:56:12,578 - root - INFO - Algo binary_search step 143 current loss 4.714100, current_train_items 4608.\n",
      "2023-03-23 10:56:12,617 - root - INFO - Algo binary_search step 144 current loss 6.958610, current_train_items 4640.\n",
      "2023-03-23 10:56:12,624 - root - INFO - Algo binary_search step 145 current loss 1.686650, current_train_items 4672.\n",
      "2023-03-23 10:56:12,649 - root - INFO - Algo binary_search step 146 current loss 3.071171, current_train_items 4704.\n",
      "2023-03-23 10:56:12,682 - root - INFO - Algo binary_search step 147 current loss 4.425960, current_train_items 4736.\n",
      "2023-03-23 10:56:12,730 - root - INFO - Algo binary_search step 148 current loss 5.308541, current_train_items 4768.\n",
      "2023-03-23 10:56:12,767 - root - INFO - Algo binary_search step 149 current loss 6.249963, current_train_items 4800.\n",
      "2023-03-23 10:56:12,775 - root - INFO - Algo binary_search step 150 current loss 1.588427, current_train_items 4832.\n",
      "2023-03-23 10:56:14,975 - root - INFO - (val) algo binary_search step 150: {'return': 0.785400390625, 'score': 0.785400390625, 'examples_seen': 4832, 'step': 150, 'algorithm': 'binary_search'}\n",
      "2023-03-23 10:56:14,975 - root - INFO - Checkpointing best model, best avg val score was 0.652, current avg val score is 0.785, val scores are: binary_search: 0.785\n",
      "2023-03-23 10:56:15,002 - root - INFO - Algo binary_search step 151 current loss 2.580257, current_train_items 4864.\n",
      "2023-03-23 10:56:15,030 - root - INFO - Algo binary_search step 152 current loss 4.298407, current_train_items 4896.\n",
      "2023-03-23 10:56:15,062 - root - INFO - Algo binary_search step 153 current loss 4.532744, current_train_items 4928.\n",
      "2023-03-23 10:56:15,102 - root - INFO - Algo binary_search step 154 current loss 5.445613, current_train_items 4960.\n",
      "2023-03-23 10:56:15,111 - root - INFO - Algo binary_search step 155 current loss 1.586367, current_train_items 4992.\n",
      "2023-03-23 10:56:15,129 - root - INFO - Algo binary_search step 156 current loss 3.078280, current_train_items 5024.\n",
      "2023-03-23 10:56:15,155 - root - INFO - Algo binary_search step 157 current loss 4.216074, current_train_items 5056.\n",
      "2023-03-23 10:56:15,185 - root - INFO - Algo binary_search step 158 current loss 4.489877, current_train_items 5088.\n",
      "2023-03-23 10:56:15,225 - root - INFO - Algo binary_search step 159 current loss 6.299974, current_train_items 5120.\n",
      "2023-03-23 10:56:15,233 - root - INFO - Algo binary_search step 160 current loss 1.742259, current_train_items 5152.\n",
      "2023-03-23 10:56:15,250 - root - INFO - Algo binary_search step 161 current loss 3.011602, current_train_items 5184.\n",
      "2023-03-23 10:56:15,276 - root - INFO - Algo binary_search step 162 current loss 3.796017, current_train_items 5216.\n",
      "2023-03-23 10:56:15,307 - root - INFO - Algo binary_search step 163 current loss 3.830343, current_train_items 5248.\n",
      "2023-03-23 10:56:15,346 - root - INFO - Algo binary_search step 164 current loss 5.355079, current_train_items 5280.\n",
      "2023-03-23 10:56:15,354 - root - INFO - Algo binary_search step 165 current loss 1.466170, current_train_items 5312.\n",
      "2023-03-23 10:56:15,370 - root - INFO - Algo binary_search step 166 current loss 2.849160, current_train_items 5344.\n",
      "2023-03-23 10:56:15,397 - root - INFO - Algo binary_search step 167 current loss 3.853394, current_train_items 5376.\n",
      "2023-03-23 10:56:15,431 - root - INFO - Algo binary_search step 168 current loss 4.358043, current_train_items 5408.\n",
      "2023-03-23 10:56:15,470 - root - INFO - Algo binary_search step 169 current loss 5.322741, current_train_items 5440.\n",
      "2023-03-23 10:56:15,478 - root - INFO - Algo binary_search step 170 current loss 1.633047, current_train_items 5472.\n",
      "2023-03-23 10:56:15,494 - root - INFO - Algo binary_search step 171 current loss 2.977946, current_train_items 5504.\n",
      "2023-03-23 10:56:15,520 - root - INFO - Algo binary_search step 172 current loss 3.868917, current_train_items 5536.\n",
      "2023-03-23 10:56:15,552 - root - INFO - Algo binary_search step 173 current loss 4.754104, current_train_items 5568.\n",
      "2023-03-23 10:56:15,595 - root - INFO - Algo binary_search step 174 current loss 5.362282, current_train_items 5600.\n",
      "2023-03-23 10:56:15,604 - root - INFO - Algo binary_search step 175 current loss 1.450623, current_train_items 5632.\n",
      "2023-03-23 10:56:15,623 - root - INFO - Algo binary_search step 176 current loss 2.534858, current_train_items 5664.\n",
      "2023-03-23 10:56:15,649 - root - INFO - Algo binary_search step 177 current loss 4.253866, current_train_items 5696.\n",
      "2023-03-23 10:56:15,680 - root - INFO - Algo binary_search step 178 current loss 4.254520, current_train_items 5728.\n",
      "2023-03-23 10:56:15,734 - root - INFO - Algo binary_search step 179 current loss 5.195738, current_train_items 5760.\n",
      "2023-03-23 10:56:15,743 - root - INFO - Algo binary_search step 180 current loss 1.179785, current_train_items 5792.\n",
      "2023-03-23 10:56:15,761 - root - INFO - Algo binary_search step 181 current loss 2.960012, current_train_items 5824.\n",
      "2023-03-23 10:56:15,789 - root - INFO - Algo binary_search step 182 current loss 5.268666, current_train_items 5856.\n",
      "2023-03-23 10:56:15,826 - root - INFO - Algo binary_search step 183 current loss 4.856419, current_train_items 5888.\n",
      "2023-03-23 10:56:15,866 - root - INFO - Algo binary_search step 184 current loss 5.623840, current_train_items 5920.\n",
      "2023-03-23 10:56:15,875 - root - INFO - Algo binary_search step 185 current loss 1.412037, current_train_items 5952.\n",
      "2023-03-23 10:56:15,893 - root - INFO - Algo binary_search step 186 current loss 2.576488, current_train_items 5984.\n",
      "2023-03-23 10:56:15,922 - root - INFO - Algo binary_search step 187 current loss 3.925064, current_train_items 6016.\n",
      "2023-03-23 10:56:15,952 - root - INFO - Algo binary_search step 188 current loss 5.178880, current_train_items 6048.\n",
      "2023-03-23 10:56:15,992 - root - INFO - Algo binary_search step 189 current loss 5.547692, current_train_items 6080.\n",
      "2023-03-23 10:56:16,002 - root - INFO - Algo binary_search step 190 current loss 1.232604, current_train_items 6112.\n",
      "2023-03-23 10:56:16,020 - root - INFO - Algo binary_search step 191 current loss 2.379769, current_train_items 6144.\n",
      "2023-03-23 10:56:16,046 - root - INFO - Algo binary_search step 192 current loss 4.406915, current_train_items 6176.\n",
      "2023-03-23 10:56:16,084 - root - INFO - Algo binary_search step 193 current loss 4.474872, current_train_items 6208.\n",
      "2023-03-23 10:56:16,136 - root - INFO - Algo binary_search step 194 current loss 5.799759, current_train_items 6240.\n",
      "2023-03-23 10:56:16,144 - root - INFO - Algo binary_search step 195 current loss 1.514112, current_train_items 6272.\n",
      "2023-03-23 10:56:16,161 - root - INFO - Algo binary_search step 196 current loss 2.402844, current_train_items 6304.\n",
      "2023-03-23 10:56:16,187 - root - INFO - Algo binary_search step 197 current loss 3.916006, current_train_items 6336.\n",
      "2023-03-23 10:56:16,220 - root - INFO - Algo binary_search step 198 current loss 4.343547, current_train_items 6368.\n",
      "2023-03-23 10:56:16,260 - root - INFO - Algo binary_search step 199 current loss 6.103591, current_train_items 6400.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 10:56:16,270 - root - INFO - Algo binary_search step 200 current loss 1.432955, current_train_items 6432.\n",
      "2023-03-23 10:56:18,483 - root - INFO - (val) algo binary_search step 200: {'return': 0.78271484375, 'score': 0.78271484375, 'examples_seen': 6432, 'step': 200, 'algorithm': 'binary_search'}\n",
      "2023-03-23 10:56:18,484 - root - INFO - Not saving new best model, best avg val score was 0.785, current avg val score is 0.783, val scores are: binary_search: 0.783\n",
      "2023-03-23 10:56:18,502 - root - INFO - Algo binary_search step 201 current loss 2.762525, current_train_items 6464.\n",
      "2023-03-23 10:56:18,529 - root - INFO - Algo binary_search step 202 current loss 3.426068, current_train_items 6496.\n",
      "2023-03-23 10:56:18,559 - root - INFO - Algo binary_search step 203 current loss 4.566252, current_train_items 6528.\n",
      "2023-03-23 10:56:18,597 - root - INFO - Algo binary_search step 204 current loss 6.586327, current_train_items 6560.\n",
      "2023-03-23 10:56:18,605 - root - INFO - Algo binary_search step 205 current loss 1.390145, current_train_items 6592.\n",
      "2023-03-23 10:56:18,620 - root - INFO - Algo binary_search step 206 current loss 2.460386, current_train_items 6624.\n",
      "2023-03-23 10:56:18,646 - root - INFO - Algo binary_search step 207 current loss 3.414877, current_train_items 6656.\n",
      "2023-03-23 10:56:18,678 - root - INFO - Algo binary_search step 208 current loss 4.645111, current_train_items 6688.\n",
      "2023-03-23 10:56:18,715 - root - INFO - Algo binary_search step 209 current loss 6.398211, current_train_items 6720.\n",
      "2023-03-23 10:56:18,724 - root - INFO - Algo binary_search step 210 current loss 1.388818, current_train_items 6752.\n",
      "2023-03-23 10:56:18,740 - root - INFO - Algo binary_search step 211 current loss 2.769339, current_train_items 6784.\n",
      "2023-03-23 10:56:18,767 - root - INFO - Algo binary_search step 212 current loss 3.056738, current_train_items 6816.\n",
      "2023-03-23 10:56:18,798 - root - INFO - Algo binary_search step 213 current loss 4.134756, current_train_items 6848.\n",
      "2023-03-23 10:56:18,835 - root - INFO - Algo binary_search step 214 current loss 5.863026, current_train_items 6880.\n",
      "2023-03-23 10:56:18,843 - root - INFO - Algo binary_search step 215 current loss 1.462282, current_train_items 6912.\n",
      "2023-03-23 10:56:18,859 - root - INFO - Algo binary_search step 216 current loss 2.399078, current_train_items 6944.\n",
      "2023-03-23 10:56:18,885 - root - INFO - Algo binary_search step 217 current loss 3.402588, current_train_items 6976.\n",
      "2023-03-23 10:56:18,917 - root - INFO - Algo binary_search step 218 current loss 3.753600, current_train_items 7008.\n",
      "2023-03-23 10:56:18,955 - root - INFO - Algo binary_search step 219 current loss 5.319936, current_train_items 7040.\n",
      "2023-03-23 10:56:18,962 - root - INFO - Algo binary_search step 220 current loss 1.365697, current_train_items 7072.\n",
      "2023-03-23 10:56:18,979 - root - INFO - Algo binary_search step 221 current loss 2.865987, current_train_items 7104.\n",
      "2023-03-23 10:56:19,004 - root - INFO - Algo binary_search step 222 current loss 3.223650, current_train_items 7136.\n",
      "2023-03-23 10:56:19,034 - root - INFO - Algo binary_search step 223 current loss 3.997132, current_train_items 7168.\n",
      "2023-03-23 10:56:19,071 - root - INFO - Algo binary_search step 224 current loss 4.566992, current_train_items 7200.\n",
      "2023-03-23 10:56:19,079 - root - INFO - Algo binary_search step 225 current loss 1.177371, current_train_items 7232.\n",
      "2023-03-23 10:56:19,094 - root - INFO - Algo binary_search step 226 current loss 2.599258, current_train_items 7264.\n",
      "2023-03-23 10:56:19,120 - root - INFO - Algo binary_search step 227 current loss 3.463998, current_train_items 7296.\n",
      "2023-03-23 10:56:19,151 - root - INFO - Algo binary_search step 228 current loss 3.771209, current_train_items 7328.\n",
      "2023-03-23 10:56:19,189 - root - INFO - Algo binary_search step 229 current loss 5.746831, current_train_items 7360.\n",
      "2023-03-23 10:56:19,196 - root - INFO - Algo binary_search step 230 current loss 1.157721, current_train_items 7392.\n",
      "2023-03-23 10:56:19,212 - root - INFO - Algo binary_search step 231 current loss 2.719445, current_train_items 7424.\n",
      "2023-03-23 10:56:19,238 - root - INFO - Algo binary_search step 232 current loss 4.094886, current_train_items 7456.\n",
      "2023-03-23 10:56:19,268 - root - INFO - Algo binary_search step 233 current loss 4.126235, current_train_items 7488.\n",
      "2023-03-23 10:56:19,306 - root - INFO - Algo binary_search step 234 current loss 5.338504, current_train_items 7520.\n",
      "2023-03-23 10:56:19,313 - root - INFO - Algo binary_search step 235 current loss 1.334369, current_train_items 7552.\n",
      "2023-03-23 10:56:19,329 - root - INFO - Algo binary_search step 236 current loss 2.708720, current_train_items 7584.\n",
      "2023-03-23 10:56:19,356 - root - INFO - Algo binary_search step 237 current loss 3.369931, current_train_items 7616.\n",
      "2023-03-23 10:56:19,386 - root - INFO - Algo binary_search step 238 current loss 3.588286, current_train_items 7648.\n",
      "2023-03-23 10:56:19,423 - root - INFO - Algo binary_search step 239 current loss 4.453252, current_train_items 7680.\n",
      "2023-03-23 10:56:19,431 - root - INFO - Algo binary_search step 240 current loss 1.258057, current_train_items 7712.\n",
      "2023-03-23 10:56:19,448 - root - INFO - Algo binary_search step 241 current loss 2.525160, current_train_items 7744.\n",
      "2023-03-23 10:56:19,474 - root - INFO - Algo binary_search step 242 current loss 3.655608, current_train_items 7776.\n",
      "2023-03-23 10:56:19,504 - root - INFO - Algo binary_search step 243 current loss 3.657381, current_train_items 7808.\n",
      "2023-03-23 10:56:19,541 - root - INFO - Algo binary_search step 244 current loss 4.944988, current_train_items 7840.\n",
      "2023-03-23 10:56:19,548 - root - INFO - Algo binary_search step 245 current loss 1.116361, current_train_items 7872.\n",
      "2023-03-23 10:56:19,564 - root - INFO - Algo binary_search step 246 current loss 2.145574, current_train_items 7904.\n",
      "2023-03-23 10:56:19,591 - root - INFO - Algo binary_search step 247 current loss 3.456420, current_train_items 7936.\n",
      "2023-03-23 10:56:19,623 - root - INFO - Algo binary_search step 248 current loss 3.774955, current_train_items 7968.\n",
      "2023-03-23 10:56:19,661 - root - INFO - Algo binary_search step 249 current loss 5.210936, current_train_items 8000.\n",
      "2023-03-23 10:56:19,668 - root - INFO - Algo binary_search step 250 current loss 1.397614, current_train_items 8032.\n",
      "2023-03-23 10:56:21,820 - root - INFO - (val) algo binary_search step 250: {'return': 0.806640625, 'score': 0.806640625, 'examples_seen': 8032, 'step': 250, 'algorithm': 'binary_search'}\n",
      "2023-03-23 10:56:21,821 - root - INFO - Checkpointing best model, best avg val score was 0.785, current avg val score is 0.807, val scores are: binary_search: 0.807\n",
      "2023-03-23 10:56:21,842 - root - INFO - Algo binary_search step 251 current loss 2.178515, current_train_items 8064.\n",
      "2023-03-23 10:56:21,872 - root - INFO - Algo binary_search step 252 current loss 2.992999, current_train_items 8096.\n",
      "2023-03-23 10:56:21,907 - root - INFO - Algo binary_search step 253 current loss 3.618250, current_train_items 8128.\n",
      "2023-03-23 10:56:21,964 - root - INFO - Algo binary_search step 254 current loss 4.308331, current_train_items 8160.\n",
      "2023-03-23 10:56:21,986 - root - INFO - Algo binary_search step 255 current loss 1.139314, current_train_items 8192.\n",
      "2023-03-23 10:56:22,180 - root - INFO - Algo binary_search step 256 current loss 2.414011, current_train_items 8224.\n",
      "2023-03-23 10:56:22,207 - root - INFO - Algo binary_search step 257 current loss 3.240346, current_train_items 8256.\n",
      "2023-03-23 10:56:22,243 - root - INFO - Algo binary_search step 258 current loss 4.259054, current_train_items 8288.\n",
      "2023-03-23 10:56:22,288 - root - INFO - Algo binary_search step 259 current loss 5.674105, current_train_items 8320.\n",
      "2023-03-23 10:56:22,297 - root - INFO - Algo binary_search step 260 current loss 1.255255, current_train_items 8352.\n",
      "2023-03-23 10:56:22,315 - root - INFO - Algo binary_search step 261 current loss 2.528146, current_train_items 8384.\n",
      "2023-03-23 10:56:22,343 - root - INFO - Algo binary_search step 262 current loss 3.687385, current_train_items 8416.\n",
      "2023-03-23 10:56:22,375 - root - INFO - Algo binary_search step 263 current loss 4.213695, current_train_items 8448.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 10:56:22,415 - root - INFO - Algo binary_search step 264 current loss 4.955285, current_train_items 8480.\n",
      "2023-03-23 10:56:22,424 - root - INFO - Algo binary_search step 265 current loss 0.889073, current_train_items 8512.\n",
      "2023-03-23 10:56:22,441 - root - INFO - Algo binary_search step 266 current loss 2.501162, current_train_items 8544.\n",
      "2023-03-23 10:56:22,473 - root - INFO - Algo binary_search step 267 current loss 3.584902, current_train_items 8576.\n",
      "2023-03-23 10:56:22,505 - root - INFO - Algo binary_search step 268 current loss 4.120938, current_train_items 8608.\n",
      "2023-03-23 10:56:22,545 - root - INFO - Algo binary_search step 269 current loss 3.977637, current_train_items 8640.\n",
      "2023-03-23 10:56:22,554 - root - INFO - Algo binary_search step 270 current loss 0.836556, current_train_items 8672.\n",
      "2023-03-23 10:56:22,571 - root - INFO - Algo binary_search step 271 current loss 2.543896, current_train_items 8704.\n",
      "2023-03-23 10:56:22,599 - root - INFO - Algo binary_search step 272 current loss 4.285215, current_train_items 8736.\n",
      "2023-03-23 10:56:22,631 - root - INFO - Algo binary_search step 273 current loss 3.856462, current_train_items 8768.\n",
      "2023-03-23 10:56:22,669 - root - INFO - Algo binary_search step 274 current loss 4.617394, current_train_items 8800.\n",
      "2023-03-23 10:56:22,677 - root - INFO - Algo binary_search step 275 current loss 0.858176, current_train_items 8832.\n",
      "2023-03-23 10:56:22,710 - root - INFO - Algo binary_search step 276 current loss 2.045194, current_train_items 8864.\n",
      "2023-03-23 10:56:22,737 - root - INFO - Algo binary_search step 277 current loss 3.402693, current_train_items 8896.\n",
      "2023-03-23 10:56:22,770 - root - INFO - Algo binary_search step 278 current loss 3.160578, current_train_items 8928.\n",
      "2023-03-23 10:56:22,808 - root - INFO - Algo binary_search step 279 current loss 4.283612, current_train_items 8960.\n",
      "2023-03-23 10:56:22,816 - root - INFO - Algo binary_search step 280 current loss 1.397782, current_train_items 8992.\n",
      "2023-03-23 10:56:22,833 - root - INFO - Algo binary_search step 281 current loss 1.676227, current_train_items 9024.\n",
      "2023-03-23 10:56:22,860 - root - INFO - Algo binary_search step 282 current loss 3.110243, current_train_items 9056.\n",
      "2023-03-23 10:56:22,892 - root - INFO - Algo binary_search step 283 current loss 2.958313, current_train_items 9088.\n",
      "2023-03-23 10:56:22,931 - root - INFO - Algo binary_search step 284 current loss 4.307877, current_train_items 9120.\n",
      "2023-03-23 10:56:22,939 - root - INFO - Algo binary_search step 285 current loss 0.936605, current_train_items 9152.\n",
      "2023-03-23 10:56:22,957 - root - INFO - Algo binary_search step 286 current loss 2.160552, current_train_items 9184.\n",
      "2023-03-23 10:56:22,984 - root - INFO - Algo binary_search step 287 current loss 3.328207, current_train_items 9216.\n",
      "2023-03-23 10:56:23,017 - root - INFO - Algo binary_search step 288 current loss 3.825409, current_train_items 9248.\n",
      "2023-03-23 10:56:23,061 - root - INFO - Algo binary_search step 289 current loss 3.895032, current_train_items 9280.\n",
      "2023-03-23 10:56:23,071 - root - INFO - Algo binary_search step 290 current loss 1.018323, current_train_items 9312.\n",
      "2023-03-23 10:56:23,090 - root - INFO - Algo binary_search step 291 current loss 2.453098, current_train_items 9344.\n",
      "2023-03-23 10:56:23,117 - root - INFO - Algo binary_search step 292 current loss 3.726223, current_train_items 9376.\n",
      "2023-03-23 10:56:23,150 - root - INFO - Algo binary_search step 293 current loss 3.966454, current_train_items 9408.\n",
      "2023-03-23 10:56:23,195 - root - INFO - Algo binary_search step 294 current loss 4.539410, current_train_items 9440.\n",
      "2023-03-23 10:56:23,203 - root - INFO - Algo binary_search step 295 current loss 0.828155, current_train_items 9472.\n",
      "2023-03-23 10:56:23,219 - root - INFO - Algo binary_search step 296 current loss 2.118734, current_train_items 9504.\n",
      "2023-03-23 10:56:23,245 - root - INFO - Algo binary_search step 297 current loss 2.928835, current_train_items 9536.\n",
      "2023-03-23 10:56:23,278 - root - INFO - Algo binary_search step 298 current loss 3.350558, current_train_items 9568.\n",
      "2023-03-23 10:56:23,317 - root - INFO - Algo binary_search step 299 current loss 4.894109, current_train_items 9600.\n",
      "2023-03-23 10:56:23,324 - root - INFO - Algo binary_search step 300 current loss 0.833648, current_train_items 9632.\n",
      "2023-03-23 10:56:25,472 - root - INFO - (val) algo binary_search step 300: {'return': 0.766357421875, 'score': 0.766357421875, 'examples_seen': 9632, 'step': 300, 'algorithm': 'binary_search'}\n",
      "2023-03-23 10:56:25,472 - root - INFO - Not saving new best model, best avg val score was 0.807, current avg val score is 0.766, val scores are: binary_search: 0.766\n",
      "2023-03-23 10:56:25,490 - root - INFO - Algo binary_search step 301 current loss 2.146490, current_train_items 9664.\n",
      "2023-03-23 10:56:25,517 - root - INFO - Algo binary_search step 302 current loss 3.609363, current_train_items 9696.\n",
      "2023-03-23 10:56:25,550 - root - INFO - Algo binary_search step 303 current loss 5.114197, current_train_items 9728.\n",
      "2023-03-23 10:56:25,590 - root - INFO - Algo binary_search step 304 current loss 4.978287, current_train_items 9760.\n",
      "2023-03-23 10:56:25,599 - root - INFO - Algo binary_search step 305 current loss 0.610340, current_train_items 9792.\n",
      "2023-03-23 10:56:25,616 - root - INFO - Algo binary_search step 306 current loss 1.948808, current_train_items 9824.\n",
      "2023-03-23 10:56:25,646 - root - INFO - Algo binary_search step 307 current loss 3.493052, current_train_items 9856.\n",
      "2023-03-23 10:56:25,679 - root - INFO - Algo binary_search step 308 current loss 3.941539, current_train_items 9888.\n",
      "2023-03-23 10:56:25,720 - root - INFO - Algo binary_search step 309 current loss 4.280981, current_train_items 9920.\n",
      "2023-03-23 10:56:25,728 - root - INFO - Algo binary_search step 310 current loss 0.628235, current_train_items 9952.\n",
      "2023-03-23 10:56:25,745 - root - INFO - Algo binary_search step 311 current loss 2.104793, current_train_items 9984.\n",
      "2023-03-23 10:56:25,773 - root - INFO - Algo binary_search step 312 current loss 3.345816, current_train_items 10016.\n",
      "2023-03-23 10:56:25,807 - root - INFO - Algo binary_search step 313 current loss 3.434582, current_train_items 10048.\n",
      "2023-03-23 10:56:25,847 - root - INFO - Algo binary_search step 314 current loss 3.853628, current_train_items 10080.\n",
      "2023-03-23 10:56:25,855 - root - INFO - Algo binary_search step 315 current loss 0.905285, current_train_items 10112.\n",
      "2023-03-23 10:56:25,871 - root - INFO - Algo binary_search step 316 current loss 1.737770, current_train_items 10144.\n",
      "2023-03-23 10:56:25,896 - root - INFO - Algo binary_search step 317 current loss 2.868692, current_train_items 10176.\n",
      "2023-03-23 10:56:25,928 - root - INFO - Algo binary_search step 318 current loss 3.051526, current_train_items 10208.\n",
      "2023-03-23 10:56:25,966 - root - INFO - Algo binary_search step 319 current loss 4.324870, current_train_items 10240.\n",
      "2023-03-23 10:56:25,974 - root - INFO - Algo binary_search step 320 current loss 0.840208, current_train_items 10272.\n",
      "2023-03-23 10:56:25,989 - root - INFO - Algo binary_search step 321 current loss 1.943321, current_train_items 10304.\n",
      "2023-03-23 10:56:26,017 - root - INFO - Algo binary_search step 322 current loss 3.260996, current_train_items 10336.\n",
      "2023-03-23 10:56:26,049 - root - INFO - Algo binary_search step 323 current loss 3.725021, current_train_items 10368.\n",
      "2023-03-23 10:56:26,087 - root - INFO - Algo binary_search step 324 current loss 4.078613, current_train_items 10400.\n",
      "2023-03-23 10:56:26,095 - root - INFO - Algo binary_search step 325 current loss 0.849162, current_train_items 10432.\n",
      "2023-03-23 10:56:26,112 - root - INFO - Algo binary_search step 326 current loss 1.560608, current_train_items 10464.\n",
      "2023-03-23 10:56:26,141 - root - INFO - Algo binary_search step 327 current loss 3.169346, current_train_items 10496.\n",
      "2023-03-23 10:56:26,174 - root - INFO - Algo binary_search step 328 current loss 3.922493, current_train_items 10528.\n",
      "2023-03-23 10:56:26,213 - root - INFO - Algo binary_search step 329 current loss 4.060633, current_train_items 10560.\n",
      "2023-03-23 10:56:26,220 - root - INFO - Algo binary_search step 330 current loss 1.166656, current_train_items 10592.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 10:56:26,236 - root - INFO - Algo binary_search step 331 current loss 1.864539, current_train_items 10624.\n",
      "2023-03-23 10:56:26,264 - root - INFO - Algo binary_search step 332 current loss 3.175578, current_train_items 10656.\n",
      "2023-03-23 10:56:26,296 - root - INFO - Algo binary_search step 333 current loss 4.009730, current_train_items 10688.\n",
      "2023-03-23 10:56:26,333 - root - INFO - Algo binary_search step 334 current loss 4.103711, current_train_items 10720.\n",
      "2023-03-23 10:56:26,341 - root - INFO - Algo binary_search step 335 current loss 0.905106, current_train_items 10752.\n",
      "2023-03-23 10:56:26,360 - root - INFO - Algo binary_search step 336 current loss 1.994769, current_train_items 10784.\n",
      "2023-03-23 10:56:26,387 - root - INFO - Algo binary_search step 337 current loss 3.212667, current_train_items 10816.\n",
      "2023-03-23 10:56:26,419 - root - INFO - Algo binary_search step 338 current loss 3.244218, current_train_items 10848.\n",
      "2023-03-23 10:56:26,457 - root - INFO - Algo binary_search step 339 current loss 3.839429, current_train_items 10880.\n",
      "2023-03-23 10:56:26,465 - root - INFO - Algo binary_search step 340 current loss 0.938552, current_train_items 10912.\n",
      "2023-03-23 10:56:26,481 - root - INFO - Algo binary_search step 341 current loss 2.811500, current_train_items 10944.\n",
      "2023-03-23 10:56:26,509 - root - INFO - Algo binary_search step 342 current loss 3.223047, current_train_items 10976.\n",
      "2023-03-23 10:56:26,540 - root - INFO - Algo binary_search step 343 current loss 3.713346, current_train_items 11008.\n",
      "2023-03-23 10:56:26,577 - root - INFO - Algo binary_search step 344 current loss 3.734778, current_train_items 11040.\n",
      "2023-03-23 10:56:26,586 - root - INFO - Algo binary_search step 345 current loss 0.960564, current_train_items 11072.\n",
      "2023-03-23 10:56:26,602 - root - INFO - Algo binary_search step 346 current loss 2.687435, current_train_items 11104.\n",
      "2023-03-23 10:56:26,629 - root - INFO - Algo binary_search step 347 current loss 3.612857, current_train_items 11136.\n",
      "2023-03-23 10:56:26,659 - root - INFO - Algo binary_search step 348 current loss 3.310485, current_train_items 11168.\n",
      "2023-03-23 10:56:26,698 - root - INFO - Algo binary_search step 349 current loss 4.250820, current_train_items 11200.\n",
      "2023-03-23 10:56:26,708 - root - INFO - Algo binary_search step 350 current loss 1.485307, current_train_items 11232.\n",
      "2023-03-23 10:56:28,863 - root - INFO - (val) algo binary_search step 350: {'return': 0.828369140625, 'score': 0.828369140625, 'examples_seen': 11232, 'step': 350, 'algorithm': 'binary_search'}\n",
      "2023-03-23 10:56:28,864 - root - INFO - Checkpointing best model, best avg val score was 0.807, current avg val score is 0.828, val scores are: binary_search: 0.828\n",
      "2023-03-23 10:56:28,883 - root - INFO - Algo binary_search step 351 current loss 2.075484, current_train_items 11264.\n",
      "2023-03-23 10:56:28,910 - root - INFO - Algo binary_search step 352 current loss 2.812346, current_train_items 11296.\n",
      "2023-03-23 10:56:28,940 - root - INFO - Algo binary_search step 353 current loss 3.101902, current_train_items 11328.\n",
      "2023-03-23 10:56:28,979 - root - INFO - Algo binary_search step 354 current loss 4.300467, current_train_items 11360.\n",
      "2023-03-23 10:56:28,987 - root - INFO - Algo binary_search step 355 current loss 0.873520, current_train_items 11392.\n",
      "2023-03-23 10:56:29,004 - root - INFO - Algo binary_search step 356 current loss 1.839491, current_train_items 11424.\n",
      "2023-03-23 10:56:29,031 - root - INFO - Algo binary_search step 357 current loss 3.134254, current_train_items 11456.\n",
      "2023-03-23 10:56:29,062 - root - INFO - Algo binary_search step 358 current loss 3.251147, current_train_items 11488.\n",
      "2023-03-23 10:56:29,102 - root - INFO - Algo binary_search step 359 current loss 3.522554, current_train_items 11520.\n",
      "2023-03-23 10:56:29,110 - root - INFO - Algo binary_search step 360 current loss 0.626772, current_train_items 11552.\n",
      "2023-03-23 10:56:29,127 - root - INFO - Algo binary_search step 361 current loss 2.036535, current_train_items 11584.\n",
      "2023-03-23 10:56:29,155 - root - INFO - Algo binary_search step 362 current loss 2.731362, current_train_items 11616.\n",
      "2023-03-23 10:56:29,186 - root - INFO - Algo binary_search step 363 current loss 3.370315, current_train_items 11648.\n",
      "2023-03-23 10:56:29,226 - root - INFO - Algo binary_search step 364 current loss 4.211765, current_train_items 11680.\n",
      "2023-03-23 10:56:29,234 - root - INFO - Algo binary_search step 365 current loss 0.614852, current_train_items 11712.\n",
      "2023-03-23 10:56:29,251 - root - INFO - Algo binary_search step 366 current loss 1.637088, current_train_items 11744.\n",
      "2023-03-23 10:56:29,278 - root - INFO - Algo binary_search step 367 current loss 2.778290, current_train_items 11776.\n",
      "2023-03-23 10:56:29,309 - root - INFO - Algo binary_search step 368 current loss 3.405160, current_train_items 11808.\n",
      "2023-03-23 10:56:29,348 - root - INFO - Algo binary_search step 369 current loss 3.753602, current_train_items 11840.\n",
      "2023-03-23 10:56:29,356 - root - INFO - Algo binary_search step 370 current loss 0.932445, current_train_items 11872.\n",
      "2023-03-23 10:56:29,372 - root - INFO - Algo binary_search step 371 current loss 2.222377, current_train_items 11904.\n",
      "2023-03-23 10:56:29,399 - root - INFO - Algo binary_search step 372 current loss 2.889932, current_train_items 11936.\n",
      "2023-03-23 10:56:29,431 - root - INFO - Algo binary_search step 373 current loss 3.782750, current_train_items 11968.\n",
      "2023-03-23 10:56:29,469 - root - INFO - Algo binary_search step 374 current loss 4.124821, current_train_items 12000.\n",
      "2023-03-23 10:56:29,476 - root - INFO - Algo binary_search step 375 current loss 0.978314, current_train_items 12032.\n",
      "2023-03-23 10:56:29,493 - root - INFO - Algo binary_search step 376 current loss 1.900434, current_train_items 12064.\n",
      "2023-03-23 10:56:29,519 - root - INFO - Algo binary_search step 377 current loss 2.774110, current_train_items 12096.\n",
      "2023-03-23 10:56:29,550 - root - INFO - Algo binary_search step 378 current loss 2.928398, current_train_items 12128.\n",
      "2023-03-23 10:56:29,588 - root - INFO - Algo binary_search step 379 current loss 4.118399, current_train_items 12160.\n",
      "2023-03-23 10:56:29,596 - root - INFO - Algo binary_search step 380 current loss 0.692408, current_train_items 12192.\n",
      "2023-03-23 10:56:29,612 - root - INFO - Algo binary_search step 381 current loss 1.843056, current_train_items 12224.\n",
      "2023-03-23 10:56:29,639 - root - INFO - Algo binary_search step 382 current loss 3.063802, current_train_items 12256.\n",
      "2023-03-23 10:56:29,670 - root - INFO - Algo binary_search step 383 current loss 3.768609, current_train_items 12288.\n",
      "2023-03-23 09:56:18,048 - root - INFO - Algo binary_search step 384 current loss 5.004218, current_train_items 12320.\n",
      "2023-03-23 09:56:18,057 - root - INFO - Algo binary_search step 385 current loss 1.117599, current_train_items 12352.\n",
      "2023-03-23 09:56:18,076 - root - INFO - Algo binary_search step 386 current loss 2.191499, current_train_items 12384.\n",
      "2023-03-23 09:56:18,103 - root - INFO - Algo binary_search step 387 current loss 3.064389, current_train_items 12416.\n",
      "2023-03-23 09:56:18,163 - root - INFO - Algo binary_search step 388 current loss 3.030267, current_train_items 12448.\n",
      "2023-03-23 09:56:18,221 - root - INFO - Algo binary_search step 389 current loss 3.878005, current_train_items 12480.\n",
      "2023-03-23 09:56:18,231 - root - INFO - Algo binary_search step 390 current loss 0.725269, current_train_items 12512.\n",
      "2023-03-23 09:56:18,250 - root - INFO - Algo binary_search step 391 current loss 1.582728, current_train_items 12544.\n",
      "2023-03-23 09:56:18,279 - root - INFO - Algo binary_search step 392 current loss 2.843823, current_train_items 12576.\n",
      "2023-03-23 09:56:18,311 - root - INFO - Algo binary_search step 393 current loss 3.354927, current_train_items 12608.\n",
      "2023-03-23 09:56:18,350 - root - INFO - Algo binary_search step 394 current loss 3.617222, current_train_items 12640.\n",
      "2023-03-23 09:56:18,358 - root - INFO - Algo binary_search step 395 current loss 1.191710, current_train_items 12672.\n",
      "2023-03-23 09:56:18,377 - root - INFO - Algo binary_search step 396 current loss 1.625610, current_train_items 12704.\n",
      "2023-03-23 09:56:18,403 - root - INFO - Algo binary_search step 397 current loss 3.600028, current_train_items 12736.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 09:56:18,435 - root - INFO - Algo binary_search step 398 current loss 4.322250, current_train_items 12768.\n",
      "2023-03-23 09:56:18,474 - root - INFO - Algo binary_search step 399 current loss 4.094738, current_train_items 12800.\n",
      "2023-03-23 09:56:18,483 - root - INFO - Algo binary_search step 400 current loss 0.450725, current_train_items 12832.\n",
      "2023-03-23 09:56:21,021 - root - INFO - (val) algo binary_search step 400: {'return': 0.6318359375, 'score': 0.6318359375, 'examples_seen': 12832, 'step': 400, 'algorithm': 'binary_search'}\n",
      "2023-03-23 09:56:21,025 - root - INFO - Not saving new best model, best avg val score was 0.828, current avg val score is 0.632, val scores are: binary_search: 0.632\n",
      "2023-03-23 09:56:21,044 - root - INFO - Algo binary_search step 401 current loss 2.042456, current_train_items 12864.\n",
      "2023-03-23 09:56:21,073 - root - INFO - Algo binary_search step 402 current loss 4.357592, current_train_items 12896.\n",
      "2023-03-23 09:56:21,111 - root - INFO - Algo binary_search step 403 current loss 3.764925, current_train_items 12928.\n",
      "2023-03-23 09:56:21,166 - root - INFO - Algo binary_search step 404 current loss 3.717284, current_train_items 12960.\n",
      "2023-03-23 09:56:21,174 - root - INFO - Algo binary_search step 405 current loss 1.100774, current_train_items 12992.\n",
      "2023-03-23 09:56:21,191 - root - INFO - Algo binary_search step 406 current loss 1.987715, current_train_items 13024.\n",
      "2023-03-23 09:56:21,217 - root - INFO - Algo binary_search step 407 current loss 3.366184, current_train_items 13056.\n",
      "2023-03-23 09:56:21,250 - root - INFO - Algo binary_search step 408 current loss 3.595825, current_train_items 13088.\n",
      "2023-03-23 09:56:21,292 - root - INFO - Algo binary_search step 409 current loss 4.139848, current_train_items 13120.\n",
      "2023-03-23 09:56:21,300 - root - INFO - Algo binary_search step 410 current loss 0.565309, current_train_items 13152.\n",
      "2023-03-23 09:56:21,317 - root - INFO - Algo binary_search step 411 current loss 2.250546, current_train_items 13184.\n",
      "2023-03-23 09:56:21,344 - root - INFO - Algo binary_search step 412 current loss 3.571389, current_train_items 13216.\n",
      "2023-03-23 09:56:21,387 - root - INFO - Algo binary_search step 413 current loss 4.322496, current_train_items 13248.\n",
      "2023-03-23 09:56:21,459 - root - INFO - Algo binary_search step 414 current loss 3.613045, current_train_items 13280.\n",
      "2023-03-23 09:56:21,468 - root - INFO - Algo binary_search step 415 current loss 0.688909, current_train_items 13312.\n",
      "2023-03-23 09:56:21,484 - root - INFO - Algo binary_search step 416 current loss 1.960258, current_train_items 13344.\n",
      "2023-03-23 09:56:21,511 - root - INFO - Algo binary_search step 417 current loss 3.432342, current_train_items 13376.\n",
      "2023-03-23 09:56:21,541 - root - INFO - Algo binary_search step 418 current loss 3.432966, current_train_items 13408.\n",
      "2023-03-23 09:56:21,578 - root - INFO - Algo binary_search step 419 current loss 4.427093, current_train_items 13440.\n",
      "2023-03-23 09:56:21,586 - root - INFO - Algo binary_search step 420 current loss 0.812818, current_train_items 13472.\n",
      "2023-03-23 09:56:21,601 - root - INFO - Algo binary_search step 421 current loss 2.556655, current_train_items 13504.\n",
      "2023-03-23 09:56:21,626 - root - INFO - Algo binary_search step 422 current loss 3.740735, current_train_items 13536.\n",
      "2023-03-23 09:56:21,655 - root - INFO - Algo binary_search step 423 current loss 3.843103, current_train_items 13568.\n",
      "2023-03-23 09:56:21,696 - root - INFO - Algo binary_search step 424 current loss 4.844922, current_train_items 13600.\n",
      "2023-03-23 09:56:21,704 - root - INFO - Algo binary_search step 425 current loss 1.688087, current_train_items 13632.\n",
      "2023-03-23 09:56:21,720 - root - INFO - Algo binary_search step 426 current loss 2.053505, current_train_items 13664.\n",
      "2023-03-23 09:56:21,746 - root - INFO - Algo binary_search step 427 current loss 3.571461, current_train_items 13696.\n",
      "2023-03-23 09:56:21,777 - root - INFO - Algo binary_search step 428 current loss 4.303271, current_train_items 13728.\n",
      "2023-03-23 09:56:21,900 - root - INFO - Algo binary_search step 429 current loss 4.054379, current_train_items 13760.\n",
      "2023-03-23 09:56:21,910 - root - INFO - Algo binary_search step 430 current loss 0.879065, current_train_items 13792.\n",
      "2023-03-23 09:56:21,927 - root - INFO - Algo binary_search step 431 current loss 1.533317, current_train_items 13824.\n",
      "2023-03-23 09:56:21,962 - root - INFO - Algo binary_search step 432 current loss 2.626345, current_train_items 13856.\n",
      "2023-03-23 09:56:21,994 - root - INFO - Algo binary_search step 433 current loss 3.191552, current_train_items 13888.\n",
      "2023-03-23 09:56:22,051 - root - INFO - Algo binary_search step 434 current loss 3.843140, current_train_items 13920.\n",
      "2023-03-23 09:56:22,059 - root - INFO - Algo binary_search step 435 current loss 0.453055, current_train_items 13952.\n",
      "2023-03-23 09:56:22,075 - root - INFO - Algo binary_search step 436 current loss 1.394342, current_train_items 13984.\n",
      "2023-03-23 09:56:22,101 - root - INFO - Algo binary_search step 437 current loss 2.737268, current_train_items 14016.\n",
      "2023-03-23 09:56:22,133 - root - INFO - Algo binary_search step 438 current loss 3.293430, current_train_items 14048.\n",
      "2023-03-23 09:56:22,172 - root - INFO - Algo binary_search step 439 current loss 3.373532, current_train_items 14080.\n",
      "2023-03-23 09:56:22,181 - root - INFO - Algo binary_search step 440 current loss 0.941145, current_train_items 14112.\n",
      "2023-03-23 09:56:22,197 - root - INFO - Algo binary_search step 441 current loss 2.005469, current_train_items 14144.\n",
      "2023-03-23 09:56:22,224 - root - INFO - Algo binary_search step 442 current loss 3.108173, current_train_items 14176.\n",
      "2023-03-23 09:56:22,255 - root - INFO - Algo binary_search step 443 current loss 2.803837, current_train_items 14208.\n",
      "2023-03-23 09:56:22,294 - root - INFO - Algo binary_search step 444 current loss 3.985677, current_train_items 14240.\n",
      "2023-03-23 09:56:22,301 - root - INFO - Algo binary_search step 445 current loss 0.812499, current_train_items 14272.\n",
      "2023-03-23 09:56:22,318 - root - INFO - Algo binary_search step 446 current loss 1.682678, current_train_items 14304.\n",
      "2023-03-23 09:56:22,344 - root - INFO - Algo binary_search step 447 current loss 2.529482, current_train_items 14336.\n",
      "2023-03-23 09:56:22,376 - root - INFO - Algo binary_search step 448 current loss 2.912470, current_train_items 14368.\n",
      "2023-03-23 09:56:22,414 - root - INFO - Algo binary_search step 449 current loss 3.714122, current_train_items 14400.\n",
      "2023-03-23 09:56:22,422 - root - INFO - Algo binary_search step 450 current loss 0.760530, current_train_items 14432.\n",
      "2023-03-23 09:56:24,704 - root - INFO - (val) algo binary_search step 450: {'return': 0.897216796875, 'score': 0.897216796875, 'examples_seen': 14432, 'step': 450, 'algorithm': 'binary_search'}\n",
      "2023-03-23 09:56:24,705 - root - INFO - Checkpointing best model, best avg val score was 0.828, current avg val score is 0.897, val scores are: binary_search: 0.897\n",
      "2023-03-23 09:56:24,726 - root - INFO - Algo binary_search step 451 current loss 1.286659, current_train_items 14464.\n",
      "2023-03-23 09:56:24,755 - root - INFO - Algo binary_search step 452 current loss 2.651958, current_train_items 14496.\n",
      "2023-03-23 09:56:24,786 - root - INFO - Algo binary_search step 453 current loss 2.620520, current_train_items 14528.\n",
      "2023-03-23 09:56:24,824 - root - INFO - Algo binary_search step 454 current loss 3.273543, current_train_items 14560.\n",
      "2023-03-23 09:56:24,833 - root - INFO - Algo binary_search step 455 current loss 0.769580, current_train_items 14592.\n",
      "2023-03-23 09:56:24,850 - root - INFO - Algo binary_search step 456 current loss 1.786036, current_train_items 14624.\n",
      "2023-03-23 09:56:24,876 - root - INFO - Algo binary_search step 457 current loss 2.228709, current_train_items 14656.\n",
      "2023-03-23 09:56:24,907 - root - INFO - Algo binary_search step 458 current loss 2.576475, current_train_items 14688.\n",
      "2023-03-23 09:56:24,945 - root - INFO - Algo binary_search step 459 current loss 3.581008, current_train_items 14720.\n",
      "2023-03-23 09:56:24,954 - root - INFO - Algo binary_search step 460 current loss 0.704036, current_train_items 14752.\n",
      "2023-03-23 09:56:24,970 - root - INFO - Algo binary_search step 461 current loss 1.736850, current_train_items 14784.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 09:56:24,995 - root - INFO - Algo binary_search step 462 current loss 2.550913, current_train_items 14816.\n",
      "2023-03-23 09:56:25,025 - root - INFO - Algo binary_search step 463 current loss 3.123833, current_train_items 14848.\n",
      "2023-03-23 09:56:25,064 - root - INFO - Algo binary_search step 464 current loss 4.423604, current_train_items 14880.\n",
      "2023-03-23 09:56:25,072 - root - INFO - Algo binary_search step 465 current loss 0.715862, current_train_items 14912.\n",
      "2023-03-23 09:56:25,088 - root - INFO - Algo binary_search step 466 current loss 1.510598, current_train_items 14944.\n",
      "2023-03-23 09:56:25,140 - root - INFO - Algo binary_search step 467 current loss 2.273409, current_train_items 14976.\n",
      "2023-03-23 09:56:25,191 - root - INFO - Algo binary_search step 468 current loss 2.992526, current_train_items 15008.\n",
      "2023-03-23 09:56:25,230 - root - INFO - Algo binary_search step 469 current loss 3.514890, current_train_items 15040.\n",
      "2023-03-23 09:56:25,238 - root - INFO - Algo binary_search step 470 current loss 0.431834, current_train_items 15072.\n",
      "2023-03-23 09:56:25,253 - root - INFO - Algo binary_search step 471 current loss 1.521427, current_train_items 15104.\n",
      "2023-03-23 09:56:25,279 - root - INFO - Algo binary_search step 472 current loss 2.502328, current_train_items 15136.\n",
      "2023-03-23 09:56:25,309 - root - INFO - Algo binary_search step 473 current loss 2.633887, current_train_items 15168.\n",
      "2023-03-23 09:56:25,346 - root - INFO - Algo binary_search step 474 current loss 4.433017, current_train_items 15200.\n",
      "2023-03-23 09:56:25,354 - root - INFO - Algo binary_search step 475 current loss 0.744354, current_train_items 15232.\n",
      "2023-03-23 09:56:25,370 - root - INFO - Algo binary_search step 476 current loss 1.820907, current_train_items 15264.\n",
      "2023-03-23 09:56:25,395 - root - INFO - Algo binary_search step 477 current loss 3.055307, current_train_items 15296.\n",
      "2023-03-23 09:56:25,425 - root - INFO - Algo binary_search step 478 current loss 3.809840, current_train_items 15328.\n",
      "2023-03-23 09:56:25,462 - root - INFO - Algo binary_search step 479 current loss 3.717701, current_train_items 15360.\n",
      "2023-03-23 09:56:25,469 - root - INFO - Algo binary_search step 480 current loss 0.460728, current_train_items 15392.\n",
      "2023-03-23 09:56:25,485 - root - INFO - Algo binary_search step 481 current loss 1.302595, current_train_items 15424.\n",
      "2023-03-23 09:56:25,510 - root - INFO - Algo binary_search step 482 current loss 2.523597, current_train_items 15456.\n",
      "2023-03-23 09:56:25,540 - root - INFO - Algo binary_search step 483 current loss 3.338085, current_train_items 15488.\n",
      "2023-03-23 09:56:25,577 - root - INFO - Algo binary_search step 484 current loss 3.595056, current_train_items 15520.\n",
      "2023-03-23 09:56:25,584 - root - INFO - Algo binary_search step 485 current loss 0.605789, current_train_items 15552.\n",
      "2023-03-23 09:56:25,599 - root - INFO - Algo binary_search step 486 current loss 1.866734, current_train_items 15584.\n",
      "2023-03-23 09:56:25,624 - root - INFO - Algo binary_search step 487 current loss 2.392738, current_train_items 15616.\n",
      "2023-03-23 09:56:25,653 - root - INFO - Algo binary_search step 488 current loss 2.636877, current_train_items 15648.\n",
      "2023-03-23 09:56:25,690 - root - INFO - Algo binary_search step 489 current loss 3.427515, current_train_items 15680.\n",
      "2023-03-23 09:56:25,697 - root - INFO - Algo binary_search step 490 current loss 0.609676, current_train_items 15712.\n",
      "2023-03-23 09:56:25,712 - root - INFO - Algo binary_search step 491 current loss 1.010127, current_train_items 15744.\n",
      "2023-03-23 09:56:25,737 - root - INFO - Algo binary_search step 492 current loss 2.892736, current_train_items 15776.\n",
      "2023-03-23 09:56:25,766 - root - INFO - Algo binary_search step 493 current loss 3.658438, current_train_items 15808.\n",
      "2023-03-23 09:56:25,803 - root - INFO - Algo binary_search step 494 current loss 4.246600, current_train_items 15840.\n",
      "2023-03-23 09:56:25,811 - root - INFO - Algo binary_search step 495 current loss 0.825478, current_train_items 15872.\n",
      "2023-03-23 09:56:25,826 - root - INFO - Algo binary_search step 496 current loss 1.515627, current_train_items 15904.\n",
      "2023-03-23 09:56:25,851 - root - INFO - Algo binary_search step 497 current loss 3.138358, current_train_items 15936.\n",
      "2023-03-23 09:56:25,880 - root - INFO - Algo binary_search step 498 current loss 3.150690, current_train_items 15968.\n",
      "2023-03-23 09:56:25,917 - root - INFO - Algo binary_search step 499 current loss 3.671061, current_train_items 16000.\n",
      "2023-03-23 09:56:25,924 - root - INFO - Algo binary_search step 500 current loss 0.885187, current_train_items 16032.\n",
      "2023-03-23 09:56:28,192 - root - INFO - (val) algo binary_search step 500: {'return': 0.7880859375, 'score': 0.7880859375, 'examples_seen': 16032, 'step': 500, 'algorithm': 'binary_search'}\n",
      "2023-03-23 09:56:28,192 - root - INFO - Not saving new best model, best avg val score was 0.897, current avg val score is 0.788, val scores are: binary_search: 0.788\n",
      "2023-03-23 09:56:28,213 - root - INFO - Algo binary_search step 501 current loss 1.306115, current_train_items 16064.\n",
      "2023-03-23 09:56:28,244 - root - INFO - Algo binary_search step 502 current loss 2.740818, current_train_items 16096.\n",
      "2023-03-23 09:56:28,279 - root - INFO - Algo binary_search step 503 current loss 3.208569, current_train_items 16128.\n",
      "2023-03-23 09:56:28,323 - root - INFO - Algo binary_search step 504 current loss 3.887590, current_train_items 16160.\n",
      "2023-03-23 09:56:28,332 - root - INFO - Algo binary_search step 505 current loss 0.695099, current_train_items 16192.\n",
      "2023-03-23 09:56:28,350 - root - INFO - Algo binary_search step 506 current loss 1.387226, current_train_items 16224.\n",
      "2023-03-23 09:56:28,377 - root - INFO - Algo binary_search step 507 current loss 2.388563, current_train_items 16256.\n",
      "2023-03-23 09:56:28,410 - root - INFO - Algo binary_search step 508 current loss 3.044021, current_train_items 16288.\n",
      "2023-03-23 09:56:28,449 - root - INFO - Algo binary_search step 509 current loss 3.563889, current_train_items 16320.\n",
      "2023-03-23 09:56:28,458 - root - INFO - Algo binary_search step 510 current loss 0.697063, current_train_items 16352.\n",
      "2023-03-23 09:56:28,475 - root - INFO - Algo binary_search step 511 current loss 2.214267, current_train_items 16384.\n",
      "2023-03-23 09:56:28,502 - root - INFO - Algo binary_search step 512 current loss 3.797522, current_train_items 16416.\n",
      "2023-03-23 09:56:28,534 - root - INFO - Algo binary_search step 513 current loss 4.130682, current_train_items 16448.\n",
      "2023-03-23 09:56:28,573 - root - INFO - Algo binary_search step 514 current loss 4.239727, current_train_items 16480.\n",
      "2023-03-23 09:56:28,581 - root - INFO - Algo binary_search step 515 current loss 0.409581, current_train_items 16512.\n",
      "2023-03-23 09:56:28,598 - root - INFO - Algo binary_search step 516 current loss 1.202310, current_train_items 16544.\n",
      "2023-03-23 09:56:28,626 - root - INFO - Algo binary_search step 517 current loss 2.428503, current_train_items 16576.\n",
      "2023-03-23 09:56:28,657 - root - INFO - Algo binary_search step 518 current loss 3.591460, current_train_items 16608.\n",
      "2023-03-23 09:56:28,695 - root - INFO - Algo binary_search step 519 current loss 4.173136, current_train_items 16640.\n",
      "2023-03-23 09:56:28,702 - root - INFO - Algo binary_search step 520 current loss 0.790336, current_train_items 16672.\n",
      "2023-03-23 09:56:28,726 - root - INFO - Algo binary_search step 521 current loss 1.082452, current_train_items 16704.\n",
      "2023-03-23 09:56:28,778 - root - INFO - Algo binary_search step 522 current loss 2.557869, current_train_items 16736.\n",
      "2023-03-23 09:56:28,809 - root - INFO - Algo binary_search step 523 current loss 2.817342, current_train_items 16768.\n",
      "2023-03-23 09:56:28,848 - root - INFO - Algo binary_search step 524 current loss 4.139346, current_train_items 16800.\n",
      "2023-03-23 09:56:28,856 - root - INFO - Algo binary_search step 525 current loss 0.328847, current_train_items 16832.\n",
      "2023-03-23 09:56:28,872 - root - INFO - Algo binary_search step 526 current loss 1.627840, current_train_items 16864.\n",
      "2023-03-23 09:56:28,899 - root - INFO - Algo binary_search step 527 current loss 2.705323, current_train_items 16896.\n",
      "2023-03-23 09:56:28,930 - root - INFO - Algo binary_search step 528 current loss 4.106278, current_train_items 16928.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 09:56:28,974 - root - INFO - Algo binary_search step 529 current loss 3.703395, current_train_items 16960.\n",
      "2023-03-23 09:56:28,985 - root - INFO - Algo binary_search step 530 current loss 0.407960, current_train_items 16992.\n",
      "2023-03-23 09:56:29,002 - root - INFO - Algo binary_search step 531 current loss 1.277289, current_train_items 17024.\n",
      "2023-03-23 09:56:29,043 - root - INFO - Algo binary_search step 532 current loss 2.813943, current_train_items 17056.\n",
      "2023-03-23 09:56:29,073 - root - INFO - Algo binary_search step 533 current loss 3.126002, current_train_items 17088.\n",
      "2023-03-23 09:56:29,110 - root - INFO - Algo binary_search step 534 current loss 3.753290, current_train_items 17120.\n",
      "2023-03-23 09:56:29,118 - root - INFO - Algo binary_search step 535 current loss 0.756774, current_train_items 17152.\n",
      "2023-03-23 09:56:29,134 - root - INFO - Algo binary_search step 536 current loss 1.085056, current_train_items 17184.\n",
      "2023-03-23 09:56:29,161 - root - INFO - Algo binary_search step 537 current loss 2.599491, current_train_items 17216.\n",
      "2023-03-23 09:56:29,192 - root - INFO - Algo binary_search step 538 current loss 3.337120, current_train_items 17248.\n",
      "2023-03-23 09:56:29,231 - root - INFO - Algo binary_search step 539 current loss 4.036834, current_train_items 17280.\n",
      "2023-03-23 09:56:29,238 - root - INFO - Algo binary_search step 540 current loss 0.784409, current_train_items 17312.\n",
      "2023-03-23 09:56:29,255 - root - INFO - Algo binary_search step 541 current loss 1.248896, current_train_items 17344.\n",
      "2023-03-23 09:56:29,281 - root - INFO - Algo binary_search step 542 current loss 2.217628, current_train_items 17376.\n",
      "2023-03-23 09:56:29,312 - root - INFO - Algo binary_search step 543 current loss 2.689898, current_train_items 17408.\n",
      "2023-03-23 09:56:29,353 - root - INFO - Algo binary_search step 544 current loss 3.061421, current_train_items 17440.\n",
      "2023-03-23 09:56:29,362 - root - INFO - Algo binary_search step 545 current loss 1.555006, current_train_items 17472.\n",
      "2023-03-23 09:56:29,380 - root - INFO - Algo binary_search step 546 current loss 1.629932, current_train_items 17504.\n",
      "2023-03-23 09:56:29,408 - root - INFO - Algo binary_search step 547 current loss 2.611153, current_train_items 17536.\n",
      "2023-03-23 09:56:29,440 - root - INFO - Algo binary_search step 548 current loss 3.018051, current_train_items 17568.\n",
      "2023-03-23 09:56:29,479 - root - INFO - Algo binary_search step 549 current loss 4.102834, current_train_items 17600.\n",
      "2023-03-23 09:56:29,487 - root - INFO - Algo binary_search step 550 current loss 0.685381, current_train_items 17632.\n",
      "2023-03-23 09:56:31,687 - root - INFO - (val) algo binary_search step 550: {'return': 0.817138671875, 'score': 0.817138671875, 'examples_seen': 17632, 'step': 550, 'algorithm': 'binary_search'}\n",
      "2023-03-23 09:56:31,688 - root - INFO - Not saving new best model, best avg val score was 0.897, current avg val score is 0.817, val scores are: binary_search: 0.817\n",
      "2023-03-23 09:56:31,704 - root - INFO - Algo binary_search step 551 current loss 1.675139, current_train_items 17664.\n",
      "2023-03-23 09:56:31,730 - root - INFO - Algo binary_search step 552 current loss 2.405188, current_train_items 17696.\n",
      "2023-03-23 09:56:31,761 - root - INFO - Algo binary_search step 553 current loss 2.444983, current_train_items 17728.\n",
      "2023-03-23 09:56:31,799 - root - INFO - Algo binary_search step 554 current loss 3.698999, current_train_items 17760.\n",
      "2023-03-23 09:56:31,807 - root - INFO - Algo binary_search step 555 current loss 0.552317, current_train_items 17792.\n",
      "2023-03-23 09:56:31,823 - root - INFO - Algo binary_search step 556 current loss 1.354372, current_train_items 17824.\n",
      "2023-03-23 09:56:31,849 - root - INFO - Algo binary_search step 557 current loss 2.354012, current_train_items 17856.\n",
      "2023-03-23 09:56:31,880 - root - INFO - Algo binary_search step 558 current loss 3.246808, current_train_items 17888.\n",
      "2023-03-23 09:56:31,919 - root - INFO - Algo binary_search step 559 current loss 2.950715, current_train_items 17920.\n",
      "2023-03-23 09:56:31,926 - root - INFO - Algo binary_search step 560 current loss 0.612431, current_train_items 17952.\n",
      "2023-03-23 09:56:31,943 - root - INFO - Algo binary_search step 561 current loss 1.973369, current_train_items 17984.\n",
      "2023-03-23 09:56:31,970 - root - INFO - Algo binary_search step 562 current loss 2.311936, current_train_items 18016.\n",
      "2023-03-23 09:56:32,022 - root - INFO - Algo binary_search step 563 current loss 2.634882, current_train_items 18048.\n",
      "2023-03-23 09:56:32,069 - root - INFO - Algo binary_search step 564 current loss 3.032160, current_train_items 18080.\n",
      "2023-03-23 09:56:32,078 - root - INFO - Algo binary_search step 565 current loss 0.342352, current_train_items 18112.\n",
      "2023-03-23 09:56:32,096 - root - INFO - Algo binary_search step 566 current loss 2.029850, current_train_items 18144.\n",
      "2023-03-23 09:56:32,124 - root - INFO - Algo binary_search step 567 current loss 2.449403, current_train_items 18176.\n",
      "2023-03-23 09:56:32,156 - root - INFO - Algo binary_search step 568 current loss 2.878332, current_train_items 18208.\n",
      "2023-03-23 09:56:32,197 - root - INFO - Algo binary_search step 569 current loss 3.425481, current_train_items 18240.\n",
      "2023-03-23 09:56:32,205 - root - INFO - Algo binary_search step 570 current loss 0.984251, current_train_items 18272.\n",
      "2023-03-23 09:56:32,223 - root - INFO - Algo binary_search step 571 current loss 1.763994, current_train_items 18304.\n",
      "2023-03-23 09:56:32,251 - root - INFO - Algo binary_search step 572 current loss 2.202139, current_train_items 18336.\n",
      "2023-03-23 09:56:32,285 - root - INFO - Algo binary_search step 573 current loss 2.758616, current_train_items 18368.\n",
      "2023-03-23 09:56:32,326 - root - INFO - Algo binary_search step 574 current loss 3.499416, current_train_items 18400.\n",
      "2023-03-23 09:56:32,335 - root - INFO - Algo binary_search step 575 current loss 0.469295, current_train_items 18432.\n",
      "2023-03-23 09:56:32,352 - root - INFO - Algo binary_search step 576 current loss 1.647876, current_train_items 18464.\n",
      "2023-03-23 09:56:32,380 - root - INFO - Algo binary_search step 577 current loss 2.559196, current_train_items 18496.\n",
      "2023-03-23 09:56:32,411 - root - INFO - Algo binary_search step 578 current loss 2.321409, current_train_items 18528.\n",
      "2023-03-23 09:56:32,451 - root - INFO - Algo binary_search step 579 current loss 3.575007, current_train_items 18560.\n",
      "2023-03-23 09:56:32,459 - root - INFO - Algo binary_search step 580 current loss 0.520458, current_train_items 18592.\n",
      "2023-03-23 09:56:32,477 - root - INFO - Algo binary_search step 581 current loss 1.254563, current_train_items 18624.\n",
      "2023-03-23 09:56:32,502 - root - INFO - Algo binary_search step 582 current loss 1.788588, current_train_items 18656.\n",
      "2023-03-23 09:56:32,532 - root - INFO - Algo binary_search step 583 current loss 2.451122, current_train_items 18688.\n",
      "2023-03-23 09:56:32,571 - root - INFO - Algo binary_search step 584 current loss 4.570301, current_train_items 18720.\n",
      "2023-03-23 09:56:32,578 - root - INFO - Algo binary_search step 585 current loss 0.688493, current_train_items 18752.\n",
      "2023-03-23 09:56:32,596 - root - INFO - Algo binary_search step 586 current loss 1.210577, current_train_items 18784.\n",
      "2023-03-23 09:56:32,622 - root - INFO - Algo binary_search step 587 current loss 1.901230, current_train_items 18816.\n",
      "2023-03-23 09:56:32,652 - root - INFO - Algo binary_search step 588 current loss 2.707468, current_train_items 18848.\n",
      "2023-03-23 09:56:32,690 - root - INFO - Algo binary_search step 589 current loss 3.856638, current_train_items 18880.\n",
      "2023-03-23 09:56:32,698 - root - INFO - Algo binary_search step 590 current loss 0.887073, current_train_items 18912.\n",
      "2023-03-23 09:56:32,714 - root - INFO - Algo binary_search step 591 current loss 1.331763, current_train_items 18944.\n",
      "2023-03-23 09:56:32,741 - root - INFO - Algo binary_search step 592 current loss 2.578159, current_train_items 18976.\n",
      "2023-03-23 09:56:32,772 - root - INFO - Algo binary_search step 593 current loss 2.969048, current_train_items 19008.\n",
      "2023-03-23 09:56:32,813 - root - INFO - Algo binary_search step 594 current loss 3.996877, current_train_items 19040.\n",
      "2023-03-23 09:56:32,822 - root - INFO - Algo binary_search step 595 current loss 0.847284, current_train_items 19072.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 09:56:32,839 - root - INFO - Algo binary_search step 596 current loss 1.235948, current_train_items 19104.\n",
      "2023-03-23 09:56:32,867 - root - INFO - Algo binary_search step 597 current loss 1.993064, current_train_items 19136.\n",
      "2023-03-23 09:56:32,901 - root - INFO - Algo binary_search step 598 current loss 2.892847, current_train_items 19168.\n",
      "2023-03-23 09:56:32,941 - root - INFO - Algo binary_search step 599 current loss 3.398289, current_train_items 19200.\n",
      "2023-03-23 09:56:32,950 - root - INFO - Algo binary_search step 600 current loss 0.882334, current_train_items 19232.\n",
      "2023-03-23 09:56:35,167 - root - INFO - (val) algo binary_search step 600: {'return': 0.902099609375, 'score': 0.902099609375, 'examples_seen': 19232, 'step': 600, 'algorithm': 'binary_search'}\n",
      "2023-03-23 09:56:35,167 - root - INFO - Checkpointing best model, best avg val score was 0.897, current avg val score is 0.902, val scores are: binary_search: 0.902\n",
      "2023-03-23 09:56:35,188 - root - INFO - Algo binary_search step 601 current loss 1.355455, current_train_items 19264.\n",
      "2023-03-23 09:56:35,214 - root - INFO - Algo binary_search step 602 current loss 2.150097, current_train_items 19296.\n",
      "2023-03-23 09:56:35,245 - root - INFO - Algo binary_search step 603 current loss 2.577105, current_train_items 19328.\n",
      "2023-03-23 09:56:35,284 - root - INFO - Algo binary_search step 604 current loss 3.375739, current_train_items 19360.\n",
      "2023-03-23 09:56:35,292 - root - INFO - Algo binary_search step 605 current loss 0.302913, current_train_items 19392.\n",
      "2023-03-23 09:56:35,309 - root - INFO - Algo binary_search step 606 current loss 1.450556, current_train_items 19424.\n",
      "2023-03-23 09:56:35,335 - root - INFO - Algo binary_search step 607 current loss 2.175917, current_train_items 19456.\n",
      "2023-03-23 09:56:35,366 - root - INFO - Algo binary_search step 608 current loss 2.432819, current_train_items 19488.\n",
      "2023-03-23 09:56:35,407 - root - INFO - Algo binary_search step 609 current loss 3.599109, current_train_items 19520.\n",
      "2023-03-23 09:56:35,415 - root - INFO - Algo binary_search step 610 current loss 0.228876, current_train_items 19552.\n",
      "2023-03-23 09:56:35,432 - root - INFO - Algo binary_search step 611 current loss 1.248991, current_train_items 19584.\n",
      "2023-03-23 09:56:35,459 - root - INFO - Algo binary_search step 612 current loss 2.400316, current_train_items 19616.\n",
      "2023-03-23 09:56:35,491 - root - INFO - Algo binary_search step 613 current loss 5.451513, current_train_items 19648.\n",
      "2023-03-23 09:56:35,532 - root - INFO - Algo binary_search step 614 current loss 5.530584, current_train_items 19680.\n",
      "2023-03-23 09:56:35,541 - root - INFO - Algo binary_search step 615 current loss 1.010798, current_train_items 19712.\n",
      "2023-03-23 09:56:35,559 - root - INFO - Algo binary_search step 616 current loss 1.017602, current_train_items 19744.\n",
      "2023-03-23 09:56:35,587 - root - INFO - Algo binary_search step 617 current loss 2.525761, current_train_items 19776.\n",
      "2023-03-23 09:56:35,621 - root - INFO - Algo binary_search step 618 current loss 3.105632, current_train_items 19808.\n",
      "2023-03-23 09:56:35,660 - root - INFO - Algo binary_search step 619 current loss 3.956601, current_train_items 19840.\n",
      "2023-03-23 09:56:35,669 - root - INFO - Algo binary_search step 620 current loss 1.202881, current_train_items 19872.\n",
      "2023-03-23 09:56:35,687 - root - INFO - Algo binary_search step 621 current loss 1.416136, current_train_items 19904.\n",
      "2023-03-23 09:56:35,714 - root - INFO - Algo binary_search step 622 current loss 2.561902, current_train_items 19936.\n",
      "2023-03-23 09:56:35,745 - root - INFO - Algo binary_search step 623 current loss 3.565505, current_train_items 19968.\n",
      "2023-03-23 09:56:35,786 - root - INFO - Algo binary_search step 624 current loss 4.204940, current_train_items 20000.\n",
      "2023-03-23 09:56:35,795 - root - INFO - Algo binary_search step 625 current loss 1.053254, current_train_items 20032.\n",
      "2023-03-23 09:56:35,813 - root - INFO - Algo binary_search step 626 current loss 1.461244, current_train_items 20064.\n",
      "2023-03-23 09:56:35,841 - root - INFO - Algo binary_search step 627 current loss 2.455093, current_train_items 20096.\n",
      "2023-03-23 09:56:35,874 - root - INFO - Algo binary_search step 628 current loss 2.770546, current_train_items 20128.\n",
      "2023-03-23 09:56:35,915 - root - INFO - Algo binary_search step 629 current loss 3.320102, current_train_items 20160.\n",
      "2023-03-23 09:56:35,925 - root - INFO - Algo binary_search step 630 current loss 0.554250, current_train_items 20192.\n",
      "2023-03-23 09:56:35,942 - root - INFO - Algo binary_search step 631 current loss 1.260499, current_train_items 20224.\n",
      "2023-03-23 09:56:35,970 - root - INFO - Algo binary_search step 632 current loss 2.489370, current_train_items 20256.\n",
      "2023-03-23 09:56:36,003 - root - INFO - Algo binary_search step 633 current loss 2.404012, current_train_items 20288.\n",
      "2023-03-23 09:56:36,058 - root - INFO - Algo binary_search step 634 current loss 4.380772, current_train_items 20320.\n",
      "2023-03-23 09:56:36,067 - root - INFO - Algo binary_search step 635 current loss 0.560300, current_train_items 20352.\n",
      "2023-03-23 09:56:36,085 - root - INFO - Algo binary_search step 636 current loss 1.392078, current_train_items 20384.\n",
      "2023-03-23 09:56:36,113 - root - INFO - Algo binary_search step 637 current loss 2.669482, current_train_items 20416.\n",
      "2023-03-23 09:56:36,145 - root - INFO - Algo binary_search step 638 current loss 2.308603, current_train_items 20448.\n",
      "2023-03-23 09:56:36,184 - root - INFO - Algo binary_search step 639 current loss 3.340676, current_train_items 20480.\n",
      "2023-03-23 09:56:36,192 - root - INFO - Algo binary_search step 640 current loss 0.296222, current_train_items 20512.\n",
      "2023-03-23 09:56:36,210 - root - INFO - Algo binary_search step 641 current loss 1.342902, current_train_items 20544.\n",
      "2023-03-23 09:56:36,238 - root - INFO - Algo binary_search step 642 current loss 2.227874, current_train_items 20576.\n",
      "2023-03-23 09:56:36,270 - root - INFO - Algo binary_search step 643 current loss 2.312115, current_train_items 20608.\n",
      "2023-03-23 09:56:36,311 - root - INFO - Algo binary_search step 644 current loss 3.052708, current_train_items 20640.\n",
      "2023-03-23 09:56:36,319 - root - INFO - Algo binary_search step 645 current loss 1.068223, current_train_items 20672.\n",
      "2023-03-23 09:56:36,337 - root - INFO - Algo binary_search step 646 current loss 1.645728, current_train_items 20704.\n",
      "2023-03-23 09:56:36,365 - root - INFO - Algo binary_search step 647 current loss 1.833413, current_train_items 20736.\n",
      "2023-03-23 09:56:36,398 - root - INFO - Algo binary_search step 648 current loss 2.260641, current_train_items 20768.\n",
      "2023-03-23 09:56:36,438 - root - INFO - Algo binary_search step 649 current loss 3.158180, current_train_items 20800.\n",
      "2023-03-23 09:56:36,446 - root - INFO - Algo binary_search step 650 current loss 0.526056, current_train_items 20832.\n",
      "2023-03-23 09:56:38,617 - root - INFO - (val) algo binary_search step 650: {'return': 0.88330078125, 'score': 0.88330078125, 'examples_seen': 20832, 'step': 650, 'algorithm': 'binary_search'}\n",
      "2023-03-23 09:56:38,617 - root - INFO - Not saving new best model, best avg val score was 0.902, current avg val score is 0.883, val scores are: binary_search: 0.883\n",
      "2023-03-23 09:56:38,633 - root - INFO - Algo binary_search step 651 current loss 0.809879, current_train_items 20864.\n",
      "2023-03-23 09:56:38,661 - root - INFO - Algo binary_search step 652 current loss 1.674087, current_train_items 20896.\n",
      "2023-03-23 09:56:38,695 - root - INFO - Algo binary_search step 653 current loss 2.637906, current_train_items 20928.\n",
      "2023-03-23 09:56:38,735 - root - INFO - Algo binary_search step 654 current loss 4.000107, current_train_items 20960.\n",
      "2023-03-23 09:56:38,745 - root - INFO - Algo binary_search step 655 current loss 0.443175, current_train_items 20992.\n",
      "2023-03-23 09:56:38,762 - root - INFO - Algo binary_search step 656 current loss 1.337516, current_train_items 21024.\n",
      "2023-03-23 09:56:38,792 - root - INFO - Algo binary_search step 657 current loss 1.767434, current_train_items 21056.\n",
      "2023-03-23 09:56:38,826 - root - INFO - Algo binary_search step 658 current loss 2.945411, current_train_items 21088.\n",
      "2023-03-23 09:56:38,868 - root - INFO - Algo binary_search step 659 current loss 3.216457, current_train_items 21120.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 09:56:38,877 - root - INFO - Algo binary_search step 660 current loss 0.500361, current_train_items 21152.\n",
      "2023-03-23 09:56:38,894 - root - INFO - Algo binary_search step 661 current loss 1.326054, current_train_items 21184.\n",
      "2023-03-23 09:56:38,922 - root - INFO - Algo binary_search step 662 current loss 1.817952, current_train_items 21216.\n",
      "2023-03-23 09:56:38,955 - root - INFO - Algo binary_search step 663 current loss 2.660838, current_train_items 21248.\n",
      "2023-03-23 09:56:38,996 - root - INFO - Algo binary_search step 664 current loss 3.487111, current_train_items 21280.\n",
      "2023-03-23 09:56:39,005 - root - INFO - Algo binary_search step 665 current loss 0.978258, current_train_items 21312.\n",
      "2023-03-23 09:56:39,034 - root - INFO - Algo binary_search step 666 current loss 1.141056, current_train_items 21344.\n",
      "2023-03-23 09:56:39,061 - root - INFO - Algo binary_search step 667 current loss 2.616483, current_train_items 21376.\n",
      "2023-03-23 09:56:39,093 - root - INFO - Algo binary_search step 668 current loss 3.055800, current_train_items 21408.\n",
      "2023-03-23 09:56:39,130 - root - INFO - Algo binary_search step 669 current loss 3.839355, current_train_items 21440.\n",
      "2023-03-23 09:56:39,138 - root - INFO - Algo binary_search step 670 current loss 0.604871, current_train_items 21472.\n",
      "2023-03-23 09:56:39,154 - root - INFO - Algo binary_search step 671 current loss 1.280064, current_train_items 21504.\n",
      "2023-03-23 09:56:39,181 - root - INFO - Algo binary_search step 672 current loss 2.376698, current_train_items 21536.\n",
      "2023-03-23 09:56:39,214 - root - INFO - Algo binary_search step 673 current loss 3.153853, current_train_items 21568.\n",
      "2023-03-23 09:56:39,253 - root - INFO - Algo binary_search step 674 current loss 3.004882, current_train_items 21600.\n",
      "2023-03-23 09:56:39,262 - root - INFO - Algo binary_search step 675 current loss 0.754794, current_train_items 21632.\n",
      "2023-03-23 09:56:39,279 - root - INFO - Algo binary_search step 676 current loss 1.437576, current_train_items 21664.\n",
      "2023-03-23 09:56:39,307 - root - INFO - Algo binary_search step 677 current loss 2.187935, current_train_items 21696.\n",
      "2023-03-23 09:56:39,339 - root - INFO - Algo binary_search step 678 current loss 2.549550, current_train_items 21728.\n",
      "2023-03-23 09:56:39,379 - root - INFO - Algo binary_search step 679 current loss 4.494502, current_train_items 21760.\n",
      "2023-03-23 09:56:39,388 - root - INFO - Algo binary_search step 680 current loss 0.666514, current_train_items 21792.\n",
      "2023-03-23 09:56:39,404 - root - INFO - Algo binary_search step 681 current loss 1.256176, current_train_items 21824.\n",
      "2023-03-23 09:56:39,432 - root - INFO - Algo binary_search step 682 current loss 1.959655, current_train_items 21856.\n",
      "2023-03-23 09:56:39,463 - root - INFO - Algo binary_search step 683 current loss 2.755331, current_train_items 21888.\n",
      "2023-03-23 09:56:39,501 - root - INFO - Algo binary_search step 684 current loss 4.904130, current_train_items 21920.\n",
      "2023-03-23 09:56:39,509 - root - INFO - Algo binary_search step 685 current loss 1.095088, current_train_items 21952.\n",
      "2023-03-23 09:56:39,527 - root - INFO - Algo binary_search step 686 current loss 1.013670, current_train_items 21984.\n",
      "2023-03-23 09:56:39,554 - root - INFO - Algo binary_search step 687 current loss 2.006938, current_train_items 22016.\n",
      "2023-03-23 09:56:39,586 - root - INFO - Algo binary_search step 688 current loss 2.378877, current_train_items 22048.\n",
      "2023-03-23 09:56:39,627 - root - INFO - Algo binary_search step 689 current loss 3.762445, current_train_items 22080.\n",
      "2023-03-23 09:56:39,636 - root - INFO - Algo binary_search step 690 current loss 0.322575, current_train_items 22112.\n",
      "2023-03-23 09:56:39,654 - root - INFO - Algo binary_search step 691 current loss 1.332056, current_train_items 22144.\n",
      "2023-03-23 09:56:39,682 - root - INFO - Algo binary_search step 692 current loss 2.452726, current_train_items 22176.\n",
      "2023-03-23 09:56:39,714 - root - INFO - Algo binary_search step 693 current loss 2.096785, current_train_items 22208.\n",
      "2023-03-23 09:56:39,756 - root - INFO - Algo binary_search step 694 current loss 4.498909, current_train_items 22240.\n",
      "2023-03-23 09:56:39,764 - root - INFO - Algo binary_search step 695 current loss 0.340367, current_train_items 22272.\n",
      "2023-03-23 09:56:39,781 - root - INFO - Algo binary_search step 696 current loss 1.117085, current_train_items 22304.\n",
      "2023-03-23 09:56:39,808 - root - INFO - Algo binary_search step 697 current loss 2.427105, current_train_items 22336.\n",
      "2023-03-23 09:56:39,838 - root - INFO - Algo binary_search step 698 current loss 2.394154, current_train_items 22368.\n",
      "2023-03-23 09:56:39,876 - root - INFO - Algo binary_search step 699 current loss 3.766576, current_train_items 22400.\n",
      "2023-03-23 09:56:39,884 - root - INFO - Algo binary_search step 700 current loss 1.485597, current_train_items 22432.\n",
      "2023-03-23 09:56:42,120 - root - INFO - (val) algo binary_search step 700: {'return': 0.731201171875, 'score': 0.731201171875, 'examples_seen': 22432, 'step': 700, 'algorithm': 'binary_search'}\n",
      "2023-03-23 09:56:42,121 - root - INFO - Not saving new best model, best avg val score was 0.902, current avg val score is 0.731, val scores are: binary_search: 0.731\n",
      "2023-03-23 09:56:42,137 - root - INFO - Algo binary_search step 701 current loss 1.429758, current_train_items 22464.\n",
      "2023-03-23 09:56:42,165 - root - INFO - Algo binary_search step 702 current loss 2.112365, current_train_items 22496.\n",
      "2023-03-23 09:56:42,195 - root - INFO - Algo binary_search step 703 current loss 2.517707, current_train_items 22528.\n",
      "2023-03-23 09:56:42,235 - root - INFO - Algo binary_search step 704 current loss 3.261961, current_train_items 22560.\n",
      "2023-03-23 09:56:42,243 - root - INFO - Algo binary_search step 705 current loss 1.118640, current_train_items 22592.\n",
      "2023-03-23 09:56:42,260 - root - INFO - Algo binary_search step 706 current loss 1.416651, current_train_items 22624.\n",
      "2023-03-23 09:56:42,286 - root - INFO - Algo binary_search step 707 current loss 2.222043, current_train_items 22656.\n",
      "2023-03-23 09:56:42,333 - root - INFO - Algo binary_search step 708 current loss 1.994111, current_train_items 22688.\n",
      "2023-03-23 09:56:42,371 - root - INFO - Algo binary_search step 709 current loss 3.141891, current_train_items 22720.\n",
      "2023-03-23 09:56:42,379 - root - INFO - Algo binary_search step 710 current loss 0.872920, current_train_items 22752.\n",
      "2023-03-23 09:56:42,396 - root - INFO - Algo binary_search step 711 current loss 0.843109, current_train_items 22784.\n",
      "2023-03-23 09:56:42,423 - root - INFO - Algo binary_search step 712 current loss 2.471102, current_train_items 22816.\n",
      "2023-03-23 09:56:42,454 - root - INFO - Algo binary_search step 713 current loss 3.236092, current_train_items 22848.\n",
      "2023-03-23 09:56:42,492 - root - INFO - Algo binary_search step 714 current loss 3.974033, current_train_items 22880.\n",
      "2023-03-23 09:56:42,499 - root - INFO - Algo binary_search step 715 current loss 0.668144, current_train_items 22912.\n",
      "2023-03-23 09:56:42,516 - root - INFO - Algo binary_search step 716 current loss 1.684381, current_train_items 22944.\n",
      "2023-03-23 09:56:42,542 - root - INFO - Algo binary_search step 717 current loss 2.456800, current_train_items 22976.\n",
      "2023-03-23 09:56:42,572 - root - INFO - Algo binary_search step 718 current loss 3.033498, current_train_items 23008.\n",
      "2023-03-23 09:56:42,612 - root - INFO - Algo binary_search step 719 current loss 3.339298, current_train_items 23040.\n",
      "2023-03-23 09:56:42,622 - root - INFO - Algo binary_search step 720 current loss 0.842153, current_train_items 23072.\n",
      "2023-03-23 09:56:42,639 - root - INFO - Algo binary_search step 721 current loss 1.780177, current_train_items 23104.\n",
      "2023-03-23 09:56:42,665 - root - INFO - Algo binary_search step 722 current loss 2.290526, current_train_items 23136.\n",
      "2023-03-23 09:56:42,696 - root - INFO - Algo binary_search step 723 current loss 2.064333, current_train_items 23168.\n",
      "2023-03-23 09:56:42,733 - root - INFO - Algo binary_search step 724 current loss 2.943072, current_train_items 23200.\n",
      "2023-03-23 09:56:42,740 - root - INFO - Algo binary_search step 725 current loss 0.352081, current_train_items 23232.\n",
      "2023-03-23 09:56:42,757 - root - INFO - Algo binary_search step 726 current loss 1.029343, current_train_items 23264.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 09:56:42,784 - root - INFO - Algo binary_search step 727 current loss 1.585537, current_train_items 23296.\n",
      "2023-03-23 09:56:42,815 - root - INFO - Algo binary_search step 728 current loss 1.845163, current_train_items 23328.\n",
      "2023-03-23 09:56:42,853 - root - INFO - Algo binary_search step 729 current loss 3.426191, current_train_items 23360.\n",
      "2023-03-23 09:56:42,861 - root - INFO - Algo binary_search step 730 current loss 1.116132, current_train_items 23392.\n",
      "2023-03-23 09:56:42,877 - root - INFO - Algo binary_search step 731 current loss 1.922843, current_train_items 23424.\n",
      "2023-03-23 09:56:42,903 - root - INFO - Algo binary_search step 732 current loss 2.877601, current_train_items 23456.\n",
      "2023-03-23 09:56:42,934 - root - INFO - Algo binary_search step 733 current loss 4.109115, current_train_items 23488.\n",
      "2023-03-23 09:56:42,971 - root - INFO - Algo binary_search step 734 current loss 4.122854, current_train_items 23520.\n",
      "2023-03-23 09:56:42,979 - root - INFO - Algo binary_search step 735 current loss 0.965200, current_train_items 23552.\n",
      "2023-03-23 09:56:42,996 - root - INFO - Algo binary_search step 736 current loss 1.315581, current_train_items 23584.\n",
      "2023-03-23 09:56:43,020 - root - INFO - Algo binary_search step 737 current loss 2.148126, current_train_items 23616.\n",
      "2023-03-23 09:56:43,052 - root - INFO - Algo binary_search step 738 current loss 2.306278, current_train_items 23648.\n",
      "2023-03-23 09:56:43,103 - root - INFO - Algo binary_search step 739 current loss 3.376508, current_train_items 23680.\n",
      "2023-03-23 09:56:43,110 - root - INFO - Algo binary_search step 740 current loss 0.431305, current_train_items 23712.\n",
      "2023-03-23 09:56:43,127 - root - INFO - Algo binary_search step 741 current loss 1.733548, current_train_items 23744.\n",
      "2023-03-23 09:56:43,153 - root - INFO - Algo binary_search step 742 current loss 2.216128, current_train_items 23776.\n",
      "2023-03-23 09:56:43,185 - root - INFO - Algo binary_search step 743 current loss 3.501111, current_train_items 23808.\n",
      "2023-03-23 09:56:43,223 - root - INFO - Algo binary_search step 744 current loss 3.774856, current_train_items 23840.\n",
      "2023-03-23 09:56:43,231 - root - INFO - Algo binary_search step 745 current loss 0.792976, current_train_items 23872.\n",
      "2023-03-23 09:56:43,248 - root - INFO - Algo binary_search step 746 current loss 1.302107, current_train_items 23904.\n",
      "2023-03-23 09:56:43,275 - root - INFO - Algo binary_search step 747 current loss 2.477104, current_train_items 23936.\n",
      "2023-03-23 09:56:43,307 - root - INFO - Algo binary_search step 748 current loss 2.389167, current_train_items 23968.\n",
      "2023-03-23 09:56:43,346 - root - INFO - Algo binary_search step 749 current loss 3.611777, current_train_items 24000.\n",
      "2023-03-23 09:56:43,353 - root - INFO - Algo binary_search step 750 current loss 0.436106, current_train_items 24032.\n",
      "2023-03-23 09:56:45,546 - root - INFO - (val) algo binary_search step 750: {'return': 0.873046875, 'score': 0.873046875, 'examples_seen': 24032, 'step': 750, 'algorithm': 'binary_search'}\n",
      "2023-03-23 09:56:45,546 - root - INFO - Not saving new best model, best avg val score was 0.902, current avg val score is 0.873, val scores are: binary_search: 0.873\n",
      "2023-03-23 09:56:45,563 - root - INFO - Algo binary_search step 751 current loss 0.931670, current_train_items 24064.\n",
      "2023-03-23 09:56:45,590 - root - INFO - Algo binary_search step 752 current loss 2.104408, current_train_items 24096.\n",
      "2023-03-23 09:56:45,621 - root - INFO - Algo binary_search step 753 current loss 2.432397, current_train_items 24128.\n",
      "2023-03-23 09:56:45,665 - root - INFO - Algo binary_search step 754 current loss 3.041717, current_train_items 24160.\n",
      "2023-03-23 09:56:45,673 - root - INFO - Algo binary_search step 755 current loss 0.520865, current_train_items 24192.\n",
      "2023-03-23 09:56:45,690 - root - INFO - Algo binary_search step 756 current loss 1.640852, current_train_items 24224.\n",
      "2023-03-23 09:56:45,716 - root - INFO - Algo binary_search step 757 current loss 1.630578, current_train_items 24256.\n",
      "2023-03-23 09:56:45,747 - root - INFO - Algo binary_search step 758 current loss 2.537316, current_train_items 24288.\n",
      "2023-03-23 09:56:45,785 - root - INFO - Algo binary_search step 759 current loss 3.291450, current_train_items 24320.\n",
      "2023-03-23 09:56:45,793 - root - INFO - Algo binary_search step 760 current loss 0.671335, current_train_items 24352.\n",
      "2023-03-23 09:56:45,809 - root - INFO - Algo binary_search step 761 current loss 2.071354, current_train_items 24384.\n",
      "2023-03-23 09:56:45,836 - root - INFO - Algo binary_search step 762 current loss 1.826460, current_train_items 24416.\n",
      "2023-03-23 09:56:45,866 - root - INFO - Algo binary_search step 763 current loss 2.234258, current_train_items 24448.\n",
      "2023-03-23 09:56:45,904 - root - INFO - Algo binary_search step 764 current loss 3.894081, current_train_items 24480.\n",
      "2023-03-23 09:56:45,912 - root - INFO - Algo binary_search step 765 current loss 0.334327, current_train_items 24512.\n",
      "2023-03-23 09:56:45,928 - root - INFO - Algo binary_search step 766 current loss 1.423417, current_train_items 24544.\n",
      "2023-03-23 09:56:45,953 - root - INFO - Algo binary_search step 767 current loss 2.063282, current_train_items 24576.\n",
      "2023-03-23 09:56:45,984 - root - INFO - Algo binary_search step 768 current loss 2.512413, current_train_items 24608.\n",
      "2023-03-23 09:56:46,034 - root - INFO - Algo binary_search step 769 current loss 3.376099, current_train_items 24640.\n",
      "2023-03-23 09:56:46,041 - root - INFO - Algo binary_search step 770 current loss 0.501425, current_train_items 24672.\n",
      "2023-03-23 09:56:46,058 - root - INFO - Algo binary_search step 771 current loss 1.176596, current_train_items 24704.\n",
      "2023-03-23 09:56:46,084 - root - INFO - Algo binary_search step 772 current loss 2.335118, current_train_items 24736.\n",
      "2023-03-23 09:56:46,114 - root - INFO - Algo binary_search step 773 current loss 2.537617, current_train_items 24768.\n",
      "2023-03-23 09:56:46,152 - root - INFO - Algo binary_search step 774 current loss 3.332491, current_train_items 24800.\n",
      "2023-03-23 09:56:46,159 - root - INFO - Algo binary_search step 775 current loss 0.688947, current_train_items 24832.\n",
      "2023-03-23 09:56:46,176 - root - INFO - Algo binary_search step 776 current loss 0.982912, current_train_items 24864.\n",
      "2023-03-23 09:56:46,201 - root - INFO - Algo binary_search step 777 current loss 2.225521, current_train_items 24896.\n",
      "2023-03-23 09:56:46,234 - root - INFO - Algo binary_search step 778 current loss 2.557493, current_train_items 24928.\n",
      "2023-03-23 09:56:46,273 - root - INFO - Algo binary_search step 779 current loss 2.748538, current_train_items 24960.\n",
      "2023-03-23 09:56:46,281 - root - INFO - Algo binary_search step 780 current loss 0.421285, current_train_items 24992.\n",
      "2023-03-23 09:56:46,298 - root - INFO - Algo binary_search step 781 current loss 1.182533, current_train_items 25024.\n",
      "2023-03-23 09:56:46,325 - root - INFO - Algo binary_search step 782 current loss 4.034111, current_train_items 25056.\n",
      "2023-03-23 09:56:46,356 - root - INFO - Algo binary_search step 783 current loss 4.240027, current_train_items 25088.\n",
      "2023-03-23 09:56:46,394 - root - INFO - Algo binary_search step 784 current loss 5.922005, current_train_items 25120.\n",
      "2023-03-23 09:56:46,402 - root - INFO - Algo binary_search step 785 current loss 0.743675, current_train_items 25152.\n",
      "2023-03-23 09:56:46,419 - root - INFO - Algo binary_search step 786 current loss 1.404142, current_train_items 25184.\n",
      "2023-03-23 09:56:46,446 - root - INFO - Algo binary_search step 787 current loss 1.972688, current_train_items 25216.\n",
      "2023-03-23 09:56:46,477 - root - INFO - Algo binary_search step 788 current loss 3.013292, current_train_items 25248.\n",
      "2023-03-23 09:56:46,515 - root - INFO - Algo binary_search step 789 current loss 3.832899, current_train_items 25280.\n",
      "2023-03-23 09:56:46,522 - root - INFO - Algo binary_search step 790 current loss 0.738805, current_train_items 25312.\n",
      "2023-03-23 09:56:46,539 - root - INFO - Algo binary_search step 791 current loss 1.210626, current_train_items 25344.\n",
      "2023-03-23 09:56:46,565 - root - INFO - Algo binary_search step 792 current loss 1.851444, current_train_items 25376.\n",
      "2023-03-23 09:56:46,597 - root - INFO - Algo binary_search step 793 current loss 2.197720, current_train_items 25408.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 09:56:46,635 - root - INFO - Algo binary_search step 794 current loss 2.729894, current_train_items 25440.\n",
      "2023-03-23 09:56:46,642 - root - INFO - Algo binary_search step 795 current loss 0.858472, current_train_items 25472.\n",
      "2023-03-23 09:56:46,660 - root - INFO - Algo binary_search step 796 current loss 0.745255, current_train_items 25504.\n",
      "2023-03-23 09:56:46,686 - root - INFO - Algo binary_search step 797 current loss 1.564073, current_train_items 25536.\n",
      "2023-03-23 09:56:46,720 - root - INFO - Algo binary_search step 798 current loss 1.781281, current_train_items 25568.\n",
      "2023-03-23 09:56:46,760 - root - INFO - Algo binary_search step 799 current loss 2.925053, current_train_items 25600.\n",
      "2023-03-23 09:56:46,769 - root - INFO - Algo binary_search step 800 current loss 0.414793, current_train_items 25632.\n",
      "2023-03-23 09:56:49,007 - root - INFO - (val) algo binary_search step 800: {'return': 0.88037109375, 'score': 0.88037109375, 'examples_seen': 25632, 'step': 800, 'algorithm': 'binary_search'}\n",
      "2023-03-23 09:56:49,007 - root - INFO - Not saving new best model, best avg val score was 0.902, current avg val score is 0.880, val scores are: binary_search: 0.880\n",
      "2023-03-23 09:56:49,027 - root - INFO - Algo binary_search step 801 current loss 1.334925, current_train_items 25664.\n",
      "2023-03-23 09:56:49,056 - root - INFO - Algo binary_search step 802 current loss 1.853533, current_train_items 25696.\n",
      "2023-03-23 09:56:49,088 - root - INFO - Algo binary_search step 803 current loss 2.028136, current_train_items 25728.\n",
      "2023-03-23 09:56:49,129 - root - INFO - Algo binary_search step 804 current loss 2.734197, current_train_items 25760.\n",
      "2023-03-23 09:56:49,137 - root - INFO - Algo binary_search step 805 current loss 0.324611, current_train_items 25792.\n",
      "2023-03-23 09:56:49,153 - root - INFO - Algo binary_search step 806 current loss 0.713567, current_train_items 25824.\n",
      "2023-03-23 09:56:49,180 - root - INFO - Algo binary_search step 807 current loss 1.523568, current_train_items 25856.\n",
      "2023-03-23 09:56:49,211 - root - INFO - Algo binary_search step 808 current loss 1.887805, current_train_items 25888.\n",
      "2023-03-23 09:56:49,251 - root - INFO - Algo binary_search step 809 current loss 3.149467, current_train_items 25920.\n",
      "2023-03-23 09:56:49,259 - root - INFO - Algo binary_search step 810 current loss 0.490049, current_train_items 25952.\n",
      "2023-03-23 09:56:49,276 - root - INFO - Algo binary_search step 811 current loss 1.396912, current_train_items 25984.\n",
      "2023-03-23 09:56:49,302 - root - INFO - Algo binary_search step 812 current loss 1.496565, current_train_items 26016.\n",
      "2023-03-23 09:56:49,333 - root - INFO - Algo binary_search step 813 current loss 2.482274, current_train_items 26048.\n",
      "2023-03-23 09:56:49,370 - root - INFO - Algo binary_search step 814 current loss 3.827843, current_train_items 26080.\n",
      "2023-03-23 09:56:49,378 - root - INFO - Algo binary_search step 815 current loss 1.048467, current_train_items 26112.\n",
      "2023-03-23 09:56:49,394 - root - INFO - Algo binary_search step 816 current loss 1.143497, current_train_items 26144.\n",
      "2023-03-23 09:56:49,421 - root - INFO - Algo binary_search step 817 current loss 1.779370, current_train_items 26176.\n",
      "2023-03-23 09:56:49,453 - root - INFO - Algo binary_search step 818 current loss 2.773568, current_train_items 26208.\n",
      "2023-03-23 09:56:49,490 - root - INFO - Algo binary_search step 819 current loss 3.526646, current_train_items 26240.\n",
      "2023-03-23 09:56:49,498 - root - INFO - Algo binary_search step 820 current loss 0.302204, current_train_items 26272.\n",
      "2023-03-23 09:56:49,515 - root - INFO - Algo binary_search step 821 current loss 0.942582, current_train_items 26304.\n",
      "2023-03-23 09:56:49,541 - root - INFO - Algo binary_search step 822 current loss 1.879971, current_train_items 26336.\n",
      "2023-03-23 09:56:49,572 - root - INFO - Algo binary_search step 823 current loss 2.292592, current_train_items 26368.\n",
      "2023-03-23 09:56:49,610 - root - INFO - Algo binary_search step 824 current loss 3.363160, current_train_items 26400.\n",
      "2023-03-23 09:56:49,618 - root - INFO - Algo binary_search step 825 current loss 0.608248, current_train_items 26432.\n",
      "2023-03-23 09:56:49,634 - root - INFO - Algo binary_search step 826 current loss 1.109850, current_train_items 26464.\n",
      "2023-03-23 09:56:49,660 - root - INFO - Algo binary_search step 827 current loss 1.528823, current_train_items 26496.\n",
      "2023-03-23 09:56:49,690 - root - INFO - Algo binary_search step 828 current loss 1.947354, current_train_items 26528.\n",
      "2023-03-23 09:56:49,727 - root - INFO - Algo binary_search step 829 current loss 2.586645, current_train_items 26560.\n",
      "2023-03-23 09:56:49,735 - root - INFO - Algo binary_search step 830 current loss 0.264808, current_train_items 26592.\n",
      "2023-03-23 09:56:49,752 - root - INFO - Algo binary_search step 831 current loss 0.968270, current_train_items 26624.\n",
      "2023-03-23 09:56:49,785 - root - INFO - Algo binary_search step 832 current loss 1.237284, current_train_items 26656.\n",
      "2023-03-23 09:56:49,831 - root - INFO - Algo binary_search step 833 current loss 2.863757, current_train_items 26688.\n",
      "2023-03-23 09:56:49,870 - root - INFO - Algo binary_search step 834 current loss 3.237615, current_train_items 26720.\n",
      "2023-03-23 09:56:49,878 - root - INFO - Algo binary_search step 835 current loss 0.262266, current_train_items 26752.\n",
      "2023-03-23 09:56:49,894 - root - INFO - Algo binary_search step 836 current loss 1.003427, current_train_items 26784.\n",
      "2023-03-23 09:56:49,921 - root - INFO - Algo binary_search step 837 current loss 1.857061, current_train_items 26816.\n",
      "2023-03-23 09:56:49,952 - root - INFO - Algo binary_search step 838 current loss 2.148894, current_train_items 26848.\n",
      "2023-03-23 09:56:49,990 - root - INFO - Algo binary_search step 839 current loss 3.554385, current_train_items 26880.\n",
      "2023-03-23 09:56:49,999 - root - INFO - Algo binary_search step 840 current loss 0.413498, current_train_items 26912.\n",
      "2023-03-23 09:56:50,016 - root - INFO - Algo binary_search step 841 current loss 1.234018, current_train_items 26944.\n",
      "2023-03-23 09:56:50,042 - root - INFO - Algo binary_search step 842 current loss 1.576857, current_train_items 26976.\n",
      "2023-03-23 09:56:50,073 - root - INFO - Algo binary_search step 843 current loss 1.946531, current_train_items 27008.\n",
      "2023-03-23 09:56:50,111 - root - INFO - Algo binary_search step 844 current loss 3.103052, current_train_items 27040.\n",
      "2023-03-23 09:56:50,119 - root - INFO - Algo binary_search step 845 current loss 0.381499, current_train_items 27072.\n",
      "2023-03-23 09:56:50,136 - root - INFO - Algo binary_search step 846 current loss 0.972628, current_train_items 27104.\n",
      "2023-03-23 09:56:50,163 - root - INFO - Algo binary_search step 847 current loss 1.571164, current_train_items 27136.\n",
      "2023-03-23 09:56:50,193 - root - INFO - Algo binary_search step 848 current loss 2.439090, current_train_items 27168.\n",
      "2023-03-23 09:56:50,233 - root - INFO - Algo binary_search step 849 current loss 2.872834, current_train_items 27200.\n",
      "2023-03-23 09:56:50,242 - root - INFO - Algo binary_search step 850 current loss 0.579501, current_train_items 27232.\n",
      "2023-03-23 09:56:52,407 - root - INFO - (val) algo binary_search step 850: {'return': 0.8564453125, 'score': 0.8564453125, 'examples_seen': 27232, 'step': 850, 'algorithm': 'binary_search'}\n",
      "2023-03-23 09:56:52,407 - root - INFO - Not saving new best model, best avg val score was 0.902, current avg val score is 0.856, val scores are: binary_search: 0.856\n",
      "2023-03-23 09:56:52,425 - root - INFO - Algo binary_search step 851 current loss 0.972657, current_train_items 27264.\n",
      "2023-03-23 09:56:52,453 - root - INFO - Algo binary_search step 852 current loss 2.073161, current_train_items 27296.\n",
      "2023-03-23 09:56:52,486 - root - INFO - Algo binary_search step 853 current loss 1.838389, current_train_items 27328.\n",
      "2023-03-23 09:56:52,525 - root - INFO - Algo binary_search step 854 current loss 2.556900, current_train_items 27360.\n",
      "2023-03-23 09:56:52,534 - root - INFO - Algo binary_search step 855 current loss 0.566302, current_train_items 27392.\n",
      "2023-03-23 09:56:52,552 - root - INFO - Algo binary_search step 856 current loss 0.814819, current_train_items 27424.\n",
      "2023-03-23 09:56:52,579 - root - INFO - Algo binary_search step 857 current loss 2.855650, current_train_items 27456.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 09:56:52,610 - root - INFO - Algo binary_search step 858 current loss 2.959124, current_train_items 27488.\n",
      "2023-03-23 09:56:52,648 - root - INFO - Algo binary_search step 859 current loss 3.625861, current_train_items 27520.\n",
      "2023-03-23 09:56:52,657 - root - INFO - Algo binary_search step 860 current loss 0.879026, current_train_items 27552.\n",
      "2023-03-23 09:56:52,674 - root - INFO - Algo binary_search step 861 current loss 0.980302, current_train_items 27584.\n",
      "2023-03-23 09:56:52,700 - root - INFO - Algo binary_search step 862 current loss 1.773355, current_train_items 27616.\n",
      "2023-03-23 09:56:52,732 - root - INFO - Algo binary_search step 863 current loss 2.163724, current_train_items 27648.\n",
      "2023-03-23 09:56:52,770 - root - INFO - Algo binary_search step 864 current loss 3.323235, current_train_items 27680.\n",
      "2023-03-23 09:56:52,777 - root - INFO - Algo binary_search step 865 current loss 0.499162, current_train_items 27712.\n",
      "2023-03-23 09:56:52,805 - root - INFO - Algo binary_search step 866 current loss 1.237032, current_train_items 27744.\n",
      "2023-03-23 09:56:52,831 - root - INFO - Algo binary_search step 867 current loss 2.295910, current_train_items 27776.\n",
      "2023-03-23 09:56:52,861 - root - INFO - Algo binary_search step 868 current loss 2.757600, current_train_items 27808.\n",
      "2023-03-23 09:56:52,899 - root - INFO - Algo binary_search step 869 current loss 2.713445, current_train_items 27840.\n",
      "2023-03-23 09:56:52,907 - root - INFO - Algo binary_search step 870 current loss 0.693181, current_train_items 27872.\n",
      "2023-03-23 09:56:52,923 - root - INFO - Algo binary_search step 871 current loss 1.289357, current_train_items 27904.\n",
      "2023-03-23 09:56:52,949 - root - INFO - Algo binary_search step 872 current loss 1.902782, current_train_items 27936.\n",
      "2023-03-23 09:56:52,980 - root - INFO - Algo binary_search step 873 current loss 2.410868, current_train_items 27968.\n",
      "2023-03-23 09:56:53,019 - root - INFO - Algo binary_search step 874 current loss 2.839871, current_train_items 28000.\n",
      "2023-03-23 09:56:53,028 - root - INFO - Algo binary_search step 875 current loss 0.345630, current_train_items 28032.\n",
      "2023-03-23 09:56:53,044 - root - INFO - Algo binary_search step 876 current loss 1.570491, current_train_items 28064.\n",
      "2023-03-23 09:56:53,073 - root - INFO - Algo binary_search step 877 current loss 1.453642, current_train_items 28096.\n",
      "2023-03-23 09:56:53,107 - root - INFO - Algo binary_search step 878 current loss 1.967477, current_train_items 28128.\n",
      "2023-03-23 09:56:53,148 - root - INFO - Algo binary_search step 879 current loss 2.629323, current_train_items 28160.\n",
      "2023-03-23 09:56:53,157 - root - INFO - Algo binary_search step 880 current loss 0.672750, current_train_items 28192.\n",
      "2023-03-23 09:56:53,176 - root - INFO - Algo binary_search step 881 current loss 1.593269, current_train_items 28224.\n",
      "2023-03-23 09:56:53,204 - root - INFO - Algo binary_search step 882 current loss 1.378450, current_train_items 28256.\n",
      "2023-03-23 09:56:53,236 - root - INFO - Algo binary_search step 883 current loss 2.089365, current_train_items 28288.\n",
      "2023-03-23 09:56:53,278 - root - INFO - Algo binary_search step 884 current loss 2.537540, current_train_items 28320.\n",
      "2023-03-23 09:56:53,286 - root - INFO - Algo binary_search step 885 current loss 0.292328, current_train_items 28352.\n",
      "2023-03-23 09:56:53,303 - root - INFO - Algo binary_search step 886 current loss 1.037945, current_train_items 28384.\n",
      "2023-03-23 09:56:53,330 - root - INFO - Algo binary_search step 887 current loss 1.670592, current_train_items 28416.\n",
      "2023-03-23 09:56:53,361 - root - INFO - Algo binary_search step 888 current loss 1.892478, current_train_items 28448.\n",
      "2023-03-23 09:56:53,401 - root - INFO - Algo binary_search step 889 current loss 2.997946, current_train_items 28480.\n",
      "2023-03-23 09:56:53,409 - root - INFO - Algo binary_search step 890 current loss 0.426084, current_train_items 28512.\n",
      "2023-03-23 09:56:53,426 - root - INFO - Algo binary_search step 891 current loss 0.931148, current_train_items 28544.\n",
      "2023-03-23 09:56:53,452 - root - INFO - Algo binary_search step 892 current loss 1.647325, current_train_items 28576.\n",
      "2023-03-23 09:56:53,483 - root - INFO - Algo binary_search step 893 current loss 1.984617, current_train_items 28608.\n",
      "2023-03-23 09:56:53,521 - root - INFO - Algo binary_search step 894 current loss 2.798050, current_train_items 28640.\n",
      "2023-03-23 09:56:53,528 - root - INFO - Algo binary_search step 895 current loss 0.145571, current_train_items 28672.\n",
      "2023-03-23 09:56:53,544 - root - INFO - Algo binary_search step 896 current loss 1.536922, current_train_items 28704.\n",
      "2023-03-23 09:56:53,571 - root - INFO - Algo binary_search step 897 current loss 2.054941, current_train_items 28736.\n",
      "2023-03-23 09:56:53,603 - root - INFO - Algo binary_search step 898 current loss 3.126964, current_train_items 28768.\n",
      "2023-03-23 09:56:53,641 - root - INFO - Algo binary_search step 899 current loss 4.181000, current_train_items 28800.\n",
      "2023-03-23 09:56:53,650 - root - INFO - Algo binary_search step 900 current loss 0.534222, current_train_items 28832.\n",
      "2023-03-23 09:56:55,819 - root - INFO - (val) algo binary_search step 900: {'return': 0.783935546875, 'score': 0.783935546875, 'examples_seen': 28832, 'step': 900, 'algorithm': 'binary_search'}\n",
      "2023-03-23 09:56:55,820 - root - INFO - Not saving new best model, best avg val score was 0.902, current avg val score is 0.784, val scores are: binary_search: 0.784\n",
      "2023-03-23 09:56:55,836 - root - INFO - Algo binary_search step 901 current loss 0.834524, current_train_items 28864.\n",
      "2023-03-23 09:56:55,863 - root - INFO - Algo binary_search step 902 current loss 3.105057, current_train_items 28896.\n",
      "2023-03-23 09:56:55,894 - root - INFO - Algo binary_search step 903 current loss 2.797904, current_train_items 28928.\n",
      "2023-03-23 09:56:55,931 - root - INFO - Algo binary_search step 904 current loss 4.448813, current_train_items 28960.\n",
      "2023-03-23 09:56:55,939 - root - INFO - Algo binary_search step 905 current loss 0.609946, current_train_items 28992.\n",
      "2023-03-23 09:56:55,955 - root - INFO - Algo binary_search step 906 current loss 1.046932, current_train_items 29024.\n",
      "2023-03-23 09:56:55,981 - root - INFO - Algo binary_search step 907 current loss 2.205289, current_train_items 29056.\n",
      "2023-03-23 09:56:56,012 - root - INFO - Algo binary_search step 908 current loss 2.743133, current_train_items 29088.\n",
      "2023-03-23 09:56:56,062 - root - INFO - Algo binary_search step 909 current loss 4.427123, current_train_items 29120.\n",
      "2023-03-23 09:56:56,071 - root - INFO - Algo binary_search step 910 current loss 0.865847, current_train_items 29152.\n",
      "2023-03-23 09:56:56,088 - root - INFO - Algo binary_search step 911 current loss 1.179791, current_train_items 29184.\n",
      "2023-03-23 09:56:56,114 - root - INFO - Algo binary_search step 912 current loss 1.836982, current_train_items 29216.\n",
      "2023-03-23 09:56:56,146 - root - INFO - Algo binary_search step 913 current loss 2.616410, current_train_items 29248.\n",
      "2023-03-23 09:56:56,185 - root - INFO - Algo binary_search step 914 current loss 3.403760, current_train_items 29280.\n",
      "2023-03-23 09:56:56,192 - root - INFO - Algo binary_search step 915 current loss 0.374227, current_train_items 29312.\n",
      "2023-03-23 09:56:56,209 - root - INFO - Algo binary_search step 916 current loss 0.590511, current_train_items 29344.\n",
      "2023-03-23 09:56:56,235 - root - INFO - Algo binary_search step 917 current loss 1.726236, current_train_items 29376.\n",
      "2023-03-23 09:56:56,266 - root - INFO - Algo binary_search step 918 current loss 2.298984, current_train_items 29408.\n",
      "2023-03-23 09:56:56,304 - root - INFO - Algo binary_search step 919 current loss 3.331460, current_train_items 29440.\n",
      "2023-03-23 09:56:56,312 - root - INFO - Algo binary_search step 920 current loss 0.685216, current_train_items 29472.\n",
      "2023-03-23 09:56:56,328 - root - INFO - Algo binary_search step 921 current loss 0.720726, current_train_items 29504.\n",
      "2023-03-23 09:56:56,355 - root - INFO - Algo binary_search step 922 current loss 1.563703, current_train_items 29536.\n",
      "2023-03-23 09:56:56,385 - root - INFO - Algo binary_search step 923 current loss 2.315636, current_train_items 29568.\n",
      "2023-03-23 09:56:56,423 - root - INFO - Algo binary_search step 924 current loss 2.837737, current_train_items 29600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 09:56:56,430 - root - INFO - Algo binary_search step 925 current loss 0.661848, current_train_items 29632.\n",
      "2023-03-23 09:56:56,446 - root - INFO - Algo binary_search step 926 current loss 0.708756, current_train_items 29664.\n",
      "2023-03-23 09:56:56,473 - root - INFO - Algo binary_search step 927 current loss 1.276768, current_train_items 29696.\n",
      "2023-03-23 09:56:56,504 - root - INFO - Algo binary_search step 928 current loss 2.631158, current_train_items 29728.\n",
      "2023-03-23 09:56:56,542 - root - INFO - Algo binary_search step 929 current loss 3.555871, current_train_items 29760.\n",
      "2023-03-23 09:56:56,549 - root - INFO - Algo binary_search step 930 current loss 0.837018, current_train_items 29792.\n",
      "2023-03-23 09:56:56,566 - root - INFO - Algo binary_search step 931 current loss 0.693261, current_train_items 29824.\n",
      "2023-03-23 09:56:56,593 - root - INFO - Algo binary_search step 932 current loss 1.426298, current_train_items 29856.\n",
      "2023-03-23 09:56:56,623 - root - INFO - Algo binary_search step 933 current loss 1.841275, current_train_items 29888.\n",
      "2023-03-23 09:56:56,660 - root - INFO - Algo binary_search step 934 current loss 2.830996, current_train_items 29920.\n",
      "2023-03-23 09:56:56,668 - root - INFO - Algo binary_search step 935 current loss 0.575194, current_train_items 29952.\n",
      "2023-03-23 09:56:56,684 - root - INFO - Algo binary_search step 936 current loss 0.715867, current_train_items 29984.\n",
      "2023-03-23 09:56:56,710 - root - INFO - Algo binary_search step 937 current loss 1.097488, current_train_items 30016.\n",
      "2023-03-23 09:56:56,740 - root - INFO - Algo binary_search step 938 current loss 2.319015, current_train_items 30048.\n",
      "2023-03-23 09:56:56,778 - root - INFO - Algo binary_search step 939 current loss 3.085735, current_train_items 30080.\n",
      "2023-03-23 09:56:56,785 - root - INFO - Algo binary_search step 940 current loss 0.717862, current_train_items 30112.\n",
      "2023-03-23 09:56:56,802 - root - INFO - Algo binary_search step 941 current loss 0.570531, current_train_items 30144.\n",
      "2023-03-23 09:56:56,828 - root - INFO - Algo binary_search step 942 current loss 1.356297, current_train_items 30176.\n",
      "2023-03-23 09:56:56,858 - root - INFO - Algo binary_search step 943 current loss 3.280083, current_train_items 30208.\n",
      "2023-03-23 09:56:56,896 - root - INFO - Algo binary_search step 944 current loss 3.828269, current_train_items 30240.\n",
      "2023-03-23 09:56:56,903 - root - INFO - Algo binary_search step 945 current loss 0.759389, current_train_items 30272.\n",
      "2023-03-23 09:56:56,919 - root - INFO - Algo binary_search step 946 current loss 0.882578, current_train_items 30304.\n",
      "2023-03-23 09:56:56,945 - root - INFO - Algo binary_search step 947 current loss 1.979854, current_train_items 30336.\n",
      "2023-03-23 09:56:56,976 - root - INFO - Algo binary_search step 948 current loss 2.591133, current_train_items 30368.\n",
      "2023-03-23 09:56:57,032 - root - INFO - Algo binary_search step 949 current loss 3.247160, current_train_items 30400.\n",
      "2023-03-23 09:56:57,040 - root - INFO - Algo binary_search step 950 current loss 0.205968, current_train_items 30432.\n",
      "2023-03-23 09:56:59,198 - root - INFO - (val) algo binary_search step 950: {'return': 0.83056640625, 'score': 0.83056640625, 'examples_seen': 30432, 'step': 950, 'algorithm': 'binary_search'}\n",
      "2023-03-23 09:56:59,198 - root - INFO - Not saving new best model, best avg val score was 0.902, current avg val score is 0.831, val scores are: binary_search: 0.831\n",
      "2023-03-23 09:56:59,216 - root - INFO - Algo binary_search step 951 current loss 0.483141, current_train_items 30464.\n",
      "2023-03-23 09:56:59,242 - root - INFO - Algo binary_search step 952 current loss 1.244303, current_train_items 30496.\n",
      "2023-03-23 09:56:59,273 - root - INFO - Algo binary_search step 953 current loss 1.982980, current_train_items 30528.\n",
      "2023-03-23 09:56:59,312 - root - INFO - Algo binary_search step 954 current loss 3.467124, current_train_items 30560.\n",
      "2023-03-23 09:56:59,320 - root - INFO - Algo binary_search step 955 current loss 0.633599, current_train_items 30592.\n",
      "2023-03-23 09:56:59,336 - root - INFO - Algo binary_search step 956 current loss 1.240733, current_train_items 30624.\n",
      "2023-03-23 09:56:59,363 - root - INFO - Algo binary_search step 957 current loss 1.911653, current_train_items 30656.\n",
      "2023-03-23 09:56:59,394 - root - INFO - Algo binary_search step 958 current loss 1.839346, current_train_items 30688.\n",
      "2023-03-23 09:56:59,432 - root - INFO - Algo binary_search step 959 current loss 2.649254, current_train_items 30720.\n",
      "2023-03-23 09:56:59,439 - root - INFO - Algo binary_search step 960 current loss 0.581487, current_train_items 30752.\n",
      "2023-03-23 09:56:59,455 - root - INFO - Algo binary_search step 961 current loss 0.736794, current_train_items 30784.\n",
      "2023-03-23 09:56:59,481 - root - INFO - Algo binary_search step 962 current loss 1.085289, current_train_items 30816.\n",
      "2023-03-23 09:56:59,512 - root - INFO - Algo binary_search step 963 current loss 1.772076, current_train_items 30848.\n",
      "2023-03-23 09:56:59,551 - root - INFO - Algo binary_search step 964 current loss 2.814941, current_train_items 30880.\n",
      "2023-03-23 09:56:59,558 - root - INFO - Algo binary_search step 965 current loss 0.301220, current_train_items 30912.\n",
      "2023-03-23 09:56:59,575 - root - INFO - Algo binary_search step 966 current loss 1.367038, current_train_items 30944.\n",
      "2023-03-23 09:56:59,602 - root - INFO - Algo binary_search step 967 current loss 1.761500, current_train_items 30976.\n",
      "2023-03-23 09:56:59,632 - root - INFO - Algo binary_search step 968 current loss 2.645685, current_train_items 31008.\n",
      "2023-03-23 09:56:59,670 - root - INFO - Algo binary_search step 969 current loss 3.116499, current_train_items 31040.\n",
      "2023-03-23 09:56:59,677 - root - INFO - Algo binary_search step 970 current loss 0.181278, current_train_items 31072.\n",
      "2023-03-23 09:56:59,694 - root - INFO - Algo binary_search step 971 current loss 0.862973, current_train_items 31104.\n",
      "2023-03-23 09:56:59,719 - root - INFO - Algo binary_search step 972 current loss 1.497636, current_train_items 31136.\n",
      "2023-03-23 09:56:59,749 - root - INFO - Algo binary_search step 973 current loss 2.298560, current_train_items 31168.\n",
      "2023-03-23 09:56:59,786 - root - INFO - Algo binary_search step 974 current loss 3.502943, current_train_items 31200.\n",
      "2023-03-23 09:56:59,794 - root - INFO - Algo binary_search step 975 current loss 1.108868, current_train_items 31232.\n",
      "2023-03-23 09:56:59,810 - root - INFO - Algo binary_search step 976 current loss 1.456077, current_train_items 31264.\n",
      "2023-03-23 09:56:59,835 - root - INFO - Algo binary_search step 977 current loss 1.678063, current_train_items 31296.\n",
      "2023-03-23 09:56:59,866 - root - INFO - Algo binary_search step 978 current loss 1.980946, current_train_items 31328.\n",
      "2023-03-23 09:56:59,903 - root - INFO - Algo binary_search step 979 current loss 3.063790, current_train_items 31360.\n",
      "2023-03-23 09:56:59,911 - root - INFO - Algo binary_search step 980 current loss 0.428570, current_train_items 31392.\n",
      "2023-03-23 09:56:59,927 - root - INFO - Algo binary_search step 981 current loss 1.103098, current_train_items 31424.\n",
      "2023-03-23 09:56:59,953 - root - INFO - Algo binary_search step 982 current loss 1.485968, current_train_items 31456.\n",
      "2023-03-23 09:56:59,983 - root - INFO - Algo binary_search step 983 current loss 2.170452, current_train_items 31488.\n",
      "2023-03-23 09:57:00,038 - root - INFO - Algo binary_search step 984 current loss 2.700604, current_train_items 31520.\n",
      "2023-03-23 09:57:00,046 - root - INFO - Algo binary_search step 985 current loss 0.536179, current_train_items 31552.\n",
      "2023-03-23 09:57:00,063 - root - INFO - Algo binary_search step 986 current loss 0.979555, current_train_items 31584.\n",
      "2023-03-23 09:57:00,090 - root - INFO - Algo binary_search step 987 current loss 1.398258, current_train_items 31616.\n",
      "2023-03-23 09:57:00,121 - root - INFO - Algo binary_search step 988 current loss 1.601209, current_train_items 31648.\n",
      "2023-03-23 09:57:00,160 - root - INFO - Algo binary_search step 989 current loss 2.951687, current_train_items 31680.\n",
      "2023-03-23 09:57:00,167 - root - INFO - Algo binary_search step 990 current loss 0.197762, current_train_items 31712.\n",
      "2023-03-23 09:57:00,184 - root - INFO - Algo binary_search step 991 current loss 0.476159, current_train_items 31744.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 09:57:00,211 - root - INFO - Algo binary_search step 992 current loss 1.665790, current_train_items 31776.\n",
      "2023-03-23 09:57:00,242 - root - INFO - Algo binary_search step 993 current loss 1.789044, current_train_items 31808.\n",
      "2023-03-23 09:57:00,280 - root - INFO - Algo binary_search step 994 current loss 2.585242, current_train_items 31840.\n",
      "2023-03-23 09:57:00,289 - root - INFO - Algo binary_search step 995 current loss 0.324096, current_train_items 31872.\n",
      "2023-03-23 09:57:00,306 - root - INFO - Algo binary_search step 996 current loss 0.568989, current_train_items 31904.\n",
      "2023-03-23 09:57:00,334 - root - INFO - Algo binary_search step 997 current loss 1.345299, current_train_items 31936.\n",
      "2023-03-23 09:57:00,364 - root - INFO - Algo binary_search step 998 current loss 2.552667, current_train_items 31968.\n",
      "2023-03-23 09:57:00,403 - root - INFO - Algo binary_search step 999 current loss 4.119041, current_train_items 32000.\n",
      "2023-03-23 09:57:00,403 - root - INFO - Restoring best model from checkpoint...\n"
     ]
    }
   ],
   "source": [
    "# Training loop.\n",
    "best_score = -1.0\n",
    "current_train_items = [0] * len(FLAGS.algorithms)\n",
    "step = 0\n",
    "next_eval = 0\n",
    "# Make sure scores improve on first step, but not overcome best score\n",
    "# until all algos have had at least one evaluation.\n",
    "val_scores = [-99999.9] * len(FLAGS.algorithms)\n",
    "length_idx = 0\n",
    "\n",
    "while step < FLAGS.train_steps:\n",
    "    feedback_list = [next(t) for t in train_samplers]\n",
    "\n",
    "    # Initialize model.\n",
    "    if step == 0:\n",
    "        all_features = [f.features for f in feedback_list]\n",
    "        if FLAGS.chunked_training:\n",
    "            # We need to initialize the model with samples of all lengths for\n",
    "            # all algorithms. Also, we need to make sure that the order of these\n",
    "            # sample sizes is the same as the order of the actual training sizes.\n",
    "            all_length_features = [all_features] + [\n",
    "                [next(t).features for t in train_samplers]\n",
    "                for _ in range(len(train_lengths))]\n",
    "            train_model.init(all_length_features[:-1], FLAGS.seed + 1)\n",
    "        else:\n",
    "            train_model.init(all_features, FLAGS.seed + 1)\n",
    "\n",
    "    # Training step.\n",
    "    for algo_idx in range(len(train_samplers)):\n",
    "        feedback = feedback_list[algo_idx]\n",
    "        rng_key, new_rng_key = jax.random.split(rng_key)\n",
    "        if FLAGS.chunked_training:\n",
    "            # In chunked training, we must indicate which training length we are\n",
    "            # using, so the model uses the correct state.\n",
    "            length_and_algo_idx = (length_idx, algo_idx)\n",
    "        else:\n",
    "            # In non-chunked training, all training lengths can be treated equally,\n",
    "            # since there is no state to maintain between batches.\n",
    "            length_and_algo_idx = algo_idx\n",
    "        cur_loss = train_model.feedback(\n",
    "            rng_key, feedback, length_and_algo_idx)\n",
    "        rng_key = new_rng_key\n",
    "\n",
    "        if FLAGS.chunked_training:\n",
    "            examples_in_chunk = np.sum(feedback.features.is_last).item()\n",
    "        else:\n",
    "            examples_in_chunk = len(feedback.features.lengths)\n",
    "        current_train_items[algo_idx] += examples_in_chunk\n",
    "        logging.info('Algo %s step %i current loss %f, current_train_items %i.',\n",
    "                     FLAGS.algorithms[algo_idx], step,\n",
    "                     cur_loss, current_train_items[algo_idx])\n",
    "\n",
    "    # Periodically evaluate model\n",
    "    if step >= next_eval:\n",
    "        eval_model.params = train_model.params\n",
    "        for algo_idx in range(len(train_samplers)):\n",
    "            common_extras = {'examples_seen': current_train_items[algo_idx],\n",
    "                             'step': step,\n",
    "                             'algorithm': FLAGS.algorithms[algo_idx]}\n",
    "\n",
    "            # Validation info.\n",
    "            new_rng_key, rng_key = jax.random.split(rng_key)\n",
    "            val_stats = collect_and_eval(\n",
    "                val_samplers[algo_idx],\n",
    "                functools.partial(eval_model.predict,\n",
    "                                  algorithm_index=algo_idx),\n",
    "                val_sample_counts[algo_idx],\n",
    "                new_rng_key,\n",
    "                extras=common_extras)\n",
    "            logging.info('(val) algo %s step %d: %s',\n",
    "                         FLAGS.algorithms[algo_idx], step, val_stats)\n",
    "            val_scores[algo_idx] = val_stats['score']\n",
    "\n",
    "        next_eval += FLAGS.eval_every\n",
    "\n",
    "        # If best total score, update best checkpoint.\n",
    "        # Also save a best checkpoint on the first step.\n",
    "        msg = (f'best avg val score was '\n",
    "               f'{best_score/len(FLAGS.algorithms):.3f}, '\n",
    "               f'current avg val score is {np.mean(val_scores):.3f}, '\n",
    "               f'val scores are: ')\n",
    "        msg += ', '.join(\n",
    "            ['%s: %.3f' % (x, y) for (x, y) in zip(FLAGS.algorithms, val_scores)])\n",
    "        if (sum(val_scores) > best_score) or step == 0:\n",
    "            best_score = sum(val_scores)\n",
    "            logging.info('Checkpointing best model, %s', msg)\n",
    "            train_model.save_model('best.pkl')\n",
    "        else:\n",
    "            logging.info('Not saving new best model, %s', msg)\n",
    "\n",
    "    step += 1\n",
    "    length_idx = (length_idx + 1) % len(train_lengths)\n",
    "\n",
    "logging.info('Restoring best model from checkpoint...')\n",
    "eval_model.restore_model('best.pkl', only_load_processor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7414d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def restore_model(model, file_name):\n",
    "    \"\"\"Restore model from `file_name`.\"\"\"\n",
    "    with open(file_name, 'rb') as f:\n",
    "        restored_state = pickle.load(f)\n",
    "        restored_params = restored_state['params']\n",
    "        model.params = hk.data_structures.merge(restored_params)\n",
    "        model.opt_state = restored_state['opt_state']\n",
    "\n",
    "def save_model(model, file_name):\n",
    "    \"\"\"Save model (processor weights only) to `file_name`.\"\"\"\n",
    "    to_save = {'params': model.params, 'opt_state': model.opt_state}\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(to_save, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c11566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(eval_model, 'eval_model_1e-3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb459f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore_model(eval_model, 'eval_model_asdf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aed2485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'return': 0.906005859375, 'score': 0.906005859375}\n"
     ]
    }
   ],
   "source": [
    "algo_idx = 0\n",
    "common_extras = {}\n",
    "\n",
    "new_rng_key, rng_key = jax.random.split(rng_key)\n",
    "val_stats = collect_and_eval(\n",
    "    val_samplers[algo_idx],\n",
    "    functools.partial(eval_model.predict, algorithm_index=algo_idx),\n",
    "    val_sample_counts[algo_idx],\n",
    "    new_rng_key,\n",
    "    extras=common_extras)\n",
    "\n",
    "print(val_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2b7510d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'return': 0.736328125, 'score': 0.736328125}\n"
     ]
    }
   ],
   "source": [
    "new_rng_key, rng_key = jax.random.split(rng_key)\n",
    "test_stats = collect_and_eval(\n",
    "    test_samplers[algo_idx],\n",
    "    functools.partial(eval_model.predict, algorithm_index=algo_idx),\n",
    "    test_sample_counts[algo_idx],\n",
    "    new_rng_key,\n",
    "    extras=common_extras)\n",
    "\n",
    "print(test_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b5f2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback = next(train_samplers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eede5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(filter(lambda x: x[:2] != '__', dir(feedback)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa70e0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(filter(lambda x: x[:2] != '__', dir(feedback.features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87285504",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd67ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback.features.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e01e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback.features.inputs[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d5c9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback.features.inputs[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16a11f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback.features.inputs[2].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d00fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback.features.inputs[3].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a78496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = feedback.features.inputs[2].data\n",
    "adj = feedback.features.inputs[3].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58635a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.where((A != 0) & (adj == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b9ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback.features.hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b088c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(feedback.features.inputs[0].data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7396caeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(feedback.outputs[0].data == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f1aa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample_counts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf86a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _concat(dps, axis):\n",
    "    return jax.tree_util.tree_map(lambda *x: np.concatenate(x, axis), *dps)\n",
    "\n",
    "def get_msgs(sampler, predict_fn, sample_count, rng_key, sample_prob=0.001):\n",
    "    \"\"\"Get messages from model.\n",
    "    \n",
    "    CAUTION: size of msgs can get large very quickly, so beware when\n",
    "        running with a large number of samples.\n",
    "    Use sample_prob to reduce the number of messages that are saved\n",
    "    by randomly sampling messages\n",
    "    \"\"\"\n",
    "    processed_samples = 0\n",
    "    msgs = []\n",
    "    while processed_samples < sample_count:\n",
    "        feedback = next(sampler)\n",
    "        batch_size = feedback.outputs[0].data.shape[0]\n",
    "        new_rng_key, rng_key = jax.random.split(rng_key)\n",
    "        _, _, cur_msgs, cur_input_msg = predict_fn(new_rng_key, feedback.features)\n",
    "        \n",
    "        cur_msgs = cur_msgs.reshape(-1, cur_msgs.shape[-1])\n",
    "        cur_input_msg = cur_input_msg.reshape(-1, cur_input_msg.shape[-1])\n",
    "        cur_msg_concat = jnp.concatenate((cur_msgs, cur_input_msg), axis=-1)\n",
    "        \n",
    "        new_rng_key, rng_key = jax.random.split(rng_key)\n",
    "        mask = jax.random.choice(new_rng_key,\n",
    "                                 a=jnp.array([False, True]),\n",
    "                                 shape=(cur_msg_concat.shape[0],),\n",
    "                                 p=jnp.array([1 - sample_prob, sample_prob]),\n",
    "                                 replace=True,)\n",
    "        cur_msg_concat = cur_msg_concat[mask]\n",
    "        \n",
    "        msgs.append(cur_msg_concat)\n",
    "        processed_samples += batch_size\n",
    "    msgs = _concat(msgs, axis=0)\n",
    "    \n",
    "    return msgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "189e76f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 128 13\n",
      "64 128 13\n",
      "64 128 13\n",
      "64 128 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(31436, 205)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rng_key, rng_key = jax.random.split(rng_key)\n",
    "batched_msgs = get_msgs(\n",
    "    test_samplers[0],\n",
    "    functools.partial(eval_model.predict, algorithm_index=0),\n",
    "#     test_sample_counts[0],  # EXPLODING MEMORY LOL\n",
    "    32*4,\n",
    "    new_rng_key,\n",
    "    0.01)\n",
    "\n",
    "batched_msgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bec654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'binary_search_val_msgs.pkl'\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(msgs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9a3dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.getsizeof(batched_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29ad849",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample_counts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbf7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(batched_msgs) / 1000000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
