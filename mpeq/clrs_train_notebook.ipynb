{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3acdd8b",
   "metadata": {},
   "source": [
    "# Run training of CLRS algorithm\n",
    "\n",
    "Copied main function from clrs_train.py. Helper functions are located in clrs_train_funcs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b11198c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 16:36:51.596749: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2023-03-27 16:36:51.596882: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2023-03-27 16:36:51.596888: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import os\n",
    "import shutil\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import logging\n",
    "import clrs\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "import haiku as hk\n",
    "\n",
    "import model\n",
    "\n",
    "import flags\n",
    "from clrs_train_funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27a69895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 27 16:36:53 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.65       Driver Version: 527.56       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   42C    P8    13W / 139W |      0MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      4807      G   /Xwayland                       N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "771141dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa63cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch = logging.StreamHandler()\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b412628f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 16:36:55,866 - jax._src.lib.xla_bridge - INFO - Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: \n",
      "2023-03-27 16:36:56,271 - jax._src.lib.xla_bridge - INFO - Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: \"rocm\". Available platform names are: CUDA Host Interpreter\n",
      "2023-03-27 16:36:56,272 - jax._src.lib.xla_bridge - INFO - Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'\n",
      "2023-03-27 16:36:56,273 - jax._src.lib.xla_bridge - INFO - Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.hint_mode == 'encoded_decoded':\n",
    "    encode_hints = True\n",
    "    decode_hints = True\n",
    "elif FLAGS.hint_mode == 'decoded_only':\n",
    "    encode_hints = False\n",
    "    decode_hints = True\n",
    "elif FLAGS.hint_mode == 'none':\n",
    "    encode_hints = False\n",
    "    decode_hints = False\n",
    "else:\n",
    "    raise ValueError(\n",
    "        'Hint mode not in {encoded_decoded, decoded_only, none}.')\n",
    "\n",
    "train_lengths = [int(x) for x in FLAGS.train_lengths]\n",
    "\n",
    "rng = np.random.RandomState(FLAGS.seed)\n",
    "rng_key = jax.random.PRNGKey(rng.randint(2**32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a79e1217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 16:36:57.743414: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2023-03-27 16:36:57,748 - root - INFO - Creating samplers for algo binary_search\n",
      "2023-03-27 16:36:57.743472: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-27 16:36:57,749 - absl - WARNING - Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.SearchSampler'>\n",
      "2023-03-27 16:36:57,750 - absl - WARNING - Sampling dataset on-the-fly, unlimited samples.\n",
      "2023-03-27 16:36:57,901 - absl - WARNING - Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.SearchSampler'>\n",
      "2023-03-27 16:36:57,902 - absl - WARNING - Sampling dataset on-the-fly, unlimited samples.\n",
      "2023-03-27 16:36:58,059 - absl - WARNING - Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.SearchSampler'>\n",
      "2023-03-27 16:36:58,060 - absl - WARNING - Sampling dataset on-the-fly, unlimited samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not! using randomized pos for split train\n",
      "Not! using randomized pos for split train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 16:36:58,227 - absl - WARNING - Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.SearchSampler'>\n",
      "2023-03-27 16:36:58,228 - absl - WARNING - Sampling dataset on-the-fly, unlimited samples.\n",
      "2023-03-27 16:36:58,401 - absl - WARNING - Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.SearchSampler'>\n",
      "2023-03-27 16:36:58,402 - absl - WARNING - Sampling dataset on-the-fly, unlimited samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not! using randomized pos for split train\n",
      "Not! using randomized pos for split train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 16:36:58,572 - absl - WARNING - Ignoring kwargs {'length_needle', 'p'} when building sampler class <class 'clrs._src.samplers.SearchSampler'>\n",
      "2023-03-27 16:36:58,573 - absl - INFO - Creating a dataset with 4096 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not! using randomized pos for split train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 16:36:58,951 - absl - INFO - 1000 samples created\n",
      "2023-03-27 16:36:59,142 - absl - INFO - 2000 samples created\n",
      "2023-03-27 16:36:59,332 - absl - INFO - 3000 samples created\n",
      "2023-03-27 16:36:59,580 - absl - INFO - 4000 samples created\n",
      "2023-03-27 16:36:59,717 - root - INFO - Dataset found at /tmp/CLRS30/CLRS30_v1.0.0. Skipping download.\n",
      "2023-03-27 16:36:59,721 - absl - INFO - Load dataset info from /tmp/CLRS30/CLRS30_v1.0.0/clrs_dataset/binary_search_test/1.0.0\n",
      "2023-03-27 16:36:59,724 - absl - INFO - Load dataset info from /tmp/CLRS30/CLRS30_v1.0.0/clrs_dataset/binary_search_test/1.0.0\n",
      "2023-03-27 16:36:59,726 - absl - INFO - Reusing dataset clrs_dataset (/tmp/CLRS30/CLRS30_v1.0.0/clrs_dataset/binary_search_test/1.0.0)\n",
      "2023-03-27 16:36:59,727 - absl - INFO - Constructing tf.data.Dataset clrs_dataset for split test, from /tmp/CLRS30/CLRS30_v1.0.0/clrs_dataset/binary_search_test/1.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not! using randomized pos for split val\n",
      "WARNING:tensorflow:From /home/kausta/miniconda3/envs/pysr/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 16:36:59,830 - tensorflow - WARNING - From /home/kausta/miniconda3/envs/pysr/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not! using randomized pos for split test\n"
     ]
    }
   ],
   "source": [
    "FLAGS.random_pos = False\n",
    "# FLAGS.algorithms = [\"insertion_sort\"]\n",
    "\n",
    "# Create samplers\n",
    "(train_samplers,\n",
    " val_samplers, val_sample_counts,\n",
    " test_samplers, test_sample_counts,\n",
    " spec_list) = create_samplers(rng, train_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e70415b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.hidden_size = 128 # 32\n",
    "FLAGS.msg_size = 32 # 32\n",
    "\n",
    "FLAGS.train_steps = 10000 # 1000\n",
    "FLAGS.eval_every = 50\n",
    "FLAGS.test_every = 500\n",
    "\n",
    "FLAGS.l1_weight = 0.01 # 0.001 \n",
    "\n",
    "# l1_weight_fn_mult_start = 1\n",
    "# l1_weight_fn_mult_end = 10\n",
    "# l1_weight_fn = lambda step: FLAGS.l1_weight * (l1_weight_fn_mult_start + step / FLAGS.train_steps * (l1_weight_fn_mult_end - l1_weight_fn_mult_start))\n",
    "\n",
    "l1_weight_fn = lambda step: FLAGS.l1_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d6249f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLAGS.hidden_size = 8\n",
    "# FLAGS.algorithms = ['dijkstra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3080605",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor_factory = model.get_processor_factory(\n",
    "    FLAGS.processor_type,\n",
    "    use_ln=FLAGS.use_ln,\n",
    "    nb_triplet_fts=FLAGS.nb_triplet_fts,\n",
    "    nb_heads=FLAGS.nb_heads\n",
    ")\n",
    "model_params = dict(\n",
    "    processor_factory=processor_factory,\n",
    "    hidden_dim=FLAGS.hidden_size,\n",
    "    msg_dim=FLAGS.msg_size,\n",
    "    encode_hints=encode_hints,\n",
    "    decode_hints=decode_hints,\n",
    "    encoder_init=FLAGS.encoder_init,\n",
    "    use_lstm=FLAGS.use_lstm,\n",
    "    learning_rate=FLAGS.learning_rate,\n",
    "    grad_clip_max_norm=FLAGS.grad_clip_max_norm,\n",
    "    checkpoint_path=FLAGS.checkpoint_path,\n",
    "    freeze_processor=FLAGS.freeze_processor,\n",
    "    dropout_prob=FLAGS.dropout_prob,\n",
    "    hint_teacher_forcing=FLAGS.hint_teacher_forcing,\n",
    "    hint_repred_mode=FLAGS.hint_repred_mode,\n",
    "    nb_msg_passing_steps=FLAGS.nb_msg_passing_steps,\n",
    "    l1_weight=FLAGS.l1_weight\n",
    ")\n",
    "\n",
    "eval_model = model.BaselineMsgModel(\n",
    "    spec=spec_list,\n",
    "    dummy_trajectory=[next(t) for t in val_samplers],\n",
    "    **model_params\n",
    ")\n",
    "# # we will never used chunked training\n",
    "# if FLAGS.chunked_training:\n",
    "#     train_model = clrs.models.BaselineModelChunked(\n",
    "#         spec=spec_list,\n",
    "#         dummy_trajectory=[next(t) for t in train_samplers],\n",
    "#         **model_params\n",
    "#     )\n",
    "# else:\n",
    "#     train_model = eval_model\n",
    "train_model = eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6738fd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 16:37:24,982 - root - INFO - Algo binary_search step 0 current loss 7.195256, current_train_items 32, l1_weight 0.010000.\n",
      "2023-03-27 16:37:26,590 - root - INFO - (val) algo binary_search step 0: {'return': 0.12744140625, 'score': 0.12744140625, 'examples_seen': 32, 'step': 0, 'algorithm': 'binary_search'}\n",
      "2023-03-27 16:37:26,591 - root - INFO - Checkpointing best model, best avg val score was -1.000, current avg val score is 0.127, val scores are: binary_search: 0.127\n",
      "2023-03-27 16:37:59,847 - root - INFO - Algo binary_search step 50 current loss 3.121903, current_train_items 1632, l1_weight 0.010000.\n",
      "2023-03-27 16:38:00,281 - root - INFO - (val) algo binary_search step 50: {'return': 0.67333984375, 'score': 0.67333984375, 'examples_seen': 1632, 'step': 50, 'algorithm': 'binary_search'}\n",
      "2023-03-27 16:38:00,282 - root - INFO - Checkpointing best model, best avg val score was 0.127, current avg val score is 0.673, val scores are: binary_search: 0.673\n",
      "2023-03-27 16:38:01,149 - root - INFO - Algo binary_search step 100 current loss 2.263062, current_train_items 3232, l1_weight 0.010000.\n",
      "2023-03-27 16:38:01,672 - root - INFO - (val) algo binary_search step 100: {'return': 0.591064453125, 'score': 0.591064453125, 'examples_seen': 3232, 'step': 100, 'algorithm': 'binary_search'}\n",
      "2023-03-27 16:38:01,673 - root - INFO - Not saving new best model, best avg val score was 0.673, current avg val score is 0.591, val scores are: binary_search: 0.591\n",
      "2023-03-27 16:38:02,532 - root - INFO - Algo binary_search step 150 current loss 1.362670, current_train_items 4832, l1_weight 0.010000.\n",
      "2023-03-27 16:38:03,034 - root - INFO - (val) algo binary_search step 150: {'return': 0.677001953125, 'score': 0.677001953125, 'examples_seen': 4832, 'step': 150, 'algorithm': 'binary_search'}\n",
      "2023-03-27 16:38:03,035 - root - INFO - Checkpointing best model, best avg val score was 0.673, current avg val score is 0.677, val scores are: binary_search: 0.677\n",
      "2023-03-27 16:38:03,895 - root - INFO - Algo binary_search step 200 current loss 1.575563, current_train_items 6432, l1_weight 0.010000.\n",
      "2023-03-27 16:38:04,421 - root - INFO - (val) algo binary_search step 200: {'return': 0.686279296875, 'score': 0.686279296875, 'examples_seen': 6432, 'step': 200, 'algorithm': 'binary_search'}\n",
      "2023-03-27 16:38:04,422 - root - INFO - Checkpointing best model, best avg val score was 0.677, current avg val score is 0.686, val scores are: binary_search: 0.686\n",
      "2023-03-27 16:38:05,265 - root - INFO - Algo binary_search step 250 current loss 1.516510, current_train_items 8032, l1_weight 0.010000.\n",
      "2023-03-27 16:38:05,759 - root - INFO - (val) algo binary_search step 250: {'return': 0.871337890625, 'score': 0.871337890625, 'examples_seen': 8032, 'step': 250, 'algorithm': 'binary_search'}\n",
      "2023-03-27 16:38:05,760 - root - INFO - Checkpointing best model, best avg val score was 0.686, current avg val score is 0.871, val scores are: binary_search: 0.871\n",
      "2023-03-27 16:38:06,593 - root - INFO - Algo binary_search step 300 current loss 0.939148, current_train_items 9632, l1_weight 0.010000.\n",
      "2023-03-27 16:38:07,098 - root - INFO - (val) algo binary_search step 300: {'return': 0.742919921875, 'score': 0.742919921875, 'examples_seen': 9632, 'step': 300, 'algorithm': 'binary_search'}\n",
      "2023-03-27 16:38:07,099 - root - INFO - Not saving new best model, best avg val score was 0.871, current avg val score is 0.743, val scores are: binary_search: 0.743\n",
      "2023-03-27 16:38:07,931 - root - INFO - Algo binary_search step 350 current loss 1.363776, current_train_items 11232, l1_weight 0.010000.\n",
      "2023-03-27 16:38:08,430 - root - INFO - (val) algo binary_search step 350: {'return': 0.822998046875, 'score': 0.822998046875, 'examples_seen': 11232, 'step': 350, 'algorithm': 'binary_search'}\n",
      "2023-03-27 16:38:08,431 - root - INFO - Not saving new best model, best avg val score was 0.871, current avg val score is 0.823, val scores are: binary_search: 0.823\n",
      "2023-03-27 16:38:09,206 - root - INFO - Algo binary_search step 400 current loss 0.585904, current_train_items 12832, l1_weight 0.010000.\n",
      "2023-03-27 16:38:09,709 - root - INFO - (val) algo binary_search step 400: {'return': 0.696044921875, 'score': 0.696044921875, 'examples_seen': 12832, 'step': 400, 'algorithm': 'binary_search'}\n",
      "2023-03-27 16:38:09,710 - root - INFO - Not saving new best model, best avg val score was 0.871, current avg val score is 0.696, val scores are: binary_search: 0.696\n",
      "2023-03-27 16:38:10,597 - root - INFO - Algo binary_search step 450 current loss 0.721804, current_train_items 14432, l1_weight 0.010000.\n",
      "2023-03-27 16:38:11,136 - root - INFO - (val) algo binary_search step 450: {'return': 0.812255859375, 'score': 0.812255859375, 'examples_seen': 14432, 'step': 450, 'algorithm': 'binary_search'}\n",
      "2023-03-27 16:38:11,137 - root - INFO - Not saving new best model, best avg val score was 0.871, current avg val score is 0.812, val scores are: binary_search: 0.812\n",
      "2023-03-27 16:38:12,007 - root - INFO - Algo binary_search step 500 current loss 0.609873, current_train_items 16032, l1_weight 0.010000.\n",
      "2023-03-27 16:38:12,526 - root - INFO - (val) algo binary_search step 500: {'return': 0.896240234375, 'score': 0.896240234375, 'examples_seen': 16032, 'step': 500, 'algorithm': 'binary_search'}\n",
      "2023-03-27 16:38:12,527 - root - INFO - Checkpointing best model, best avg val score was 0.871, current avg val score is 0.896, val scores are: binary_search: 0.896\n",
      "2023-03-27 16:38:13,359 - root - INFO - Algo binary_search step 550 current loss 1.035880, current_train_items 17632, l1_weight 0.010000.\n",
      "2023-03-27 16:38:13,918 - root - INFO - (val) algo binary_search step 550: {'return': 0.84521484375, 'score': 0.84521484375, 'examples_seen': 17632, 'step': 550, 'algorithm': 'binary_search'}\n",
      "2023-03-27 16:38:13,918 - root - INFO - Not saving new best model, best avg val score was 0.896, current avg val score is 0.845, val scores are: binary_search: 0.845\n",
      "2023-03-27 16:38:14,780 - root - INFO - Algo binary_search step 600 current loss 1.271245, current_train_items 19232, l1_weight 0.010000.\n",
      "2023-03-27 16:38:15,327 - root - INFO - (val) algo binary_search step 600: {'return': 0.7890625, 'score': 0.7890625, 'examples_seen': 19232, 'step': 600, 'algorithm': 'binary_search'}\n",
      "2023-03-27 16:38:15,328 - root - INFO - Not saving new best model, best avg val score was 0.896, current avg val score is 0.789, val scores are: binary_search: 0.789\n",
      "2023-03-27 16:38:16,164 - root - INFO - Algo binary_search step 650 current loss 1.045015, current_train_items 20832, l1_weight 0.010000.\n",
      "2023-03-27 16:38:16,749 - root - INFO - (val) algo binary_search step 650: {'return': 0.818359375, 'score': 0.818359375, 'examples_seen': 20832, 'step': 650, 'algorithm': 'binary_search'}\n",
      "2023-03-27 16:38:16,750 - root - INFO - Not saving new best model, best avg val score was 0.896, current avg val score is 0.818, val scores are: binary_search: 0.818\n",
      "2023-03-27 16:38:17,583 - root - INFO - Algo binary_search step 700 current loss 0.972108, current_train_items 22432, l1_weight 0.010000.\n",
      "2023-03-27 16:38:18,055 - root - INFO - (val) algo binary_search step 700: {'return': 0.876220703125, 'score': 0.876220703125, 'examples_seen': 22432, 'step': 700, 'algorithm': 'binary_search'}\n",
      "2023-03-27 16:38:18,056 - root - INFO - Not saving new best model, best avg val score was 0.896, current avg val score is 0.876, val scores are: binary_search: 0.876\n",
      "2023-03-27 16:38:18,884 - root - INFO - Algo binary_search step 750 current loss 0.735554, current_train_items 24032, l1_weight 0.010000.\n",
      "2023-03-27 16:38:19,386 - root - INFO - (val) algo binary_search step 750: {'return': 0.86376953125, 'score': 0.86376953125, 'examples_seen': 24032, 'step': 750, 'algorithm': 'binary_search'}\n",
      "2023-03-27 16:38:19,387 - root - INFO - Not saving new best model, best avg val score was 0.896, current avg val score is 0.864, val scores are: binary_search: 0.864\n",
      "2023-03-27 16:38:20,211 - root - INFO - Algo binary_search step 800 current loss 0.532184, current_train_items 25632, l1_weight 0.010000.\n",
      "2023-03-27 16:38:20,759 - root - INFO - (val) algo binary_search step 800: {'return': 0.866943359375, 'score': 0.866943359375, 'examples_seen': 25632, 'step': 800, 'algorithm': 'binary_search'}\n",
      "2023-03-27 16:38:20,760 - root - INFO - Not saving new best model, best avg val score was 0.896, current avg val score is 0.867, val scores are: binary_search: 0.867\n",
      "2023-03-27 16:38:21,645 - root - INFO - Algo binary_search step 850 current loss 0.840132, current_train_items 27232, l1_weight 0.010000.\n",
      "2023-03-27 16:38:22,139 - root - INFO - (val) algo binary_search step 850: {'return': 0.840576171875, 'score': 0.840576171875, 'examples_seen': 27232, 'step': 850, 'algorithm': 'binary_search'}\n",
      "2023-03-27 16:38:22,140 - root - INFO - Not saving new best model, best avg val score was 0.896, current avg val score is 0.841, val scores are: binary_search: 0.841\n",
      "2023-03-27 16:38:22,928 - root - INFO - Algo binary_search step 900 current loss 0.811713, current_train_items 28832, l1_weight 0.010000.\n",
      "2023-03-27 16:38:23,431 - root - INFO - (val) algo binary_search step 900: {'return': 0.886962890625, 'score': 0.886962890625, 'examples_seen': 28832, 'step': 900, 'algorithm': 'binary_search'}\n",
      "2023-03-27 16:38:23,432 - root - INFO - Not saving new best model, best avg val score was 0.896, current avg val score is 0.887, val scores are: binary_search: 0.887\n",
      "2023-03-27 16:38:24,359 - root - INFO - Algo binary_search step 950 current loss 0.317325, current_train_items 30432, l1_weight 0.010000.\n",
      "2023-03-27 16:38:24,897 - root - INFO - (val) algo binary_search step 950: {'return': 0.88720703125, 'score': 0.88720703125, 'examples_seen': 30432, 'step': 950, 'algorithm': 'binary_search'}\n",
      "2023-03-27 16:38:24,898 - root - INFO - Not saving new best model, best avg val score was 0.896, current avg val score is 0.887, val scores are: binary_search: 0.887\n",
      "2023-03-27 16:38:25,677 - root - INFO - Checkpointing final model, best avg val score was 0.896, current avg val score is 0.887, val scores are: binary_search: 0.887\n",
      "2023-03-27 16:38:25,712 - root - INFO - Restoring best model from checkpoint...\n"
     ]
    }
   ],
   "source": [
    "# Training loop.\n",
    "best_score = -1.0\n",
    "current_train_items = [0] * len(FLAGS.algorithms)\n",
    "step = 0\n",
    "next_eval = 0\n",
    "# Make sure scores improve on first step, but not overcome best score\n",
    "# until all algos have had at least one evaluation.\n",
    "val_scores = [-99999.9] * len(FLAGS.algorithms)\n",
    "length_idx = 0\n",
    "\n",
    "while step < FLAGS.train_steps:\n",
    "    feedback_list = [next(t) for t in train_samplers]\n",
    "\n",
    "    # Initialize model.\n",
    "    if step == 0:\n",
    "        all_features = [f.features for f in feedback_list]\n",
    "        if FLAGS.chunked_training:\n",
    "            # We need to initialize the model with samples of all lengths for\n",
    "            # all algorithms. Also, we need to make sure that the order of these\n",
    "            # sample sizes is the same as the order of the actual training sizes.\n",
    "            all_length_features = [all_features] + [\n",
    "                [next(t).features for t in train_samplers]\n",
    "                for _ in range(len(train_lengths))]\n",
    "            train_model.init(all_length_features[:-1], FLAGS.seed + 1)\n",
    "        else:\n",
    "            train_model.init(all_features, FLAGS.seed + 1)\n",
    "\n",
    "    train_model.l1_weight = l1_weight_fn(step)\n",
    "    # Training step.\n",
    "    for algo_idx in range(len(train_samplers)):\n",
    "        feedback = feedback_list[algo_idx]\n",
    "        rng_key, new_rng_key = jax.random.split(rng_key)\n",
    "        if FLAGS.chunked_training:\n",
    "            # In chunked training, we must indicate which training length we are\n",
    "            # using, so the model uses the correct state.\n",
    "            length_and_algo_idx = (length_idx, algo_idx)\n",
    "        else:\n",
    "            # In non-chunked training, all training lengths can be treated equally,\n",
    "            # since there is no state to maintain between batches.\n",
    "            length_and_algo_idx = algo_idx\n",
    "        cur_loss = train_model.feedback(\n",
    "            rng_key, feedback, length_and_algo_idx)\n",
    "        rng_key = new_rng_key\n",
    "\n",
    "        if FLAGS.chunked_training:\n",
    "            examples_in_chunk = np.sum(feedback.features.is_last).item()\n",
    "        else:\n",
    "            examples_in_chunk = len(feedback.features.lengths)\n",
    "        current_train_items[algo_idx] += examples_in_chunk\n",
    "        if step % 50 == 0:\n",
    "            logging.info('Algo %s step %i current loss %f, current_train_items %i, l1_weight %f.',\n",
    "                        FLAGS.algorithms[algo_idx], step,\n",
    "                        cur_loss, current_train_items[algo_idx], train_model.l1_weight)\n",
    "\n",
    "    # Periodically evaluate model\n",
    "    if step >= next_eval:\n",
    "        eval_model.params = train_model.params\n",
    "        for algo_idx in range(len(train_samplers)):\n",
    "            common_extras = {'examples_seen': current_train_items[algo_idx],\n",
    "                             'step': step,\n",
    "                             'algorithm': FLAGS.algorithms[algo_idx]}\n",
    "\n",
    "            # Validation info.\n",
    "            new_rng_key, rng_key = jax.random.split(rng_key)\n",
    "            val_stats = collect_and_eval(\n",
    "                val_samplers[algo_idx],\n",
    "                functools.partial(eval_model.predict,\n",
    "                                  algorithm_index=algo_idx),\n",
    "                val_sample_counts[algo_idx],\n",
    "                new_rng_key,\n",
    "                extras=common_extras)\n",
    "            logging.info('(val) algo %s step %d: %s',\n",
    "                         FLAGS.algorithms[algo_idx], step, val_stats)\n",
    "            val_scores[algo_idx] = val_stats['score']\n",
    "\n",
    "        next_eval += FLAGS.eval_every\n",
    "\n",
    "        # If best total score, update best checkpoint.\n",
    "        # Also save a best checkpoint on the first step.\n",
    "        msg = (f'best avg val score was '\n",
    "               f'{best_score/len(FLAGS.algorithms):.3f}, '\n",
    "               f'current avg val score is {np.mean(val_scores):.3f}, '\n",
    "               f'val scores are: ')\n",
    "        msg += ', '.join(\n",
    "            ['%s: %.3f' % (x, y) for (x, y) in zip(FLAGS.algorithms, val_scores)])\n",
    "        if (sum(val_scores) > best_score) or step == 0:\n",
    "            best_score = sum(val_scores)\n",
    "            logging.info('Checkpointing best model, %s', msg)\n",
    "            train_model.save_model('best.pkl')\n",
    "        else:\n",
    "            logging.info('Not saving new best model, %s', msg)\n",
    "\n",
    "    step += 1\n",
    "    length_idx = (length_idx + 1) % len(train_lengths)\n",
    "\n",
    "logging.info('Checkpointing final model, %s', msg)\n",
    "train_model.save_model('final.pkl')\n",
    "\n",
    "logging.info('Restoring best model from checkpoint...')\n",
    "eval_model.restore_model('best.pkl', only_load_processor=False)\n",
    "# logging.info('Restoring final model from checkpoint...')\n",
    "# eval_model.restore_model('final.pkl', only_load_processor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7414d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def restore_model(model, file_name):\n",
    "    \"\"\"Restore model from `file_name`.\"\"\"\n",
    "    with open(file_name, 'rb') as f:\n",
    "        restored_state = pickle.load(f)\n",
    "        restored_params = restored_state['params']\n",
    "        model.params = hk.data_structures.merge(restored_params)\n",
    "        model.opt_state = restored_state['opt_state']\n",
    "\n",
    "def save_model(model, file_name):\n",
    "    \"\"\"Save model (processor weights only) to `file_name`.\"\"\"\n",
    "    to_save = {'params': model.params, 'opt_state': model.opt_state}\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(to_save, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4c11566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(eval_model, 'eval_model_1e-3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb459f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore_model(eval_model, 'eval_model_asdf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1aed2485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'return': 0.88671875, 'score': 0.88671875}\n"
     ]
    }
   ],
   "source": [
    "algo_idx = 0\n",
    "common_extras = {}\n",
    "\n",
    "new_rng_key, rng_key = jax.random.split(rng_key)\n",
    "val_stats = collect_and_eval(\n",
    "    val_samplers[algo_idx],\n",
    "    functools.partial(eval_model.predict, algorithm_index=algo_idx),\n",
    "    val_sample_counts[algo_idx],\n",
    "    new_rng_key,\n",
    "    extras=common_extras)\n",
    "\n",
    "print(val_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2b7510d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'return': 0.5390625, 'score': 0.5390625}\n"
     ]
    }
   ],
   "source": [
    "new_rng_key, rng_key = jax.random.split(rng_key)\n",
    "test_stats = collect_and_eval(\n",
    "    test_samplers[algo_idx],\n",
    "    functools.partial(eval_model.predict, algorithm_index=algo_idx),\n",
    "    test_sample_counts[algo_idx],\n",
    "    new_rng_key,\n",
    "    extras=common_extras)\n",
    "\n",
    "print(test_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00b5f2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback = next(train_samplers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6eede5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_asdict',\n",
       " '_field_defaults',\n",
       " '_fields',\n",
       " '_fields_defaults',\n",
       " '_make',\n",
       " '_replace',\n",
       " 'count',\n",
       " 'features',\n",
       " 'index',\n",
       " 'outputs']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: x[:2] != '__', dir(feedback)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa70e0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_asdict',\n",
       " '_field_defaults',\n",
       " '_fields',\n",
       " '_fields_defaults',\n",
       " '_make',\n",
       " '_replace',\n",
       " 'count',\n",
       " 'hints',\n",
       " 'index',\n",
       " 'inputs',\n",
       " 'lengths']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: x[:2] != '__', dir(feedback.features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87285504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Features(inputs=(DataPoint(name=\"pos\",\tlocation=node,\ttype=scalar,\tdata=Array(32, 4)), DataPoint(name=\"key\",\tlocation=node,\ttype=scalar,\tdata=Array(32, 4)), DataPoint(name=\"target\",\tlocation=graph,\ttype=scalar,\tdata=Array(32,)), DataPoint(name=\"pred\",\tlocation=node,\ttype=pointer,\tdata=Array(32, 4))), hints=(DataPoint(name=\"low\",\tlocation=node,\ttype=mask_one,\tdata=Array(3, 32, 4)), DataPoint(name=\"high\",\tlocation=node,\ttype=mask_one,\tdata=Array(3, 32, 4)), DataPoint(name=\"mid\",\tlocation=node,\ttype=mask_one,\tdata=Array(3, 32, 4))), lengths=array([3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cd67ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DataPoint(name=\"pos\",\tlocation=node,\ttype=scalar,\tdata=Array(32, 4)),\n",
       " DataPoint(name=\"key\",\tlocation=node,\ttype=scalar,\tdata=Array(32, 4)),\n",
       " DataPoint(name=\"target\",\tlocation=graph,\ttype=scalar,\tdata=Array(32,)),\n",
       " DataPoint(name=\"pred\",\tlocation=node,\ttype=pointer,\tdata=Array(32, 4)))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback.features.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14e01e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75],\n",
       "       [0.  , 0.25, 0.5 , 0.75]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback.features.inputs[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03d5c9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02520887, 0.34267156, 0.73365599, 0.8296627 ],\n",
       "       [0.2815863 , 0.4715894 , 0.47860625, 0.48026793],\n",
       "       [0.39097453, 0.47543256, 0.57908949, 0.70142573],\n",
       "       [0.30469259, 0.42536476, 0.53733447, 0.57030581],\n",
       "       [0.21131138, 0.40548309, 0.75526293, 0.99791545],\n",
       "       [0.02907753, 0.18829309, 0.25950104, 0.71756621],\n",
       "       [0.37008792, 0.50818862, 0.70534563, 0.8590399 ],\n",
       "       [0.18123752, 0.31062654, 0.42587453, 0.51728185],\n",
       "       [0.17784155, 0.36243278, 0.53391556, 0.64810164],\n",
       "       [0.11175705, 0.25690464, 0.30079149, 0.83954411],\n",
       "       [0.0177951 , 0.05114759, 0.7110521 , 0.72883802],\n",
       "       [0.62460559, 0.75709726, 0.92234513, 0.94757189],\n",
       "       [0.06444846, 0.077098  , 0.34084127, 0.36992203],\n",
       "       [0.22745867, 0.23235493, 0.64552243, 0.70196529],\n",
       "       [0.02107851, 0.19214855, 0.90481048, 0.99302876],\n",
       "       [0.01860355, 0.39062096, 0.56357491, 0.69268914],\n",
       "       [0.10956793, 0.1245223 , 0.54496254, 0.64379351],\n",
       "       [0.02517611, 0.36283305, 0.57656876, 0.72705971],\n",
       "       [0.05109744, 0.30032844, 0.49777668, 0.85829909],\n",
       "       [0.01416618, 0.41836951, 0.51768147, 0.97180758],\n",
       "       [0.70435098, 0.82598814, 0.84156319, 0.93552742],\n",
       "       [0.12521531, 0.23405063, 0.38627487, 0.96702793],\n",
       "       [0.1957237 , 0.27583585, 0.27952177, 0.35949288],\n",
       "       [0.29109291, 0.40392249, 0.55143256, 0.89704872],\n",
       "       [0.08870553, 0.3302426 , 0.35989486, 0.42474906],\n",
       "       [0.17955742, 0.35009913, 0.47138836, 0.48836977],\n",
       "       [0.54700663, 0.70987029, 0.7676581 , 0.93909581],\n",
       "       [0.06050048, 0.44188159, 0.83723281, 0.93331125],\n",
       "       [0.13884649, 0.40045882, 0.42686125, 0.6587571 ],\n",
       "       [0.35168628, 0.42568155, 0.91370612, 0.92092841],\n",
       "       [0.21015951, 0.31253423, 0.34624332, 0.35713608],\n",
       "       [0.54149327, 0.62400143, 0.70318085, 0.80415906]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback.features.inputs[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b16a11f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82062526, 0.52817175, 0.71065433, 0.3316224 , 0.90621436,\n",
       "       0.51697819, 0.03612513, 0.07783235, 0.75587324, 0.06289266,\n",
       "       0.36138149, 0.56755967, 0.60333232, 0.00822275, 0.06009184,\n",
       "       0.78350037, 0.95836797, 0.25672611, 0.09071109, 0.63983783,\n",
       "       0.2822263 , 0.40492029, 0.2021623 , 0.37730146, 0.61462071,\n",
       "       0.71113094, 0.62929972, 0.03444254, 0.93701735, 0.4842491 ,\n",
       "       0.08684329, 0.46058426])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback.features.inputs[2].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97d00fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.],\n",
       "       [0., 0., 1., 2.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback.features.inputs[3].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a78496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = feedback.features.inputs[2].data\n",
    "adj = feedback.features.inputs[3].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b58635a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([ 0,  0,  1,  1,  2,  2,  3,  3,  4,  4,  5,  5,  6,  6,  7,  7,  8,\n",
       "         8,  9,  9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16,\n",
       "        17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23, 24, 24, 25,\n",
       "        25, 26, 26, 27, 27, 28, 28, 29, 29, 30, 30, 31, 31], dtype=int32),\n",
       " Array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1],      dtype=int32))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.where(jnp.expand_dims((A != 0), 1) & (adj == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19b9ee9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DataPoint(name=\"low\",\tlocation=node,\ttype=mask_one,\tdata=Array(3, 32, 4)),\n",
       " DataPoint(name=\"high\",\tlocation=node,\ttype=mask_one,\tdata=Array(3, 32, 4)),\n",
       " DataPoint(name=\"mid\",\tlocation=node,\ttype=mask_one,\tdata=Array(3, 32, 4)))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback.features.hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b088c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(feedback.features.inputs[0].data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7396caeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]),\n",
       " array([3, 3, 3, 1, 3, 3, 0, 0, 3, 0, 2, 0, 3, 0, 1, 3, 3, 1, 1, 3, 0, 3,\n",
       "        1, 1, 3, 3, 1, 0, 3, 2, 0, 0]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(feedback.outputs[0].data == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96f1aa77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample_counts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "183fb917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Features(inputs=(DataPoint(name=\"pos\",\tlocation=node,\ttype=scalar,\tdata=Array(32, 4)), DataPoint(name=\"key\",\tlocation=node,\ttype=scalar,\tdata=Array(32, 4)), DataPoint(name=\"target\",\tlocation=graph,\ttype=scalar,\tdata=Array(32,)), DataPoint(name=\"pred\",\tlocation=node,\ttype=pointer,\tdata=Array(32, 4))), hints=(DataPoint(name=\"low\",\tlocation=node,\ttype=mask_one,\tdata=Array(3, 32, 4)), DataPoint(name=\"high\",\tlocation=node,\ttype=mask_one,\tdata=Array(3, 32, 4)), DataPoint(name=\"mid\",\tlocation=node,\ttype=mask_one,\tdata=Array(3, 32, 4))), lengths=array([3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "189e76f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 6, 64, 64, 32) 32 512 12\n",
      "Thresholding: 24192 of 786432\n",
      "Criteria thresholding: 128 of 786432\n",
      "Random sampling: 128 of 786432\n",
      "(32, 6, 64, 64, 32) 32 512 12\n",
      "Thresholding: 24192 of 786432\n",
      "Criteria thresholding: 128 of 786432\n",
      "Random sampling: 128 of 786432\n",
      "(32, 6, 64, 64, 32) 32 512 12\n",
      "Thresholding: 24192 of 786432\n",
      "Criteria thresholding: 128 of 786432\n",
      "Random sampling: 128 of 786432\n",
      "(32, 6, 64, 64, 32) 32 512 12\n",
      "Thresholding: 24192 of 786432\n",
      "Criteria thresholding: 128 of 786432\n",
      "Random sampling: 128 of 786432\n",
      "(32, 6, 64, 64, 32) 32 512 12\n",
      "Thresholding: 24192 of 786432\n",
      "Criteria thresholding: 128 of 786432\n",
      "Random sampling: 128 of 786432\n",
      "(32, 6, 64, 64, 32) 32 512 12\n",
      "Thresholding: 24192 of 786432\n",
      "Criteria thresholding: 128 of 786432\n",
      "Random sampling: 128 of 786432\n",
      "(32, 6, 64, 64, 32) 32 512 12\n",
      "Thresholding: 24192 of 786432\n",
      "Criteria thresholding: 128 of 786432\n",
      "Random sampling: 128 of 786432\n",
      "(32, 6, 64, 64, 32) 32 512 12\n",
      "Thresholding: 24192 of 786432\n",
      "Criteria thresholding: 128 of 786432\n",
      "Random sampling: 128 of 786432\n",
      "(32, 6, 64, 64, 32) 32 512 12\n",
      "Thresholding: 24192 of 786432\n",
      "Criteria thresholding: 128 of 786432\n",
      "Random sampling: 128 of 786432\n",
      "(32, 6, 64, 64, 32) 32 512 12\n",
      "Thresholding: 24192 of 786432\n",
      "Criteria thresholding: 128 of 786432\n",
      "Random sampling: 128 of 786432\n",
      "(32, 6, 64, 64, 32) 32 512 12\n",
      "Thresholding: 24192 of 786432\n",
      "Criteria thresholding: 128 of 786432\n",
      "Random sampling: 128 of 786432\n",
      "(32, 6, 64, 64, 32) 32 512 12\n",
      "Thresholding: 24192 of 786432\n",
      "Criteria thresholding: 128 of 786432\n",
      "Random sampling: 128 of 786432\n",
      "(32, 6, 64, 64, 32) 32 512 12\n",
      "Thresholding: 24192 of 786432\n",
      "Criteria thresholding: 128 of 786432\n",
      "Random sampling: 128 of 786432\n",
      "(32, 6, 64, 64, 32) 32 512 12\n",
      "Thresholding: 24192 of 786432\n",
      "Criteria thresholding: 128 of 786432\n",
      "Random sampling: 128 of 786432\n",
      "(32, 6, 64, 64, 32) 32 512 12\n",
      "Thresholding: 24192 of 786432\n",
      "Criteria thresholding: 128 of 786432\n",
      "Random sampling: 128 of 786432\n",
      "(32, 6, 64, 64, 32) 32 512 12\n",
      "Thresholding: 24192 of 786432\n",
      "Criteria thresholding: 128 of 786432\n",
      "Random sampling: 128 of 786432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2048, 556)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rng_key, rng_key = jax.random.split(rng_key)\n",
    "batched_msgs = get_msgs(\n",
    "    test_samplers[0],\n",
    "    functools.partial(eval_model.predict, algorithm_index=0),\n",
    "#     test_sample_counts[0],  # EXPLODING MEMORY LOL\n",
    "    4*32*4,\n",
    "    new_rng_key,\n",
    "    # For binary search: mid1 == 1 or mid2 == 1\n",
    "    criteria=lambda x: np.bitwise_or(x[:, -1] == 1, x[:, -2] == 1),\n",
    "    # criteria=None,\n",
    "    sample_prob=1)\n",
    "\n",
    "batched_msgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a54a1ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0, dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.sum(jnp.linalg.norm(batched_msgs[:,:32],axis=1) < 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7200bf49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0, dtype=int32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.sum(jnp.max(jnp.abs(batched_msgs[:,:32]),axis=1) < 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d39b3e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.01300676, -0.00516211,  0.04877086,  0.05424519,  0.02105969,\n",
       "         0.01826444, -0.01051411, -0.0716765 ,  0.03990274,  0.07754934,\n",
       "        -0.02410381, -0.05027805,  0.04341411,  0.04791321, -0.00606619,\n",
       "        -0.03409918, -0.00920935, -0.00709733,  0.07736857,  0.01340538,\n",
       "        -0.84274709,  0.05170161, -0.01429862, -0.5576036 , -0.01667661,\n",
       "        -0.012039  ,  0.08439622, -0.06144607,  0.00974206,  0.00482731,\n",
       "        -0.00879854,  0.01555658]),\n",
       " array([ 0.23687603,  0.01969739, -0.03851569,  0.22293663, -0.05194453,\n",
       "        -0.18434471, -0.00436173,  0.03789113, -0.090555  , -0.07392705,\n",
       "         0.03429982,  0.01792889,  0.10030431,  0.01679242,  0.0422462 ,\n",
       "        -0.17402378, -0.08953831, -0.11886487, -0.07830518, -0.01434487,\n",
       "        -0.84145832, -0.02248025, -0.04409573, -0.53596944,  0.09152045,\n",
       "        -0.07621835, -0.07672852,  0.1089345 , -0.22144185,  0.34828785,\n",
       "         0.04142797, -0.06552748]),\n",
       " array([ 2.83360243e-01,  2.20238939e-02, -2.14380212e-02,  6.99609593e-02,\n",
       "         1.93971589e-01, -1.56252369e-01, -7.94411451e-02, -9.93853286e-02,\n",
       "        -2.69285329e-02, -7.95676485e-02,  4.73265946e-02,  7.68973771e-03,\n",
       "        -4.13947217e-02, -6.15037046e-02,  1.90831766e-01, -1.64541334e-01,\n",
       "        -7.53758252e-02, -1.43416062e-01, -1.02811763e-02, -1.07657455e-01,\n",
       "        -6.79945648e-01, -9.13131014e-02, -6.65814430e-02, -3.67070526e-01,\n",
       "         1.28150046e-01, -3.54245543e-01, -1.28103644e-02,  4.49328005e-01,\n",
       "        -1.49005517e-01,  4.93980050e-01,  9.35589969e-02,  3.29548056e-04]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_msgs[0][:32], batched_msgs[1][:32], batched_msgs[2][:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1bec654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'binary_search_val_msgs.pkl'\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(batched_msgs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e9a3dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9109632"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(batched_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c29ad849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample_counts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3cbf7089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.109632"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(batched_msgs) / 1000000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('pysr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "36b0488005d1a76292731de31d3f8eec57be1775967151d475554d081124d99a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
